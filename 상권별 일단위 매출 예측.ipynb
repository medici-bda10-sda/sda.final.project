{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting prophet\n",
      "  Downloading prophet-1.1.6-py3-none-win_amd64.whl.metadata (3.6 kB)\n",
      "Collecting cmdstanpy>=1.0.4 (from prophet)\n",
      "  Downloading cmdstanpy-1.2.5-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: numpy>=1.15.4 in c:\\users\\m\\anaconda3\\lib\\site-packages (from prophet) (1.26.4)\n",
      "Requirement already satisfied: matplotlib>=2.0.0 in c:\\users\\m\\anaconda3\\lib\\site-packages (from prophet) (3.9.2)\n",
      "Requirement already satisfied: pandas>=1.0.4 in c:\\users\\m\\anaconda3\\lib\\site-packages (from prophet) (2.2.2)\n",
      "Collecting holidays<1,>=0.25 (from prophet)\n",
      "  Downloading holidays-0.66-py3-none-any.whl.metadata (26 kB)\n",
      "Requirement already satisfied: tqdm>=4.36.1 in c:\\users\\m\\anaconda3\\lib\\site-packages (from prophet) (4.66.5)\n",
      "Collecting importlib-resources (from prophet)\n",
      "  Downloading importlib_resources-6.5.2-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting stanio<2.0.0,>=0.4.0 (from cmdstanpy>=1.0.4->prophet)\n",
      "  Downloading stanio-0.5.1-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\m\\anaconda3\\lib\\site-packages (from holidays<1,>=0.25->prophet) (2.9.0.post0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\m\\anaconda3\\lib\\site-packages (from matplotlib>=2.0.0->prophet) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\m\\anaconda3\\lib\\site-packages (from matplotlib>=2.0.0->prophet) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\m\\anaconda3\\lib\\site-packages (from matplotlib>=2.0.0->prophet) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\m\\anaconda3\\lib\\site-packages (from matplotlib>=2.0.0->prophet) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\m\\anaconda3\\lib\\site-packages (from matplotlib>=2.0.0->prophet) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\m\\anaconda3\\lib\\site-packages (from matplotlib>=2.0.0->prophet) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\m\\anaconda3\\lib\\site-packages (from matplotlib>=2.0.0->prophet) (3.1.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\m\\anaconda3\\lib\\site-packages (from pandas>=1.0.4->prophet) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\m\\anaconda3\\lib\\site-packages (from pandas>=1.0.4->prophet) (2023.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\m\\anaconda3\\lib\\site-packages (from tqdm>=4.36.1->prophet) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\m\\anaconda3\\lib\\site-packages (from python-dateutil->holidays<1,>=0.25->prophet) (1.16.0)\n",
      "Downloading prophet-1.1.6-py3-none-win_amd64.whl (13.3 MB)\n",
      "   ---------------------------------------- 0.0/13.3 MB ? eta -:--:--\n",
      "   ---------------------- ----------------- 7.3/13.3 MB 37.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 13.3/13.3 MB 34.8 MB/s eta 0:00:00\n",
      "Downloading cmdstanpy-1.2.5-py3-none-any.whl (94 kB)\n",
      "Downloading holidays-0.66-py3-none-any.whl (791 kB)\n",
      "   ---------------------------------------- 0.0/791.2 kB ? eta -:--:--\n",
      "   --------------------------------------- 791.2/791.2 kB 33.1 MB/s eta 0:00:00\n",
      "Downloading importlib_resources-6.5.2-py3-none-any.whl (37 kB)\n",
      "Downloading stanio-0.5.1-py3-none-any.whl (8.1 kB)\n",
      "Installing collected packages: stanio, importlib-resources, holidays, cmdstanpy, prophet\n",
      "Successfully installed cmdstanpy-1.2.5 holidays-0.66 importlib-resources-6.5.2 prophet-1.1.6 stanio-0.5.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ïùº Îã®ÏúÑ Îß§Ï∂ú Îç∞Ïù¥ÌÑ∞ Ï∂îÏ†ï ÏûëÏóÖÏù¥ ÏôÑÎ£åÎêòÏóàÏäµÎãàÎã§.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from prophet import Prophet\n",
    "import numpy as np\n",
    "\n",
    "# ÌååÏùº Í≤ΩÎ°ú ÏÑ§Ï†ï\n",
    "file_path = r\"C:\\Users\\m\\Desktop\\Î®∏Ïã†Îü¨Îãù ÏÇ¨Ïö© Îç∞Ïù¥ÌÑ∞\\ÌîºÏ≤òÏóîÏßÄÎãàÏñ¥ÎßÅÌïúÌÜµÌï©Îç∞Ïù¥ÌÑ∞\\ÌîºÏ≤òÏóîÏßÄÎãàÏñ¥ÎßÅÏùºÎã®Îã§ÌïúÌÜµÌï©Îç∞Ïù¥ÌÑ∞.csv\"\n",
    "\n",
    "# Îç∞Ïù¥ÌÑ∞ Î°úÎìú\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# ÌïÑÏöîÌïú ÏπºÎüº ÏÑ†ÌÉù\n",
    "df = df[['Í∏∞Ï§Ä_ÎÖÑÎ∂ÑÍ∏∞_ÏΩîÎìú', 'ÏÉÅÍ∂å_ÏΩîÎìú_Î™Ö', 'ÏõîÏöîÏùº_Îß§Ï∂ú_Í∏àÏï°', 'ÌôîÏöîÏùº_Îß§Ï∂ú_Í∏àÏï°', \n",
    "          'ÏàòÏöîÏùº_Îß§Ï∂ú_Í∏àÏï°', 'Î™©ÏöîÏùº_Îß§Ï∂ú_Í∏àÏï°', 'Í∏àÏöîÏùº_Îß§Ï∂ú_Í∏àÏï°', 'ÌÜ†ÏöîÏùº_Îß§Ï∂ú_Í∏àÏï°', 'ÏùºÏöîÏùº_Îß§Ï∂ú_Í∏àÏï°']]\n",
    "\n",
    "# Í∏∞Ï§Ä_ÎÖÑÎ∂ÑÍ∏∞_ÏΩîÎìúÎ•º ÎÇ†ÏßúÎ°ú Î≥ÄÌôò (Í∞Å Î∂ÑÍ∏∞Ïùò Ï≤´ Î≤àÏß∏ ÎÇ†)\n",
    "def convert_quarter_to_date(quarter_code):\n",
    "    year = int(str(quarter_code)[:4])\n",
    "    quarter = int(str(quarter_code)[4:])\n",
    "    month = {1: '01', 2: '04', 3: '07', 4: '10'}[quarter]\n",
    "    return f\"{year}-{month}-01\"\n",
    "\n",
    "df['ÎÇ†Ïßú'] = df['Í∏∞Ï§Ä_ÎÖÑÎ∂ÑÍ∏∞_ÏΩîÎìú'].apply(convert_quarter_to_date)\n",
    "df['ÎÇ†Ïßú'] = pd.to_datetime(df['ÎÇ†Ïßú'])\n",
    "\n",
    "# ÏöîÏùº Îß§Ï∂ú Îç∞Ïù¥ÌÑ∞ Í∞ÄÍ≥µ\n",
    "daily_sales_list = []\n",
    "for _, row in df.iterrows():\n",
    "    base_date = row['ÎÇ†Ïßú']\n",
    "    sales_values = [row['ÏõîÏöîÏùº_Îß§Ï∂ú_Í∏àÏï°'], row['ÌôîÏöîÏùº_Îß§Ï∂ú_Í∏àÏï°'], row['ÏàòÏöîÏùº_Îß§Ï∂ú_Í∏àÏï°'],\n",
    "                     row['Î™©ÏöîÏùº_Îß§Ï∂ú_Í∏àÏï°'], row['Í∏àÏöîÏùº_Îß§Ï∂ú_Í∏àÏï°'], row['ÌÜ†ÏöîÏùº_Îß§Ï∂ú_Í∏àÏï°'], row['ÏùºÏöîÏùº_Îß§Ï∂ú_Í∏àÏï°']]\n",
    "    \n",
    "    # Î∂ÑÍ∏∞ Í∏∞Ï§Ä Îç∞Ïù¥ÌÑ∞Î•º Ï£ºÏ∞® Îã®ÏúÑÎ°ú Î∞òÎ≥µÌïòÎ©∞ Îß§Ïùº Îç∞Ïù¥ÌÑ∞Î•º ÏÉùÏÑ±\n",
    "    for week_offset in range(13):  # Î∂ÑÍ∏∞Îäî 13Ï£º\n",
    "        week_start_date = base_date + pd.Timedelta(weeks=week_offset)\n",
    "        for day_offset, sales_value in enumerate(sales_values):\n",
    "            daily_date = week_start_date + pd.Timedelta(days=day_offset)\n",
    "            daily_sales_list.append({\n",
    "                'ÎÇ†Ïßú': daily_date,\n",
    "                'ÏöîÏùº': daily_date.strftime('%A'),\n",
    "                'ÏÉÅÍ∂åÎ™Ö': row['ÏÉÅÍ∂å_ÏΩîÎìú_Î™Ö'],\n",
    "                'Îß§Ï∂ú': sales_value / 13  # Ï£ºÏ∞® Îã®ÏúÑ Îß§Ï∂ú ÌèâÍ∑†ÏúºÎ°ú ÎÇòÎàî\n",
    "            })\n",
    "\n",
    "# Îç∞Ïù¥ÌÑ∞ÌîÑÎ†àÏûÑ Î≥ÄÌôò\n",
    "daily_sales_df = pd.DataFrame(daily_sales_list)\n",
    "\n",
    "# Í≤∞Í≥º Ï†ÄÏû•\n",
    "output_file = r\"C:\\Users\\m\\Desktop\\Î®∏Ïã†Îü¨Îãù ÏÇ¨Ïö© Îç∞Ïù¥ÌÑ∞\\ÌîºÏ≤òÏóîÏßÄÎãàÏñ¥ÎßÅÌïúÌÜµÌï©Îç∞Ïù¥ÌÑ∞\\ÏùºÎã®ÏúÑ_Îß§Ï∂ú_Ï∂îÏ†ïÏπò.csv\"\n",
    "daily_sales_df.to_csv(output_file, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(\"Ïùº Îã®ÏúÑ Îß§Ï∂ú Îç∞Ïù¥ÌÑ∞ Ï∂îÏ†ï ÏûëÏóÖÏù¥ ÏôÑÎ£åÎêòÏóàÏäµÎãàÎã§.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Îç∞Ïù¥ÌÑ∞ Í≤ÄÏ¶ùÏΩîÎìú"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You are trying to merge on object and int64 columns for key 'Í∏∞Ï§Ä_ÎÖÑÎ∂ÑÍ∏∞_ÏΩîÎìú'. If you wish to proceed you should use pd.concat",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 24\u001b[0m\n\u001b[0;32m     21\u001b[0m original_quarter_sales\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mÏÉÅÍ∂å_ÏΩîÎìú_Î™Ö\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mÏÉÅÍ∂åÎ™Ö\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mÎãπÏõî_Îß§Ï∂ú_Í∏àÏï°\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mÏõêÎ≥∏_Îß§Ï∂ú\u001b[39m\u001b[38;5;124m'\u001b[39m}, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Îç∞Ïù¥ÌÑ∞ Î≥ëÌï© ÌõÑ Ï∞®Ïù¥ ÌôïÏù∏\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m merged_sales \u001b[38;5;241m=\u001b[39m preprocessed_quarter_sales\u001b[38;5;241m.\u001b[39mmerge(original_quarter_sales, on\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mÍ∏∞Ï§Ä_ÎÖÑÎ∂ÑÍ∏∞_ÏΩîÎìú\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mÏÉÅÍ∂åÎ™Ö\u001b[39m\u001b[38;5;124m'\u001b[39m], how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     25\u001b[0m merged_sales[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mÎß§Ï∂úÏ∞®Ïù¥\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m merged_sales[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mÎß§Ï∂ú\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m-\u001b[39m merged_sales[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mÏõêÎ≥∏_Îß§Ï∂ú\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Îß§Ï∂ú Ï∞®Ïù¥Í∞Ä 0Ïù¥ ÏïÑÎãå Îç∞Ïù¥ÌÑ∞ ÌôïÏù∏\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\m\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:10832\u001b[0m, in \u001b[0;36mDataFrame.merge\u001b[1;34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m  10813\u001b[0m \u001b[38;5;129m@Substitution\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m  10814\u001b[0m \u001b[38;5;129m@Appender\u001b[39m(_merge_doc, indents\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m  10815\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmerge\u001b[39m(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  10828\u001b[0m     validate: MergeValidate \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m  10829\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[0;32m  10830\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreshape\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmerge\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m merge\n\u001b[1;32m> 10832\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m merge(\n\u001b[0;32m  10833\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m  10834\u001b[0m         right,\n\u001b[0;32m  10835\u001b[0m         how\u001b[38;5;241m=\u001b[39mhow,\n\u001b[0;32m  10836\u001b[0m         on\u001b[38;5;241m=\u001b[39mon,\n\u001b[0;32m  10837\u001b[0m         left_on\u001b[38;5;241m=\u001b[39mleft_on,\n\u001b[0;32m  10838\u001b[0m         right_on\u001b[38;5;241m=\u001b[39mright_on,\n\u001b[0;32m  10839\u001b[0m         left_index\u001b[38;5;241m=\u001b[39mleft_index,\n\u001b[0;32m  10840\u001b[0m         right_index\u001b[38;5;241m=\u001b[39mright_index,\n\u001b[0;32m  10841\u001b[0m         sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[0;32m  10842\u001b[0m         suffixes\u001b[38;5;241m=\u001b[39msuffixes,\n\u001b[0;32m  10843\u001b[0m         copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m  10844\u001b[0m         indicator\u001b[38;5;241m=\u001b[39mindicator,\n\u001b[0;32m  10845\u001b[0m         validate\u001b[38;5;241m=\u001b[39mvalidate,\n\u001b[0;32m  10846\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\m\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:170\u001b[0m, in \u001b[0;36mmerge\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m    155\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _cross_merge(\n\u001b[0;32m    156\u001b[0m         left_df,\n\u001b[0;32m    157\u001b[0m         right_df,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    167\u001b[0m         copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m    168\u001b[0m     )\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 170\u001b[0m     op \u001b[38;5;241m=\u001b[39m _MergeOperation(\n\u001b[0;32m    171\u001b[0m         left_df,\n\u001b[0;32m    172\u001b[0m         right_df,\n\u001b[0;32m    173\u001b[0m         how\u001b[38;5;241m=\u001b[39mhow,\n\u001b[0;32m    174\u001b[0m         on\u001b[38;5;241m=\u001b[39mon,\n\u001b[0;32m    175\u001b[0m         left_on\u001b[38;5;241m=\u001b[39mleft_on,\n\u001b[0;32m    176\u001b[0m         right_on\u001b[38;5;241m=\u001b[39mright_on,\n\u001b[0;32m    177\u001b[0m         left_index\u001b[38;5;241m=\u001b[39mleft_index,\n\u001b[0;32m    178\u001b[0m         right_index\u001b[38;5;241m=\u001b[39mright_index,\n\u001b[0;32m    179\u001b[0m         sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[0;32m    180\u001b[0m         suffixes\u001b[38;5;241m=\u001b[39msuffixes,\n\u001b[0;32m    181\u001b[0m         indicator\u001b[38;5;241m=\u001b[39mindicator,\n\u001b[0;32m    182\u001b[0m         validate\u001b[38;5;241m=\u001b[39mvalidate,\n\u001b[0;32m    183\u001b[0m     )\n\u001b[0;32m    184\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result(copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "File \u001b[1;32mc:\\Users\\m\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:807\u001b[0m, in \u001b[0;36m_MergeOperation.__init__\u001b[1;34m(self, left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, indicator, validate)\u001b[0m\n\u001b[0;32m    803\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_tolerance(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft_join_keys)\n\u001b[0;32m    805\u001b[0m \u001b[38;5;66;03m# validate the merge keys dtypes. We may need to coerce\u001b[39;00m\n\u001b[0;32m    806\u001b[0m \u001b[38;5;66;03m# to avoid incompatible dtypes\u001b[39;00m\n\u001b[1;32m--> 807\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_coerce_merge_keys()\n\u001b[0;32m    809\u001b[0m \u001b[38;5;66;03m# If argument passed to validate,\u001b[39;00m\n\u001b[0;32m    810\u001b[0m \u001b[38;5;66;03m# check if columns specified as unique\u001b[39;00m\n\u001b[0;32m    811\u001b[0m \u001b[38;5;66;03m# are in fact unique.\u001b[39;00m\n\u001b[0;32m    812\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validate \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\m\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:1508\u001b[0m, in \u001b[0;36m_MergeOperation._maybe_coerce_merge_keys\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1502\u001b[0m     \u001b[38;5;66;03m# unless we are merging non-string-like with string-like\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[0;32m   1504\u001b[0m         inferred_left \u001b[38;5;129;01min\u001b[39;00m string_types \u001b[38;5;129;01mand\u001b[39;00m inferred_right \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m string_types\n\u001b[0;32m   1505\u001b[0m     ) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   1506\u001b[0m         inferred_right \u001b[38;5;129;01min\u001b[39;00m string_types \u001b[38;5;129;01mand\u001b[39;00m inferred_left \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m string_types\n\u001b[0;32m   1507\u001b[0m     ):\n\u001b[1;32m-> 1508\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;66;03m# datetimelikes must match exactly\u001b[39;00m\n\u001b[0;32m   1511\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m needs_i8_conversion(lk\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m needs_i8_conversion(rk\u001b[38;5;241m.\u001b[39mdtype):\n",
      "\u001b[1;31mValueError\u001b[0m: You are trying to merge on object and int64 columns for key 'Í∏∞Ï§Ä_ÎÖÑÎ∂ÑÍ∏∞_ÏΩîÎìú'. If you wish to proceed you should use pd.concat"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Îç∞Ïù¥ÌÑ∞ Î∂àÎü¨Ïò§Í∏∞\n",
    "preprocessed_df = pd.read_csv(r\"C:\\Users\\m\\Desktop\\Î®∏Ïã†Îü¨Îãù ÏÇ¨Ïö© Îç∞Ïù¥ÌÑ∞\\ÌîºÏ≤òÏóîÏßÄÎãàÏñ¥ÎßÅÌïúÌÜµÌï©Îç∞Ïù¥ÌÑ∞\\ÏùºÎã®ÏúÑ_Îß§Ï∂ú_Ï∂îÏ†ïÏπò.csv\")  # Ï†ÑÏ≤òÎ¶¨ Îç∞Ïù¥ÌÑ∞\n",
    "original_df = pd.read_csv(r\"C:\\Users\\m\\Desktop\\Î®∏Ïã†Îü¨Îãù ÏÇ¨Ïö© Îç∞Ïù¥ÌÑ∞\\ÌîºÏ≤òÏóîÏßÄÎãàÏñ¥ÎßÅÌïúÌÜµÌï©Îç∞Ïù¥ÌÑ∞\\ÌîºÏ≤òÏóîÏßÄÎãàÏñ¥ÎßÅÏùºÎã®Îã§ÌïúÌÜµÌï©Îç∞Ïù¥ÌÑ∞.csv\")  # ÏõêÎ≥∏ Îç∞Ïù¥ÌÑ∞\n",
    "\n",
    "# ÎÇ†Ïßú Ïª¨ÎüºÏùÑ datetimeÏúºÎ°ú Î≥ÄÌôò\n",
    "preprocessed_df['ÎÇ†Ïßú'] = pd.to_datetime(preprocessed_df['ÎÇ†Ïßú'])\n",
    "\n",
    "# ÎÇ†ÏßúÎ•º Í∏∞Ï§ÄÏúºÎ°ú 'Í∏∞Ï§Ä_ÎÖÑÎ∂ÑÍ∏∞_ÏΩîÎìú' ÏÉùÏÑ± (YYYYQ ÌòïÏãù)\n",
    "preprocessed_df['Í∏∞Ï§Ä_ÎÖÑÎ∂ÑÍ∏∞_ÏΩîÎìú'] = preprocessed_df['ÎÇ†Ïßú'].dt.year.astype(str) + ((preprocessed_df['ÎÇ†Ïßú'].dt.month - 1) // 3 + 1).astype(str)\n",
    "\n",
    "# 1. Ïó∞Î∂ÑÍ∏∞Î≥Ñ Îß§Ï∂ú Ï¥ùÌï© ÎπÑÍµê\n",
    "# Ï†ÑÏ≤òÎ¶¨ Îç∞Ïù¥ÌÑ∞ÏóêÏÑú Ïó∞Î∂ÑÍ∏∞Î≥Ñ, ÏÉÅÍ∂åÎ≥Ñ Îß§Ï∂ú Ìï©ÏÇ∞\n",
    "preprocessed_quarter_sales = preprocessed_df.groupby(['Í∏∞Ï§Ä_ÎÖÑÎ∂ÑÍ∏∞_ÏΩîÎìú', 'ÏÉÅÍ∂åÎ™Ö'])['Îß§Ï∂ú'].sum().reset_index()\n",
    "\n",
    "# ÏõêÎ≥∏ Îç∞Ïù¥ÌÑ∞ÏóêÏÑú ÎãπÏõî Îß§Ï∂ú Í∏àÏï° (Ïó∞Î∂ÑÍ∏∞Î≥Ñ Îß§Ï∂ú) ÏÑ†ÌÉù\n",
    "original_quarter_sales = original_df[['Í∏∞Ï§Ä_ÎÖÑÎ∂ÑÍ∏∞_ÏΩîÎìú', 'ÏÉÅÍ∂å_ÏΩîÎìú_Î™Ö', 'ÎãπÏõî_Îß§Ï∂ú_Í∏àÏï°']].copy()\n",
    "\n",
    "# Ïª¨ÎüºÎ™Ö ÌÜµÏùº (ÏÉÅÍ∂åÎ™Ö Í∏∞Ï§Ä)\n",
    "original_quarter_sales.rename(columns={'ÏÉÅÍ∂å_ÏΩîÎìú_Î™Ö': 'ÏÉÅÍ∂åÎ™Ö', 'ÎãπÏõî_Îß§Ï∂ú_Í∏àÏï°': 'ÏõêÎ≥∏_Îß§Ï∂ú'}, inplace=True)\n",
    "\n",
    "# Îç∞Ïù¥ÌÑ∞ Î≥ëÌï© ÌõÑ Ï∞®Ïù¥ ÌôïÏù∏\n",
    "merged_sales = preprocessed_quarter_sales.merge(original_quarter_sales, on=['Í∏∞Ï§Ä_ÎÖÑÎ∂ÑÍ∏∞_ÏΩîÎìú', 'ÏÉÅÍ∂åÎ™Ö'], how='left')\n",
    "merged_sales['Îß§Ï∂úÏ∞®Ïù¥'] = merged_sales['Îß§Ï∂ú'] - merged_sales['ÏõêÎ≥∏_Îß§Ï∂ú']\n",
    "\n",
    "# Îß§Ï∂ú Ï∞®Ïù¥Í∞Ä 0Ïù¥ ÏïÑÎãå Îç∞Ïù¥ÌÑ∞ ÌôïÏù∏\n",
    "sales_mismatch = merged_sales[merged_sales['Îß§Ï∂úÏ∞®Ïù¥'] != 0]\n",
    "\n",
    "# 2. ÏöîÏùºÎ≥Ñ Îß§Ï∂ú Ï¥ùÌï© ÎπÑÍµê\n",
    "# Ï†ÑÏ≤òÎ¶¨ Îç∞Ïù¥ÌÑ∞ÏóêÏÑú Ïó∞Î∂ÑÍ∏∞Î≥Ñ, ÏÉÅÍ∂åÎ≥Ñ, ÏöîÏùºÎ≥Ñ Îß§Ï∂ú Ìï©ÏÇ∞\n",
    "preprocessed_weekly_sales = preprocessed_df.groupby(['Í∏∞Ï§Ä_ÎÖÑÎ∂ÑÍ∏∞_ÏΩîÎìú', 'ÏÉÅÍ∂åÎ™Ö', 'ÏöîÏùº'])['Îß§Ï∂ú'].sum().reset_index()\n",
    "\n",
    "# ÏõêÎ≥∏ Îç∞Ïù¥ÌÑ∞ÏóêÏÑú ÏöîÏùºÎ≥Ñ Îß§Ï∂ú Ïª¨Îüº Ï∂îÏ∂ú Î∞è Î≥ÄÌôò\n",
    "original_weekly_sales = original_df.melt(id_vars=['Í∏∞Ï§Ä_ÎÖÑÎ∂ÑÍ∏∞_ÏΩîÎìú', 'ÏÉÅÍ∂å_ÏΩîÎìú_Î™Ö'], \n",
    "                                         value_vars=['ÏõîÏöîÏùº_Îß§Ï∂ú_Í∏àÏï°', 'ÌôîÏöîÏùº_Îß§Ï∂ú_Í∏àÏï°', 'ÏàòÏöîÏùº_Îß§Ï∂ú_Í∏àÏï°',\n",
    "                                                     'Î™©ÏöîÏùº_Îß§Ï∂ú_Í∏àÏï°', 'Í∏àÏöîÏùº_Îß§Ï∂ú_Í∏àÏï°', 'ÌÜ†ÏöîÏùº_Îß§Ï∂ú_Í∏àÏï°', 'ÏùºÏöîÏùº_Îß§Ï∂ú_Í∏àÏï°'],\n",
    "                                         var_name='ÏöîÏùº', value_name='ÏõêÎ≥∏_ÏöîÏùºÎ≥Ñ_Îß§Ï∂ú')\n",
    "\n",
    "# ÏöîÏùº Ïª¨Îüº Î≥ÄÌôò\n",
    "original_weekly_sales['ÏöîÏùº'] = original_weekly_sales['ÏöîÏùº'].str.replace('_Îß§Ï∂ú_Í∏àÏï°', '').str.replace('ÏõîÏöîÏùº', 'Ïõî').replace('ÌôîÏöîÏùº', 'Ìôî').replace('ÏàòÏöîÏùº', 'Ïàò')\\\n",
    "    .replace('Î™©ÏöîÏùº', 'Î™©').replace('Í∏àÏöîÏùº', 'Í∏à').replace('ÌÜ†ÏöîÏùº', 'ÌÜ†').replace('ÏùºÏöîÏùº', 'Ïùº')\n",
    "\n",
    "# Ïª¨ÎüºÎ™Ö ÌÜµÏùº (ÏÉÅÍ∂åÎ™Ö Í∏∞Ï§Ä)\n",
    "original_weekly_sales.rename(columns={'ÏÉÅÍ∂å_ÏΩîÎìú_Î™Ö': 'ÏÉÅÍ∂åÎ™Ö'}, inplace=True)\n",
    "\n",
    "# Îç∞Ïù¥ÌÑ∞ Î≥ëÌï© ÌõÑ Ï∞®Ïù¥ ÌôïÏù∏\n",
    "merged_weekly_sales = preprocessed_weekly_sales.merge(original_weekly_sales, on=['Í∏∞Ï§Ä_ÎÖÑÎ∂ÑÍ∏∞_ÏΩîÎìú', 'ÏÉÅÍ∂åÎ™Ö', 'ÏöîÏùº'], how='left')\n",
    "merged_weekly_sales['ÏöîÏùºÎ≥Ñ_Îß§Ï∂úÏ∞®Ïù¥'] = merged_weekly_sales['Îß§Ï∂ú'] - merged_weekly_sales['ÏõêÎ≥∏_ÏöîÏùºÎ≥Ñ_Îß§Ï∂ú']\n",
    "\n",
    "# ÏöîÏùºÎ≥Ñ Îß§Ï∂ú Ï∞®Ïù¥Í∞Ä 0Ïù¥ ÏïÑÎãå Îç∞Ïù¥ÌÑ∞ ÌôïÏù∏\n",
    "weekly_sales_mismatch = merged_weekly_sales[merged_weekly_sales['ÏöîÏùºÎ≥Ñ_Îß§Ï∂úÏ∞®Ïù¥'] != 0]\n",
    "\n",
    "# Í≤∞Í≥º Ï∂úÎ†•\n",
    "print(\"Ïó∞Î∂ÑÍ∏∞Î≥Ñ Îß§Ï∂ú Ï∞®Ïù¥Í∞Ä ÏûàÎäî Îç∞Ïù¥ÌÑ∞:\")\n",
    "print(sales_mismatch)\n",
    "\n",
    "print(\"\\nÏöîÏùºÎ≥Ñ Îß§Ï∂ú Ï∞®Ïù¥Í∞Ä ÏûàÎäî Îç∞Ïù¥ÌÑ∞:\")\n",
    "print(weekly_sales_mismatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è Î∂ÑÍ∏∞Î≥Ñ Îß§Ï∂ú Ï¥ùÌï©Ïù¥ ÏõêÎ≥∏ Îç∞Ïù¥ÌÑ∞ÏôÄ Îã§Î¶ÖÎãàÎã§.\n",
      "      Í∏∞Ï§Ä_ÎÖÑÎ∂ÑÍ∏∞_ÏΩîÎìú            ÏÉÅÍ∂åÎ™Ö            Îß§Ï∂ú         ÏõêÎ≥∏_Îß§Ï∂ú          Îß§Ï∂úÏ∞®Ïù¥\n",
      "0         20191   4.19ÎØºÏ£ºÎ¨òÏßÄÏó≠ 2Î≤à  2.682584e+08  2.712070e+08 -2.948548e+06\n",
      "1         20191           63ÎπåÎî©  1.974116e+08  1.993332e+08 -1.921632e+06\n",
      "2         20191  DMC(ÎîîÏßÄÌÑ∏ÎØ∏ÎîîÏñ¥ÏãúÌã∞)  3.041191e+09  3.050783e+09 -9.592076e+06\n",
      "3         20191      GSÍ∞ïÎèôÏûêÏù¥ÏïÑÌååÌä∏  5.903896e+08  5.969977e+08 -6.608188e+06\n",
      "4         20191            GÌÉÄÏõå  2.215648e+08  2.236545e+08 -2.089705e+06\n",
      "...         ...            ...           ...           ...           ...\n",
      "27006     20232        Ìö®Ï∞ΩÎèôÏ£ºÎØºÏÑºÌÑ∞  2.378038e+08  2.363720e+08  1.431883e+06\n",
      "27007     20232        ÌõÑÏïîÎèôÏ£ºÎØºÏÑºÌÑ∞  7.537991e+08  7.495219e+08  4.277202e+06\n",
      "27008     20232           ÌõÑÏïîÏãúÏû•  7.540955e+08  7.495562e+08  4.539292e+06\n",
      "27009     20232        ÌúòÎ¨∏Í≥†ÍµêÏÇ¨Í±∞Î¶¨  9.547698e+09  9.546515e+09  1.182764e+06\n",
      "27010     20232           ÌùëÎ¶¨Îã®Í∏∏  1.141724e+09  1.137050e+09  4.674159e+06\n",
      "\n",
      "[11715 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ÌååÏùº Í≤ΩÎ°ú ÏÑ§Ï†ï\n",
    "original_file_path = r\"C:\\Users\\m\\Desktop\\Î®∏Ïã†Îü¨Îãù ÏÇ¨Ïö© Îç∞Ïù¥ÌÑ∞\\ÌîºÏ≤òÏóîÏßÄÎãàÏñ¥ÎßÅÌïúÌÜµÌï©Îç∞Ïù¥ÌÑ∞\\ÌîºÏ≤òÏóîÏßÄÎãàÏñ¥ÎßÅÏùºÎã®Îã§ÌïúÌÜµÌï©Îç∞Ïù¥ÌÑ∞.csv\"\n",
    "preprocessed_file_path = r\"C:\\Users\\m\\Desktop\\Î®∏Ïã†Îü¨Îãù ÏÇ¨Ïö© Îç∞Ïù¥ÌÑ∞\\ÌîºÏ≤òÏóîÏßÄÎãàÏñ¥ÎßÅÌïúÌÜµÌï©Îç∞Ïù¥ÌÑ∞\\ÏùºÎã®ÏúÑ_Îß§Ï∂ú_Ï∂îÏ†ïÏπò.csv\"\n",
    "\n",
    "# Îç∞Ïù¥ÌÑ∞ Î∂àÎü¨Ïò§Í∏∞\n",
    "original_df = pd.read_csv(original_file_path)\n",
    "preprocessed_df = pd.read_csv(preprocessed_file_path)\n",
    "\n",
    "# ÎÇ†Ïßú Ïª¨ÎüºÏùÑ datetime ÌòïÏãùÏúºÎ°ú Î≥ÄÌôò\n",
    "preprocessed_df[\"ÎÇ†Ïßú\"] = pd.to_datetime(preprocessed_df[\"ÎÇ†Ïßú\"])\n",
    "\n",
    "# Ï†ÑÏ≤òÎ¶¨ Îç∞Ïù¥ÌÑ∞ÏóêÏÑú Í∏∞Ï§Ä_ÎÖÑÎ∂ÑÍ∏∞_ÏΩîÎìú ÏÉùÏÑ±\n",
    "def get_quarter_code(date):\n",
    "    year = date.year\n",
    "    quarter = (date.month - 1) // 3 + 1\n",
    "    return f\"{year}{quarter}\"  # Î¨∏ÏûêÏó¥(str)Î°ú Î≥ÄÌôò\n",
    "\n",
    "preprocessed_df[\"Í∏∞Ï§Ä_ÎÖÑÎ∂ÑÍ∏∞_ÏΩîÎìú\"] = preprocessed_df[\"ÎÇ†Ïßú\"].apply(get_quarter_code)\n",
    "\n",
    "# üìå 1. Ï†ÑÏ≤òÎ¶¨Îêú Îç∞Ïù¥ÌÑ∞Ïùò Î∂ÑÍ∏∞Î≥Ñ Îß§Ï∂ú Ï¥ùÌï© Í≥ÑÏÇ∞\n",
    "quarter_sales = preprocessed_df.groupby([\"Í∏∞Ï§Ä_ÎÖÑÎ∂ÑÍ∏∞_ÏΩîÎìú\", \"ÏÉÅÍ∂åÎ™Ö\"])[\"Îß§Ï∂ú\"].sum().reset_index()\n",
    "\n",
    "# üìå 2. ÏõêÎ≥∏ Îç∞Ïù¥ÌÑ∞ÏóêÏÑú Î∂ÑÍ∏∞Î≥Ñ Îß§Ï∂úÏùÑ ÏßëÍ≥Ñ\n",
    "original_df[\"ÎãπÏõî_Îß§Ï∂ú_Í∏àÏï°\"] = original_df[[\"ÏõîÏöîÏùº_Îß§Ï∂ú_Í∏àÏï°\", \"ÌôîÏöîÏùº_Îß§Ï∂ú_Í∏àÏï°\", \"ÏàòÏöîÏùº_Îß§Ï∂ú_Í∏àÏï°\",\n",
    "                                          \"Î™©ÏöîÏùº_Îß§Ï∂ú_Í∏àÏï°\", \"Í∏àÏöîÏùº_Îß§Ï∂ú_Í∏àÏï°\", \"ÌÜ†ÏöîÏùº_Îß§Ï∂ú_Í∏àÏï°\", \"ÏùºÏöîÏùº_Îß§Ï∂ú_Í∏àÏï°\"]].sum(axis=1)\n",
    "\n",
    "original_quarter_sales = original_df.groupby([\"Í∏∞Ï§Ä_ÎÖÑÎ∂ÑÍ∏∞_ÏΩîÎìú\", \"ÏÉÅÍ∂å_ÏΩîÎìú_Î™Ö\"])[\"ÎãπÏõî_Îß§Ï∂ú_Í∏àÏï°\"].sum().reset_index()\n",
    "original_quarter_sales.rename(columns={\"ÏÉÅÍ∂å_ÏΩîÎìú_Î™Ö\": \"ÏÉÅÍ∂åÎ™Ö\", \"ÎãπÏõî_Îß§Ï∂ú_Í∏àÏï°\": \"ÏõêÎ≥∏_Îß§Ï∂ú\"}, inplace=True)\n",
    "\n",
    "# üìå üî• Îç∞Ïù¥ÌÑ∞ ÌÉÄÏûÖ ÎßûÏ∂îÍ∏∞ (Ï§ëÏöî!!)\n",
    "quarter_sales[\"Í∏∞Ï§Ä_ÎÖÑÎ∂ÑÍ∏∞_ÏΩîÎìú\"] = quarter_sales[\"Í∏∞Ï§Ä_ÎÖÑÎ∂ÑÍ∏∞_ÏΩîÎìú\"].astype(str)\n",
    "original_quarter_sales[\"Í∏∞Ï§Ä_ÎÖÑÎ∂ÑÍ∏∞_ÏΩîÎìú\"] = original_quarter_sales[\"Í∏∞Ï§Ä_ÎÖÑÎ∂ÑÍ∏∞_ÏΩîÎìú\"].astype(str)\n",
    "\n",
    "# üìå 3. Îç∞Ïù¥ÌÑ∞ Î≥ëÌï© ÌõÑ Ï∞®Ïù¥ ÌôïÏù∏\n",
    "merged_sales = quarter_sales.merge(original_quarter_sales, on=[\"Í∏∞Ï§Ä_ÎÖÑÎ∂ÑÍ∏∞_ÏΩîÎìú\", \"ÏÉÅÍ∂åÎ™Ö\"], how=\"left\")\n",
    "merged_sales[\"Îß§Ï∂úÏ∞®Ïù¥\"] = merged_sales[\"Îß§Ï∂ú\"] - merged_sales[\"ÏõêÎ≥∏_Îß§Ï∂ú\"]\n",
    "\n",
    "# üìå 4. Ï∞®Ïù¥Í∞Ä ÏûàÎäî Îç∞Ïù¥ÌÑ∞ Ï∂úÎ†•\n",
    "diff_sales = merged_sales[merged_sales[\"Îß§Ï∂úÏ∞®Ïù¥\"].abs() > 1e-3]\n",
    "if diff_sales.empty:\n",
    "    print(\"‚úÖ Î∂ÑÍ∏∞Î≥Ñ Îß§Ï∂ú Ï¥ùÌï©Ïù¥ ÏõêÎ≥∏ Îç∞Ïù¥ÌÑ∞ÏôÄ ÏùºÏπòÌï©ÎãàÎã§.\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Î∂ÑÍ∏∞Î≥Ñ Îß§Ï∂ú Ï¥ùÌï©Ïù¥ ÏõêÎ≥∏ Îç∞Ïù¥ÌÑ∞ÏôÄ Îã§Î¶ÖÎãàÎã§.\")\n",
    "    print(diff_sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä ÌèâÍ∑† Ïò§Ï∞® ÎπÑÏú®: -0.0067%\n",
      "üìä Ï§ëÏïôÍ∞í Ïò§Ï∞® ÎπÑÏú®: 0.0000%\n",
      "üìà ÏµúÎåÄ Ïò§Ï∞® ÎπÑÏú®: 35.2485%\n",
      "üìâ ÏµúÏÜå Ïò§Ï∞® ÎπÑÏú®: -7.6923%\n",
      "üìä ÌëúÏ§ÄÌé∏Ï∞®: 0.5703%\n",
      "‚ö†Ô∏è Ïò§Ï∞®Í∞Ä 5% Ïù¥ÏÉÅÏù∏ Îç∞Ïù¥ÌÑ∞ Í∞úÏàò: 10Í∞ú / 33021Í∞ú\n",
      "      Í∏∞Ï§Ä_ÎÖÑÎ∂ÑÍ∏∞_ÏΩîÎìú          ÏÉÅÍ∂åÎ™Ö            Îß§Ï∂ú         ÏõêÎ≥∏_Îß§Ï∂ú          Îß§Ï∂úÏ∞®Ïù¥  \\\n",
      "1292      20191     Ï§ëÍ≥°1ÎèôÏ£ºÎØºÏÑºÌÑ∞  1.675343e+05  1.814955e+05 -1.396119e+04   \n",
      "1648      20192        Í¥ëÏßÑÍ≤ΩÏ∞∞ÏÑú  3.737195e+06  2.763206e+06  9.739897e+05   \n",
      "2792      20192     Ï§ëÍ≥°1ÎèôÏ£ºÎØºÏÑºÌÑ∞  2.045314e+05  1.905702e+05  1.396119e+04   \n",
      "2933      20192       ÌóåÏù∏Í∞ÄÍµ¨Îã®ÏßÄ  6.756818e+05  6.281701e+05  4.751168e+04   \n",
      "2938      20192        ÌôçÎÇ®ÍµêÎÇ®Ï∏°  2.152892e+07  2.037803e+07  1.150888e+06   \n",
      "20209     20222        ÏÉàÏÑùÍ¥ÄÏãúÏû•  1.429342e+06  1.317718e+06  1.116237e+05   \n",
      "25574     20232      Í∞úÎØ∏Ïñ¥Î¶∞Ïù¥Í≥µÏõê  7.173754e+06  5.593344e+06  1.580410e+06   \n",
      "26279     20232        ÏÑúÏ¥àÏÜåÎ∞©ÏÑú  1.914530e+06  1.777778e+06  1.367521e+05   \n",
      "26442     20232       Ïã†Î¶ºÏó≠ 1Î≤à  1.068046e+06  8.136818e+05  2.543644e+05   \n",
      "26678     20232  Ïö∞Ïû•ÏÇ∞Î°ØÎç∞Ï∫êÏä¨ÏïÑÌååÌä∏Ïïû  9.617592e+07  8.788174e+07  8.294184e+06   \n",
      "\n",
      "         Ïò§Ï∞®ÎπÑÏú®(%)  \n",
      "1292   -7.692308  \n",
      "1648   35.248540  \n",
      "2792    7.326008  \n",
      "2933    7.563506  \n",
      "2938    5.647688  \n",
      "20209   8.470988  \n",
      "25574  28.255190  \n",
      "26279   7.692308  \n",
      "26442  31.260912  \n",
      "26678   9.437892  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# üìå Îß§Ï∂ú ÎåÄÎπÑ Ïò§Ï∞® ÎπÑÏú®(%) Í≥ÑÏÇ∞\n",
    "merged_sales[\"Ïò§Ï∞®ÎπÑÏú®(%)\"] = (merged_sales[\"Îß§Ï∂úÏ∞®Ïù¥\"] / merged_sales[\"ÏõêÎ≥∏_Îß§Ï∂ú\"]) * 100\n",
    "\n",
    "# üìä Ï†ÑÏ≤¥ ÌèâÍ∑† Ïò§Ï∞® ÎπÑÏú®\n",
    "mean_error = merged_sales[\"Ïò§Ï∞®ÎπÑÏú®(%)\"].mean()\n",
    "median_error = merged_sales[\"Ïò§Ï∞®ÎπÑÏú®(%)\"].median()\n",
    "max_error = merged_sales[\"Ïò§Ï∞®ÎπÑÏú®(%)\"].max()\n",
    "min_error = merged_sales[\"Ïò§Ï∞®ÎπÑÏú®(%)\"].min()\n",
    "std_dev = merged_sales[\"Ïò§Ï∞®ÎπÑÏú®(%)\"].std()\n",
    "\n",
    "# ‚ö†Ô∏è Ïò§Ï∞®Í∞Ä ÌÅ∞ ÏÉÅÍ∂å ÌôïÏù∏ (Ï†àÎåÄÍ∞í Í∏∞Ï§Ä 5% Ïù¥ÏÉÅ)\n",
    "large_errors = merged_sales[merged_sales[\"Ïò§Ï∞®ÎπÑÏú®(%)\"].abs() > 5]\n",
    "\n",
    "print(f\"üìä ÌèâÍ∑† Ïò§Ï∞® ÎπÑÏú®: {mean_error:.4f}%\")\n",
    "print(f\"üìä Ï§ëÏïôÍ∞í Ïò§Ï∞® ÎπÑÏú®: {median_error:.4f}%\")\n",
    "print(f\"üìà ÏµúÎåÄ Ïò§Ï∞® ÎπÑÏú®: {max_error:.4f}%\")\n",
    "print(f\"üìâ ÏµúÏÜå Ïò§Ï∞® ÎπÑÏú®: {min_error:.4f}%\")\n",
    "print(f\"üìä ÌëúÏ§ÄÌé∏Ï∞®: {std_dev:.4f}%\")\n",
    "print(f\"‚ö†Ô∏è Ïò§Ï∞®Í∞Ä 5% Ïù¥ÏÉÅÏù∏ Îç∞Ïù¥ÌÑ∞ Í∞úÏàò: {len(large_errors)}Í∞ú / {len(merged_sales)}Í∞ú\")\n",
    "\n",
    "# üìå Ïò§Ï∞®Í∞Ä ÌÅ∞ ÏÉÅÍ∂å ÏÉÅÏúÑ 10Í∞ú Ï∂úÎ†•\n",
    "print(large_errors.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ïª¨ÎüºÎ™Ö: Index(['ÎÇ†Ïßú', 'ÏöîÏùº', 'ÏÉÅÍ∂åÎ™Ö', 'Îß§Ï∂ú'], dtype='object')\n",
      "\n",
      "Îç∞Ïù¥ÌÑ∞ ÎÇ¥Ïö©:\n",
      "           ÎÇ†Ïßú         ÏöîÏùº  ÏÉÅÍ∂åÎ™Ö             Îß§Ï∂ú\n",
      "0  2019-01-01    Tuesday  ÎÖ∏ÏõêÏó≠  542866.435897\n",
      "1  2019-01-02  Wednesday  ÎÖ∏ÏõêÏó≠  329470.337607\n",
      "2  2019-01-03   Thursday  ÎÖ∏ÏõêÏó≠  591216.192308\n",
      "3  2019-01-04     Friday  ÎÖ∏ÏõêÏó≠  344147.508547\n",
      "4  2019-01-05   Saturday  ÎÖ∏ÏõêÏó≠  255746.397436\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ÌååÏùº Í≤ΩÎ°úÎ•º Î≥ÄÏàòÏóê Ï†ÄÏû•Ìï©ÎãàÎã§.\n",
    "file_path = r\"C:\\Users\\m\\Desktop\\Î®∏Ïã†Îü¨Îãù ÏÇ¨Ïö© Îç∞Ïù¥ÌÑ∞\\ÌîºÏ≤òÏóîÏßÄÎãàÏñ¥ÎßÅÌïúÌÜµÌï©Îç∞Ïù¥ÌÑ∞\\ÏùºÎã®ÏúÑ_Îß§Ï∂ú_Ï∂îÏ†ïÏπò.csv\"\n",
    "\n",
    "# pandasÎ•º ÏÇ¨Ïö©ÌïòÏó¨ CSV ÌååÏùºÏùÑ ÏùΩÏñ¥ÏòµÎãàÎã§.\n",
    "try:\n",
    "    df = pd.read_csv(file_path)\n",
    "    # Ïª¨ÎüºÎ™ÖÏùÑ Ï∂úÎ†•Ìï©ÎãàÎã§.\n",
    "    print(\"Ïª¨ÎüºÎ™Ö:\", df.columns)\n",
    "    # Îç∞Ïù¥ÌÑ∞ ÎÇ¥Ïö©ÏùÑ Ï∂úÎ†•Ìï©ÎãàÎã§. (Ï≤òÏùå 5Í∞ú ÌñâÎßå Ï∂úÎ†•)\n",
    "    print(\"\\nÎç∞Ïù¥ÌÑ∞ ÎÇ¥Ïö©:\")\n",
    "    print(df.head())\n",
    "except FileNotFoundError:\n",
    "    print(f\"ÌååÏùºÏùÑ Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§: {file_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"ÌååÏùºÏùÑ ÏùΩÎäî ÎèôÏïà Ïò§Î•òÍ∞Ä Î∞úÏÉùÌñàÏäµÎãàÎã§: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\m\\anaconda3\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 50836 (\\N{HANGUL SYLLABLE YO}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "c:\\Users\\m\\anaconda3\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 51068 (\\N{HANGUL SYLLABLE IL}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "c:\\Users\\m\\anaconda3\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 48324 (\\N{HANGUL SYLLABLE BYEOL}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "c:\\Users\\m\\anaconda3\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 47588 (\\N{HANGUL SYLLABLE MAE}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "c:\\Users\\m\\anaconda3\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 52636 (\\N{HANGUL SYLLABLE CUL}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "c:\\Users\\m\\anaconda3\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 48708 (\\N{HANGUL SYLLABLE BI}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "c:\\Users\\m\\anaconda3\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 50984 (\\N{HANGUL SYLLABLE YUL}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "c:\\Users\\m\\anaconda3\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 44368 (\\N{HANGUL SYLLABLE GYO}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "c:\\Users\\m\\anaconda3\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 50900 (\\N{HANGUL SYLLABLE WEOL}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "c:\\Users\\m\\anaconda3\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 44552 (\\N{HANGUL SYLLABLE GEUM}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "c:\\Users\\m\\anaconda3\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 50529 (\\N{HANGUL SYLLABLE AEG}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "c:\\Users\\m\\anaconda3\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 54868 (\\N{HANGUL SYLLABLE HWA}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "c:\\Users\\m\\anaconda3\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 49688 (\\N{HANGUL SYLLABLE SU}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "c:\\Users\\m\\anaconda3\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 47785 (\\N{HANGUL SYLLABLE MOG}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "c:\\Users\\m\\anaconda3\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 53664 (\\N{HANGUL SYLLABLE TO}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "c:\\Users\\m\\anaconda3\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 50896 (\\N{HANGUL SYLLABLE WEON}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "c:\\Users\\m\\anaconda3\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 48376 (\\N{HANGUL SYLLABLE BON}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "c:\\Users\\m\\anaconda3\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 45936 (\\N{HANGUL SYLLABLE DE}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "c:\\Users\\m\\anaconda3\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 51060 (\\N{HANGUL SYLLABLE I}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "c:\\Users\\m\\anaconda3\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 53552 (\\N{HANGUL SYLLABLE TEO}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "c:\\Users\\m\\anaconda3\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 49373 (\\N{HANGUL SYLLABLE SAENG}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "c:\\Users\\m\\anaconda3\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 49457 (\\N{HANGUL SYLLABLE SEONG}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ÏöîÏùºÎ≥Ñ Îß§Ï∂ú ÎπÑÏú® MSE: 0.0006747959118144538\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# ÌååÏùº Í≤ΩÎ°ú ÏÑ§Ï†ï\n",
    "original_file = r\"C:\\Users\\m\\Desktop\\Î®∏Ïã†Îü¨Îãù ÏÇ¨Ïö© Îç∞Ïù¥ÌÑ∞\\ÌîºÏ≤òÏóîÏßÄÎãàÏñ¥ÎßÅÌïúÌÜµÌï©Îç∞Ïù¥ÌÑ∞\\ÌîºÏ≤òÏóîÏßÄÎãàÏñ¥ÎßÅÏùºÎã®Îã§ÌïúÌÜµÌï©Îç∞Ïù¥ÌÑ∞.csv\"\n",
    "generated_file = r\"C:\\Users\\m\\Desktop\\Î®∏Ïã†Îü¨Îãù ÏÇ¨Ïö© Îç∞Ïù¥ÌÑ∞\\ÌîºÏ≤òÏóîÏßÄÎãàÏñ¥ÎßÅÌïúÌÜµÌï©Îç∞Ïù¥ÌÑ∞\\ÏùºÎã®ÏúÑ_Îß§Ï∂ú_Ï∂îÏ†ïÏπò.csv\"\n",
    "\n",
    "# Îç∞Ïù¥ÌÑ∞ Î°úÎìú\n",
    "original_df = pd.read_csv(original_file)\n",
    "generated_df = pd.read_csv(generated_file)\n",
    "\n",
    "# ÏõêÎ≥∏ Îç∞Ïù¥ÌÑ∞ ÏöîÏùºÎ≥Ñ Îß§Ï∂ú ÎπÑÏú® Í≥ÑÏÇ∞\n",
    "original_sales = original_df[['ÏõîÏöîÏùº_Îß§Ï∂ú_Í∏àÏï°', 'ÌôîÏöîÏùº_Îß§Ï∂ú_Í∏àÏï°', 'ÏàòÏöîÏùº_Îß§Ï∂ú_Í∏àÏï°',\n",
    "                               'Î™©ÏöîÏùº_Îß§Ï∂ú_Í∏àÏï°', 'Í∏àÏöîÏùº_Îß§Ï∂ú_Í∏àÏï°', 'ÌÜ†ÏöîÏùº_Îß§Ï∂ú_Í∏àÏï°', 'ÏùºÏöîÏùº_Îß§Ï∂ú_Í∏àÏï°']].sum()\n",
    "original_ratio = original_sales / original_sales.sum()\n",
    "\n",
    "# ÏöîÏùº Îß§Ìïë\n",
    "day_mapping = {\n",
    "    \"Monday\": \"ÏõîÏöîÏùº_Îß§Ï∂ú_Í∏àÏï°\",\n",
    "    \"Tuesday\": \"ÌôîÏöîÏùº_Îß§Ï∂ú_Í∏àÏï°\",\n",
    "    \"Wednesday\": \"ÏàòÏöîÏùº_Îß§Ï∂ú_Í∏àÏï°\",\n",
    "    \"Thursday\": \"Î™©ÏöîÏùº_Îß§Ï∂ú_Í∏àÏï°\",\n",
    "    \"Friday\": \"Í∏àÏöîÏùº_Îß§Ï∂ú_Í∏àÏï°\",\n",
    "    \"Saturday\": \"ÌÜ†ÏöîÏùº_Îß§Ï∂ú_Í∏àÏï°\",\n",
    "    \"Sunday\": \"ÏùºÏöîÏùº_Îß§Ï∂ú_Í∏àÏï°\"\n",
    "}\n",
    "\n",
    "# ÏöîÏùº Îß§Ìïë Ï†ÅÏö©\n",
    "generated_df['ÏöîÏùº'] = generated_df['ÏöîÏùº'].map(day_mapping)\n",
    "\n",
    "# ÏöîÏùºÎ≥Ñ Îß§Ï∂ú Ìï© Í≥ÑÏÇ∞\n",
    "generated_ratio = generated_df.groupby('ÏöîÏùº')['Îß§Ï∂ú'].sum()\n",
    "generated_ratio /= generated_ratio.sum()\n",
    "\n",
    "# ÎπÑÏú® ÎπÑÍµê ÏãúÍ∞ÅÌôî\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(original_ratio.index, original_ratio.values, alpha=0.6, label='ÏõêÎ≥∏ Îç∞Ïù¥ÌÑ∞')\n",
    "plt.bar(generated_ratio.index, generated_ratio.values, alpha=0.6, label='ÏÉùÏÑ± Îç∞Ïù¥ÌÑ∞')\n",
    "plt.title(\"ÏöîÏùºÎ≥Ñ Îß§Ï∂ú ÎπÑÏú® ÎπÑÍµê\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# MSE Í≥ÑÏÇ∞\n",
    "common_days = list(set(original_ratio.index) & set(generated_ratio.index))\n",
    "mse = mean_squared_error(original_ratio.loc[common_days].values, generated_ratio.loc[common_days].values)\n",
    "print(f\"ÏöîÏùºÎ≥Ñ Îß§Ï∂ú ÎπÑÏú® MSE: {mse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Í≤ÄÏ¶ùÍ≤∞Í≥º\n",
    "\n",
    "üìä ÌèâÍ∞Ä:\n",
    "ÌèâÍ∑† Ïò§Ï∞® ÎπÑÏú®: -0.0067% ‚Üí Ï†ÑÎ∞òÏ†ÅÏúºÎ°ú ÏõêÎ≥∏ Îç∞Ïù¥ÌÑ∞ÏôÄ Í±∞Ïùò ÏùºÏπòÌïòÎäî ÏàòÏ§ÄÏûÑ.\n",
    "Ï§ëÏïôÍ∞í Ïò§Ï∞® ÎπÑÏú®: 0.0000% ‚Üí ÎåÄÎ∂ÄÎ∂ÑÏùò ÏÉÅÍ∂åÏóêÏÑúÎäî ÌÅ∞ Ï∞®Ïù¥Í∞Ä ÏóÜÏùå.\n",
    "ÌëúÏ§ÄÌé∏Ï∞®: 0.5703% ‚Üí Ïò§Ï∞®Í∞Ä Ï†ÑÏ≤¥Ï†ÅÏúºÎ°ú ÏïàÏ†ïÏ†ÅÏù∏ Ìé∏.\n",
    "Ïò§Ï∞® 5% Ïù¥ÏÉÅÏù∏ Îç∞Ïù¥ÌÑ∞ Í∞úÏàò: 10Í∞ú / 33,021Í∞ú ‚Üí ÏïΩ 0.03% ÏàòÏ§ÄÏù¥ÎØÄÎ°ú Î¨¥ÏãúÌï¥ÎèÑ Îê† Ï†ïÎèÑ.\n",
    "\n",
    "üìà Ï£ºÎ™©Ìï¥Ïïº Ìï† Ï†ê:\n",
    "ÏùºÎ∂Ä ÏµúÎåÄ Ïò§Ï∞®(35.25%) Î∞è ÏµúÏÜå Ïò§Ï∞®(-7.69%) Î∞úÏÉùÌïú Í≤ΩÏö∞Í∞Ä ÏûàÏùå.\n",
    "ÌäπÌûà, Í¥ëÏßÑÍ≤ΩÏ∞∞ÏÑú(35.25%), Í∞úÎØ∏Ïñ¥Î¶∞Ïù¥Í≥µÏõê(28.26%), Ïã†Î¶ºÏó≠ 1Î≤à(31.26%) Îì±Ïùò Ïò§Ï∞®Ïú®Ïù¥ ÎÜíÏùÄ Í≤ΩÏö∞Îäî ÏõêÏù∏ Î∂ÑÏÑùÏù¥ ÌïÑÏöî.\n",
    "Ïò§Ï∞®Í∞Ä ÌÅ∞ Îç∞Ïù¥ÌÑ∞Í∞Ä ÌäπÏ†ï ÏßÄÏó≠Ïóê ÏßëÏ§ëÎêòÏñ¥ ÏûàÎã§Î©¥, ÌäπÏ†ï ÏÉÅÍ∂åÏùò Îç∞Ïù¥ÌÑ∞ Ï≤òÎ¶¨ Í≥ºÏ†ïÏóêÏÑú Î¨∏Ï†úÍ∞Ä Î∞úÏÉùÌñàÏùÑ Í∞ÄÎä•ÏÑ±Ïù¥ ÏûàÏùå.\n",
    "\n",
    "‚úÖ Í≤∞Î°†:\n",
    "Ï†ÑÏ≤¥Ï†ÅÏúºÎ°ú ÏñëÌò∏Ìïú ÏàòÏ§ÄÏúºÎ°ú Î≥¥ÏûÑ.\n",
    "Îã§Îßå, Ïò§Ï∞®Í∞Ä ÌÅ∞ ÏùºÎ∂Ä ÏÉÅÍ∂å(Ïò§Ï∞®Ïú® 10% Ïù¥ÏÉÅ)ÏùÄ Í≤ÄÌÜ†ÌïòÎäî Í≤ÉÏù¥ Ï¢ãÏùå.\n",
    "‚Üí ÏõêÎ≥∏ Îç∞Ïù¥ÌÑ∞ÏôÄ ÎπÑÍµêÌïòÏó¨ Ï†ÑÏ≤òÎ¶¨ Í≥ºÏ†ïÏóêÏÑú ÏÜêÏã§Ïù¥ Î∞úÏÉùÌñàÎäîÏßÄ ÌôïÏù∏Ìï¥Î≥¥Îäî Í≤ÉÏù¥ ÌïÑÏöî.\n",
    "Í∑∏ÎûòÎèÑ Ï†ÑÏ≤¥ Îç∞Ïù¥ÌÑ∞Ïùò 99.97% Ïù¥ÏÉÅÏù¥ Îß§Ïö∞ ÏûëÏùÄ Ïò§Ï∞® Î≤îÏúÑ ÎÇ¥Ïóê ÏûàÏúºÎØÄÎ°ú Ïã§Î¨¥Ï†ÅÏúºÎ°ú ÌÅ∞ Î¨∏Ï†úÎäî ÏïÑÎãò."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Í≥ÑÏÇ∞ Î∞©Ïãù Í∞úÏÑ† ÏΩîÎìú(Îã®ÏàúÌûà Î∂ÑÍ∏∞Î•º 13ÏúºÎ°ú ÎÇòÎàÑÎäî Í≤ÉÏù¥ ÏïÑÎãàÎùº Î∂ÑÍ∏∞Î≥Ñ Ïã§Ï†ú ÎÇ†ÏßúÏàòÏôÄ ÏöîÏùºÏàòÎ•º ÌôïÏù∏ÌïòÍ≥† Ïù¥Î•º Î∞òÏòÅÌïòÏó¨ Í≥ÑÏÇ∞, ÏÉÅÍ∂åÎßå Í≥†Î†§ÌïòÎäî Í≤ÉÏù¥ ÏïÑÎãàÎùº ÏóÖÏ¢ÖÍπåÏßÄ Í≥†Î†§ÌïòÏó¨ ÌïôÏäµ, Í≥ÑÏÇ∞)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 56\u001b[0m\n\u001b[0;32m     50\u001b[0m         weekday \u001b[38;5;241m=\u001b[39m date\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mA\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     51\u001b[0m         sales_value \u001b[38;5;241m=\u001b[39m weekday_sales_map[weekday] \u001b[38;5;241m/\u001b[39m quarter_dates[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mÏöîÏùº\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalue_counts()[weekday]\n\u001b[0;32m     52\u001b[0m         daily_sales_list\u001b[38;5;241m.\u001b[39mappend({\n\u001b[0;32m     53\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mÎÇ†Ïßú\u001b[39m\u001b[38;5;124m'\u001b[39m: date,\n\u001b[0;32m     54\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mÏöîÏùº\u001b[39m\u001b[38;5;124m'\u001b[39m: weekday,\n\u001b[0;32m     55\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mÏÉÅÍ∂åÎ™Ö\u001b[39m\u001b[38;5;124m'\u001b[39m: row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mÏÉÅÍ∂å_ÏΩîÎìú_Î™Ö\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m---> 56\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mÏóÖÏ¢Ö\u001b[39m\u001b[38;5;124m'\u001b[39m: row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mÏÑúÎπÑÏä§_ÏóÖÏ¢Ö_ÏΩîÎìú_Î™Ö\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     57\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mÎß§Ï∂ú\u001b[39m\u001b[38;5;124m'\u001b[39m: sales_value\n\u001b[0;32m     58\u001b[0m         })\n\u001b[0;32m     60\u001b[0m \u001b[38;5;66;03m# Îç∞Ïù¥ÌÑ∞ÌîÑÎ†àÏûÑ Î≥ÄÌôò\u001b[39;00m\n\u001b[0;32m     61\u001b[0m daily_sales_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(daily_sales_list)\n",
      "File \u001b[1;32mc:\\Users\\m\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py:1121\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[0;32m   1120\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[1;32m-> 1121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_value(key)\n\u001b[0;32m   1123\u001b[0m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[0;32m   1124\u001b[0m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[0;32m   1125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
      "File \u001b[1;32mc:\\Users\\m\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py:1237\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m   1234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[0;32m   1236\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[1;32m-> 1237\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mget_loc(label)\n\u001b[0;32m   1239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[0;32m   1240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[loc]\n",
      "File \u001b[1;32mc:\\Users\\m\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3777\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3772\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m other, result_name\n\u001b[0;32m   3774\u001b[0m \u001b[38;5;66;03m# --------------------------------------------------------------------\u001b[39;00m\n\u001b[0;32m   3775\u001b[0m \u001b[38;5;66;03m# Indexing Methods\u001b[39;00m\n\u001b[1;32m-> 3777\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_loc\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[0;32m   3778\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   3779\u001b[0m \u001b[38;5;124;03m    Get integer location, slice or boolean mask for requested label.\u001b[39;00m\n\u001b[0;32m   3780\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3801\u001b[0m \u001b[38;5;124;03m    array([False,  True, False,  True])\u001b[39;00m\n\u001b[0;32m   3802\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   3803\u001b[0m     casted_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_cast_indexer(key)\n",
      "File \u001b[1;32mc:\\Users\\m\\anaconda3\\Lib\\site-packages\\debugpy\\_vendored\\pydevd\\_pydevd_bundle\\pydevd_trace_dispatch_regular.py:326\u001b[0m, in \u001b[0;36mThreadTracer.__call__\u001b[1;34m(self, frame, event, arg)\u001b[0m\n\u001b[0;32m    323\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_args \u001b[38;5;241m=\u001b[39m args\n\u001b[0;32m    324\u001b[0m \u001b[38;5;66;03m# ENDIF\u001b[39;00m\n\u001b[1;32m--> 326\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, frame, event, arg):\n\u001b[0;32m    327\u001b[0m \u001b[38;5;250m        \u001b[39m\u001b[38;5;124;03m''' This is the callback used when we enter some context in the debugger.\u001b[39;00m\n\u001b[0;32m    328\u001b[0m \n\u001b[0;32m    329\u001b[0m \u001b[38;5;124;03m        We also decorate the thread we are in with info about the debugging.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    337\u001b[0m \u001b[38;5;124;03m            This is the global debugger (this method should actually be added as a method to it).\u001b[39;00m\n\u001b[0;32m    338\u001b[0m \u001b[38;5;124;03m        '''\u001b[39;00m\n\u001b[0;32m    339\u001b[0m         \u001b[38;5;66;03m# IFDEF CYTHON\u001b[39;00m\n\u001b[0;32m    340\u001b[0m         \u001b[38;5;66;03m# cdef str filename;\u001b[39;00m\n\u001b[0;32m    341\u001b[0m         \u001b[38;5;66;03m# cdef str base;\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    350\u001b[0m         \u001b[38;5;66;03m# DEBUG = 'code_to_debug' in frame.f_code.co_filename\u001b[39;00m\n\u001b[0;32m    351\u001b[0m         \u001b[38;5;66;03m# if DEBUG: print('ENTER: trace_dispatch: %s %s %s %s' % (frame.f_code.co_filename, frame.f_lineno, event, frame.f_code.co_name))\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from prophet import Prophet\n",
    "import numpy as np\n",
    "\n",
    "# ÌååÏùº Í≤ΩÎ°ú ÏÑ§Ï†ï\n",
    "file_path = r\"C:\\Users\\m\\Desktop\\Î®∏Ïã†Îü¨Îãù ÏÇ¨Ïö© Îç∞Ïù¥ÌÑ∞\\ÌîºÏ≤òÏóîÏßÄÎãàÏñ¥ÎßÅÌïúÌÜµÌï©Îç∞Ïù¥ÌÑ∞\\ÌîºÏ≤òÏóîÏßÄÎãàÏñ¥ÎßÅÏùºÎã®Îã§ÌïúÌÜµÌï©Îç∞Ïù¥ÌÑ∞.csv\"\n",
    "\n",
    "# Îç∞Ïù¥ÌÑ∞ Î°úÎìú\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# ÌïÑÏöîÌïú ÏπºÎüº ÏÑ†ÌÉù\n",
    "df = df[['Í∏∞Ï§Ä_ÎÖÑÎ∂ÑÍ∏∞_ÏΩîÎìú', 'ÏÉÅÍ∂å_ÏΩîÎìú_Î™Ö', 'ÏÑúÎπÑÏä§_ÏóÖÏ¢Ö_ÏΩîÎìú_Î™Ö', \n",
    "          'ÏõîÏöîÏùº_Îß§Ï∂ú_Í∏àÏï°', 'ÌôîÏöîÏùº_Îß§Ï∂ú_Í∏àÏï°', 'ÏàòÏöîÏùº_Îß§Ï∂ú_Í∏àÏï°', \n",
    "          'Î™©ÏöîÏùº_Îß§Ï∂ú_Í∏àÏï°', 'Í∏àÏöîÏùº_Îß§Ï∂ú_Í∏àÏï°', 'ÌÜ†ÏöîÏùº_Îß§Ï∂ú_Í∏àÏï°', 'ÏùºÏöîÏùº_Îß§Ï∂ú_Í∏àÏï°']]\n",
    "\n",
    "# Í∏∞Ï§Ä_ÎÖÑÎ∂ÑÍ∏∞_ÏΩîÎìúÎ•º ÎÇ†ÏßúÎ°ú Î≥ÄÌôò (Í∞Å Î∂ÑÍ∏∞Ïùò Ï≤´ Î≤àÏß∏ ÎÇ†)\n",
    "def convert_quarter_to_date(quarter_code):\n",
    "    year = int(str(quarter_code)[:4])\n",
    "    quarter = int(str(quarter_code)[4:])\n",
    "    month = {1: '01', 2: '04', 3: '07', 4: '10'}[quarter]\n",
    "    return f\"{year}-{month}-01\"\n",
    "\n",
    "df['ÎÇ†Ïßú'] = df['Í∏∞Ï§Ä_ÎÖÑÎ∂ÑÍ∏∞_ÏΩîÎìú'].apply(convert_quarter_to_date)\n",
    "df['ÎÇ†Ïßú'] = pd.to_datetime(df['ÎÇ†Ïßú'])\n",
    "\n",
    "# Î∂ÑÍ∏∞Î≥Ñ Ïã§Ï†ú ÎÇ†Ïßú Ïàò Í≥ÑÏÇ∞\n",
    "start_date = pd.to_datetime(\"2019-01-01\")\n",
    "end_date = pd.to_datetime(\"2024-06-30\")\n",
    "\n",
    "# Ï†ÑÏ≤¥ ÎÇ†Ïßú Î≤îÏúÑ Îç∞Ïù¥ÌÑ∞ÌîÑÎ†àÏûÑ ÏÉùÏÑ±\n",
    "date_range = pd.date_range(start=start_date, end=end_date, freq='D')\n",
    "date_info_df = pd.DataFrame({'ÎÇ†Ïßú': date_range})\n",
    "date_info_df['ÏöîÏùº'] = date_info_df['ÎÇ†Ïßú'].dt.strftime('%A')\n",
    "\n",
    "# ÏõêÎ≥∏ Îç∞Ïù¥ÌÑ∞ÏôÄ ÎÇ†Ïßú Î≤îÏúÑ Îç∞Ïù¥ÌÑ∞ÌîÑÎ†àÏûÑ Î≥ëÌï©\n",
    "daily_sales_list = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    base_date = row['ÎÇ†Ïßú']\n",
    "    quarter_mask = (date_info_df['ÎÇ†Ïßú'] >= base_date) & (date_info_df['ÎÇ†Ïßú'] < base_date + pd.DateOffset(months=3))\n",
    "    quarter_dates = date_info_df[quarter_mask]\n",
    "\n",
    "    sales_values = [row['ÏõîÏöîÏùº_Îß§Ï∂ú_Í∏àÏï°'], row['ÌôîÏöîÏùº_Îß§Ï∂ú_Í∏àÏï°'], row['ÏàòÏöîÏùº_Îß§Ï∂ú_Í∏àÏï°'],\n",
    "                     row['Î™©ÏöîÏùº_Îß§Ï∂ú_Í∏àÏï°'], row['Í∏àÏöîÏùº_Îß§Ï∂ú_Í∏àÏï°'], row['ÌÜ†ÏöîÏùº_Îß§Ï∂ú_Í∏àÏï°'], row['ÏùºÏöîÏùº_Îß§Ï∂ú_Í∏àÏï°']]\n",
    "\n",
    "    # ÏöîÏùºÎ≥Ñ Îß§Ï∂ú Îß§Ìïë\n",
    "    weekday_sales_map = dict(zip(['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'], sales_values))\n",
    "\n",
    "    for date in quarter_dates['ÎÇ†Ïßú']:\n",
    "        weekday = date.strftime('%A')\n",
    "        sales_value = weekday_sales_map[weekday] / quarter_dates['ÏöîÏùº'].value_counts()[weekday]\n",
    "        daily_sales_list.append({\n",
    "            'ÎÇ†Ïßú': date,\n",
    "            'ÏöîÏùº': weekday,\n",
    "            'ÏÉÅÍ∂åÎ™Ö': row['ÏÉÅÍ∂å_ÏΩîÎìú_Î™Ö'],\n",
    "            'ÏóÖÏ¢Ö': row['ÏÑúÎπÑÏä§_ÏóÖÏ¢Ö_ÏΩîÎìú_Î™Ö'],\n",
    "            'Îß§Ï∂ú': sales_value\n",
    "        })\n",
    "\n",
    "# Îç∞Ïù¥ÌÑ∞ÌîÑÎ†àÏûÑ Î≥ÄÌôò\n",
    "daily_sales_df = pd.DataFrame(daily_sales_list)\n",
    "\n",
    "# Prophet Î™®Îç∏ÎßÅ Î∞è Í≤∞Í≥º ÏòàÏ∏°\n",
    "prophet_results = []\n",
    "\n",
    "for (district, industry), group in daily_sales_df.groupby(['ÏÉÅÍ∂åÎ™Ö', 'ÏóÖÏ¢Ö']):\n",
    "    prophet_df = group[['ÎÇ†Ïßú', 'Îß§Ï∂ú']].rename(columns={'ÎÇ†Ïßú': 'ds', 'Îß§Ï∂ú': 'y'})\n",
    "    model = Prophet()\n",
    "    model.fit(prophet_df)\n",
    "\n",
    "    future = model.make_future_dataframe(periods=90)  # Ìñ•ÌõÑ 90Ïùº ÏòàÏ∏°\n",
    "    forecast = model.predict(future)\n",
    "\n",
    "    forecast = forecast[['ds', 'yhat']].rename(columns={'ds': 'ÎÇ†Ïßú', 'yhat': 'ÏòàÏ∏°_Îß§Ï∂ú'})\n",
    "    forecast['ÏÉÅÍ∂åÎ™Ö'] = district\n",
    "    forecast['ÏóÖÏ¢Ö'] = industry\n",
    "    prophet_results.append(forecast)\n",
    "\n",
    "# ÏòàÏ∏° Í≤∞Í≥º Îç∞Ïù¥ÌÑ∞ÌîÑÎ†àÏûÑÏúºÎ°ú Î≥ÄÌôò\n",
    "forecast_df = pd.concat(prophet_results)\n",
    "\n",
    "# Í≤∞Í≥º Ï†ÄÏû•\n",
    "output_file = r\"C:\\Users\\m\\Desktop\\Î®∏Ïã†Îü¨Îãù ÏÇ¨Ïö© Îç∞Ïù¥ÌÑ∞\\ÌîºÏ≤òÏóîÏßÄÎãàÏñ¥ÎßÅÌïúÌÜµÌï©Îç∞Ïù¥ÌÑ∞\\Prophet_ÏòàÏ∏°_Í≤∞Í≥º.csv\"\n",
    "forecast_df.to_csv(output_file, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(\"Prophet Î™®Îç∏ÎßÅ Î∞è Îç∞Ïù¥ÌÑ∞ Ï†ÄÏû•Ïù¥ ÏôÑÎ£åÎêòÏóàÏäµÎãàÎã§.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Requirement already satisfied: prophet in c:\\users\\m\\anaconda3\\lib\\site-packages (1.1.6)\n",
      "Requirement already satisfied: cmdstanpy>=1.0.4 in c:\\users\\m\\anaconda3\\lib\\site-packages (from prophet) (1.2.5)\n",
      "Requirement already satisfied: numpy>=1.15.4 in c:\\users\\m\\anaconda3\\lib\\site-packages (from prophet) (1.26.4)\n",
      "Requirement already satisfied: matplotlib>=2.0.0 in c:\\users\\m\\anaconda3\\lib\\site-packages (from prophet) (3.9.2)\n",
      "Requirement already satisfied: pandas>=1.0.4 in c:\\users\\m\\anaconda3\\lib\\site-packages (from prophet) (2.2.2)\n",
      "Requirement already satisfied: holidays<1,>=0.25 in c:\\users\\m\\anaconda3\\lib\\site-packages (from prophet) (0.66)\n",
      "Requirement already satisfied: tqdm>=4.36.1 in c:\\users\\m\\anaconda3\\lib\\site-packages (from prophet) (4.66.5)\n",
      "Requirement already satisfied: importlib-resources in c:\\users\\m\\anaconda3\\lib\\site-packages (from prophet) (6.5.2)\n",
      "Requirement already satisfied: stanio<2.0.0,>=0.4.0 in c:\\users\\m\\anaconda3\\lib\\site-packages (from cmdstanpy>=1.0.4->prophet) (0.5.1)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\m\\anaconda3\\lib\\site-packages (from holidays<1,>=0.25->prophet) (2.9.0.post0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\m\\anaconda3\\lib\\site-packages (from matplotlib>=2.0.0->prophet) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\m\\anaconda3\\lib\\site-packages (from matplotlib>=2.0.0->prophet) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\m\\anaconda3\\lib\\site-packages (from matplotlib>=2.0.0->prophet) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\m\\anaconda3\\lib\\site-packages (from matplotlib>=2.0.0->prophet) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\m\\anaconda3\\lib\\site-packages (from matplotlib>=2.0.0->prophet) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\m\\anaconda3\\lib\\site-packages (from matplotlib>=2.0.0->prophet) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\m\\anaconda3\\lib\\site-packages (from matplotlib>=2.0.0->prophet) (3.1.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\m\\anaconda3\\lib\\site-packages (from pandas>=1.0.4->prophet) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\m\\anaconda3\\lib\\site-packages (from pandas>=1.0.4->prophet) (2023.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\m\\anaconda3\\lib\\site-packages (from tqdm>=4.36.1->prophet) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\m\\anaconda3\\lib\\site-packages (from python-dateutil->holidays<1,>=0.25->prophet) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall prophet\n",
    "!pip install prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: prophet in c:\\users\\m\\anaconda3\\lib\\site-packages (1.1.6)\n",
      "Requirement already satisfied: cmdstanpy>=1.0.4 in c:\\users\\m\\anaconda3\\lib\\site-packages (from prophet) (1.2.5)\n",
      "Requirement already satisfied: numpy>=1.15.4 in c:\\users\\m\\anaconda3\\lib\\site-packages (from prophet) (1.26.4)\n",
      "Requirement already satisfied: matplotlib>=2.0.0 in c:\\users\\m\\anaconda3\\lib\\site-packages (from prophet) (3.9.2)\n",
      "Requirement already satisfied: pandas>=1.0.4 in c:\\users\\m\\anaconda3\\lib\\site-packages (from prophet) (2.2.2)\n",
      "Requirement already satisfied: holidays<1,>=0.25 in c:\\users\\m\\anaconda3\\lib\\site-packages (from prophet) (0.66)\n",
      "Requirement already satisfied: tqdm>=4.36.1 in c:\\users\\m\\anaconda3\\lib\\site-packages (from prophet) (4.66.5)\n",
      "Requirement already satisfied: importlib-resources in c:\\users\\m\\anaconda3\\lib\\site-packages (from prophet) (6.5.2)\n",
      "Requirement already satisfied: stanio<2.0.0,>=0.4.0 in c:\\users\\m\\anaconda3\\lib\\site-packages (from cmdstanpy>=1.0.4->prophet) (0.5.1)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\m\\anaconda3\\lib\\site-packages (from holidays<1,>=0.25->prophet) (2.9.0.post0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\m\\anaconda3\\lib\\site-packages (from matplotlib>=2.0.0->prophet) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\m\\anaconda3\\lib\\site-packages (from matplotlib>=2.0.0->prophet) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\m\\anaconda3\\lib\\site-packages (from matplotlib>=2.0.0->prophet) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\m\\anaconda3\\lib\\site-packages (from matplotlib>=2.0.0->prophet) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\m\\anaconda3\\lib\\site-packages (from matplotlib>=2.0.0->prophet) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\m\\anaconda3\\lib\\site-packages (from matplotlib>=2.0.0->prophet) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\m\\anaconda3\\lib\\site-packages (from matplotlib>=2.0.0->prophet) (3.1.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\m\\anaconda3\\lib\\site-packages (from pandas>=1.0.4->prophet) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\m\\anaconda3\\lib\\site-packages (from pandas>=1.0.4->prophet) (2023.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\m\\anaconda3\\lib\\site-packages (from tqdm>=4.36.1->prophet) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\m\\anaconda3\\lib\\site-packages (from python-dateutil->holidays<1,>=0.25->prophet) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xc1 in position 0: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mprophet\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Prophet\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatetime\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m datetime, timedelta\n\u001b[1;32m----> 6\u001b[0m model \u001b[38;5;241m=\u001b[39m Prophet(stan_backend\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCMDSTANPY\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Îç∞Ïù¥ÌÑ∞ Î°úÎìú\u001b[39;00m\n\u001b[0;32m      9\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mm\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDesktop\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mÎ®∏Ïã†Îü¨Îãù ÏÇ¨Ïö© Îç∞Ïù¥ÌÑ∞\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mÌîºÏ≤òÏóîÏßÄÎãàÏñ¥ÎßÅÌïúÌÜµÌï©Îç∞Ïù¥ÌÑ∞\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mÌîºÏ≤òÏóîÏßÄÎãàÏñ¥ÎßÅÏùºÎã®Îã§ÌïúÌÜµÌï©Îç∞Ïù¥ÌÑ∞.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\m\\anaconda3\\Lib\\site-packages\\prophet\\forecaster.py:155\u001b[0m, in \u001b[0;36mProphet.__init__\u001b[1;34m(self, growth, changepoints, n_changepoints, changepoint_range, yearly_seasonality, weekly_seasonality, daily_seasonality, holidays, seasonality_mode, seasonality_prior_scale, holidays_prior_scale, changepoint_prior_scale, mcmc_samples, interval_width, uncertainty_samples, stan_backend, scaling, holidays_mode)\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidate_inputs()\n\u001b[1;32m--> 155\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_stan_backend(stan_backend)\n",
      "File \u001b[1;32mc:\\Users\\m\\anaconda3\\Lib\\site-packages\\prophet\\forecaster.py:166\u001b[0m, in \u001b[0;36mProphet._load_stan_backend\u001b[1;34m(self, stan_backend)\u001b[0m\n\u001b[0;32m    164\u001b[0m             logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to load backend \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m), trying the next one\u001b[39m\u001b[38;5;124m\"\u001b[39m, i\u001b[38;5;241m.\u001b[39mname, e)\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 166\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstan_backend \u001b[38;5;241m=\u001b[39m StanBackendEnum\u001b[38;5;241m.\u001b[39mget_backend_class(stan_backend)()\n\u001b[0;32m    168\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoaded stan backend: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstan_backend\u001b[38;5;241m.\u001b[39mget_type())\n",
      "File \u001b[1;32mc:\\Users\\m\\anaconda3\\Lib\\site-packages\\prophet\\models.py:95\u001b[0m, in \u001b[0;36mCmdStanPyBackend.__init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m local_cmdstan\u001b[38;5;241m.\u001b[39mexists():\n\u001b[0;32m     94\u001b[0m     cmdstanpy\u001b[38;5;241m.\u001b[39mset_cmdstan_path(\u001b[38;5;28mstr\u001b[39m(local_cmdstan))\n\u001b[1;32m---> 95\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\m\\anaconda3\\Lib\\site-packages\\prophet\\models.py:53\u001b[0m, in \u001b[0;36mIStanBackend.__init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m---> 53\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_model()\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstan_fit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnewton_fallback \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\m\\anaconda3\\Lib\\site-packages\\prophet\\models.py:104\u001b[0m, in \u001b[0;36mCmdStanPyBackend.load_model\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcmdstanpy\u001b[39;00m\n\u001b[0;32m    103\u001b[0m model_file \u001b[38;5;241m=\u001b[39m importlib_resources\u001b[38;5;241m.\u001b[39mfiles(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprophet\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstan_model\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprophet_model.bin\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 104\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cmdstanpy\u001b[38;5;241m.\u001b[39mCmdStanModel(exe_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(model_file))\n",
      "File \u001b[1;32mc:\\Users\\m\\anaconda3\\Lib\\site-packages\\cmdstanpy\\model.py:237\u001b[0m, in \u001b[0;36mCmdStanModel.__init__\u001b[1;34m(self, model_name, stan_file, exe_file, force_compile, stanc_options, cpp_options, user_header, compile)\u001b[0m\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m platform\u001b[38;5;241m.\u001b[39msystem() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWindows\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    236\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 237\u001b[0m         do_command([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwhere.exe\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtbb.dll\u001b[39m\u001b[38;5;124m'\u001b[39m], fd_out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    238\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m:\n\u001b[0;32m    239\u001b[0m         \u001b[38;5;66;03m# Add tbb to the $PATH on Windows\u001b[39;00m\n\u001b[0;32m    240\u001b[0m         libtbb \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSTAN_TBB\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\m\\anaconda3\\Lib\\site-packages\\cmdstanpy\\utils\\command.py:53\u001b[0m, in \u001b[0;36mdo_command\u001b[1;34m(cmd, cwd, fd_out, pbar)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m proc\u001b[38;5;241m.\u001b[39mpoll() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m proc\u001b[38;5;241m.\u001b[39mstdout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 53\u001b[0m         line \u001b[38;5;241m=\u001b[39m proc\u001b[38;5;241m.\u001b[39mstdout\u001b[38;5;241m.\u001b[39mreadline()\n\u001b[0;32m     54\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m fd_out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     55\u001b[0m             fd_out\u001b[38;5;241m.\u001b[39mwrite(line)\n",
      "File \u001b[1;32m<frozen codecs>:322\u001b[0m, in \u001b[0;36mdecode\u001b[1;34m(self, input, final)\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xc1 in position 0: invalid start byte"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from prophet import Prophet\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "model = Prophet(stan_backend='CMDSTANPY')\n",
    "\n",
    "# Îç∞Ïù¥ÌÑ∞ Î°úÎìú\n",
    "file_path = r\"C:\\Users\\m\\Desktop\\Î®∏Ïã†Îü¨Îãù ÏÇ¨Ïö© Îç∞Ïù¥ÌÑ∞\\ÌîºÏ≤òÏóîÏßÄÎãàÏñ¥ÎßÅÌïúÌÜµÌï©Îç∞Ïù¥ÌÑ∞\\ÌîºÏ≤òÏóîÏßÄÎãàÏñ¥ÎßÅÏùºÎã®Îã§ÌïúÌÜµÌï©Îç∞Ïù¥ÌÑ∞.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# ÌïÑÏöîÌïú Ïª¨ÎüºÎßå ÏÑ†ÌÉù\n",
    "sales_columns = [\"ÏÉÅÍ∂å_ÏΩîÎìú_Î™Ö\", \"ÏÑúÎπÑÏä§_ÏóÖÏ¢Ö_ÏΩîÎìú_Î™Ö\", \"Í∏∞Ï§Ä_ÎÖÑÎ∂ÑÍ∏∞_ÏΩîÎìú\", \"ÏõîÏöîÏùº_Îß§Ï∂ú_Í∏àÏï°\", \"ÌôîÏöîÏùº_Îß§Ï∂ú_Í∏àÏï°\", \"ÏàòÏöîÏùº_Îß§Ï∂ú_Í∏àÏï°\", \"Î™©ÏöîÏùº_Îß§Ï∂ú_Í∏àÏï°\", \"Í∏àÏöîÏùº_Îß§Ï∂ú_Í∏àÏï°\", \"ÌÜ†ÏöîÏùº_Îß§Ï∂ú_Í∏àÏï°\", \"ÏùºÏöîÏùº_Îß§Ï∂ú_Í∏àÏï°\"]\n",
    "data = data[sales_columns]\n",
    "\n",
    "# Îß§Ï∂ú Îç∞Ïù¥ÌÑ∞Î•º float ÌòïÏãùÏúºÎ°ú Î≥ÄÌôò\n",
    "data.iloc[:, 3:] = data.iloc[:, 3:].astype(float)\n",
    "\n",
    "# Í≤∞Í≥º Ï†ÄÏû•ÏùÑ ÏúÑÌïú Î¶¨Ïä§Ìä∏\n",
    "daily_sales_results = []\n",
    "\n",
    "# ÏÉÅÍ∂å-ÏóÖÏ¢ÖÎ≥ÑÎ°ú ÏãúÍ≥ÑÏó¥ Î™®Îç∏ ÌïôÏäµ Î∞è Î≥ÄÌôò\n",
    "for (district, category), group in data.groupby([\"ÏÉÅÍ∂å_ÏΩîÎìú_Î™Ö\", \"ÏÑúÎπÑÏä§_ÏóÖÏ¢Ö_ÏΩîÎìú_Î™Ö\"]):\n",
    "    df_list = []\n",
    "    \n",
    "    # Î∂ÑÍ∏∞Î≥Ñ Îç∞Ïù¥ÌÑ∞ Ï†ïÎ¶¨\n",
    "    for _, row in group.iterrows():\n",
    "        year_quarter = str(int(row[\"Í∏∞Ï§Ä_ÎÖÑÎ∂ÑÍ∏∞_ÏΩîÎìú\"]))  # ÏÜåÏàòÏ†ê Î∞©ÏßÄ\n",
    "        year = int(year_quarter[:4])\n",
    "        quarter = int(year_quarter[4])\n",
    "        \n",
    "        # Î∂ÑÍ∏∞Î≥Ñ ÏãúÏûë ÎÇ†Ïßú ÏÑ§Ï†ï\n",
    "        quarter_start_month = {1: 1, 2: 4, 3: 7, 4: 10}[quarter]\n",
    "        start_date = datetime(year, quarter_start_month, 1)\n",
    "        end_date = start_date + pd.offsets.QuarterEnd()\n",
    "        \n",
    "        # ÏöîÏùºÎ≥Ñ Îß§Ï∂ú Îç∞Ïù¥ÌÑ∞ Î≥ÄÌôò\n",
    "        for i, day in enumerate([\"Ïõî\", \"Ìôî\", \"Ïàò\", \"Î™©\", \"Í∏à\", \"ÌÜ†\", \"Ïùº\"]):\n",
    "            sales_value = row[f\"{day}ÏöîÏùº_Îß§Ï∂ú_Í∏àÏï°\"]\n",
    "            date_range = pd.date_range(start=start_date, end=end_date, freq='W-MON') + timedelta(days=i)\n",
    "            \n",
    "            for date in date_range:\n",
    "                if date > end_date:\n",
    "                    break\n",
    "                df_list.append({\"ds\": date, \"y\": sales_value})\n",
    "    \n",
    "    # Prophet Î™®Îç∏ ÌïôÏäµ\n",
    "    df_prophet = pd.DataFrame(df_list)\n",
    "    model = Prophet()\n",
    "    model.fit(df_prophet)\n",
    "    \n",
    "    # Í∏∞Ï°¥ Îç∞Ïù¥ÌÑ∞Ïóê ÎåÄÌï¥ ÏùºÎ≥Ñ Îß§Ï∂úÏùÑ ÏòàÏ∏°\n",
    "    date_range = pd.date_range(start=df_prophet[\"ds\"].min(), end=df_prophet[\"ds\"].max(), freq='D')\n",
    "    future_df = pd.DataFrame({\"ds\": date_range})\n",
    "    forecast = model.predict(future_df)\n",
    "    \n",
    "    # ÏòàÏ∏° Í≤∞Í≥º Ï†ÄÏû•\n",
    "    for i, row in forecast.iterrows():\n",
    "        daily_sales_results.append({\n",
    "            \"ÎÇ†Ïßú\": row[\"ds\"].strftime(\"%Y-%m-%d\"),\n",
    "            \"ÏöîÏùº\": row[\"ds\"].strftime(\"%a\")[0],\n",
    "            \"ÏÉÅÍ∂å\": district,\n",
    "            \"ÏóÖÏ¢Ö\": category,\n",
    "            \"Îß§Ï∂ú_Í∏àÏï°\": row[\"yhat\"]\n",
    "        })\n",
    "\n",
    "# Î≥ÄÌôòÎêú Îç∞Ïù¥ÌÑ∞ÌîÑÎ†àÏûÑ ÏÉùÏÑ± Î∞è Ï†ÄÏû•\n",
    "daily_sales_df = pd.DataFrame(daily_sales_results)\n",
    "output_path = r\"C:\\Users\\m\\Desktop\\Î®∏Ïã†Îü¨Îãù ÏÇ¨Ïö© Îç∞Ïù¥ÌÑ∞\\ÏùºÎ≥Ñ_Îß§Ï∂ú_Îç∞Ïù¥ÌÑ∞.csv\"\n",
    "daily_sales_df.to_csv(output_path, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(f\"Í≥ºÍ±∞ ÏùºÎ≥Ñ Îß§Ï∂ú Îç∞Ïù¥ÌÑ∞Í∞Ä Ï†ÄÏû•ÎêòÏóàÏäµÎãàÎã§: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CmdStan install directory: C:\\Users\\m\\.cmdstan\n",
      "Installing CmdStan version: 2.36.0\n",
      "Downloading CmdStan version 2.36.0\n",
      "Download successful, file: C:\\Users\\m\\AppData\\Local\\Temp\\tmpkqzhf_8g\n",
      "Extracting distribution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10:35:03 - cmdstanpy - WARNING - CmdStan installation failed.\n",
      "Command \"make build\" failed\n",
      "Command: ['mingw32-make', 'build', '-j1']\n",
      "failed with error [WinError 2] ÏßÄÏ†ïÎêú ÌååÏùºÏùÑ Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unpacked download as cmdstan-2.36.0\n",
      "Building version cmdstan-2.36.0, may take several minutes, depending on your system.\n"
     ]
    },
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xc1 in position 0: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m cmdstanpy\u001b[38;5;241m.\u001b[39minstall_cmdstan()\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Prophet ÏÑ§Ï†ï\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m model \u001b[38;5;241m=\u001b[39m Prophet(stan_backend\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCMDSTANPY\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Îç∞Ïù¥ÌÑ∞ Î°úÎìú (Ïù∏ÏΩîÎî© ÏÑ§Ï†ï Ï∂îÍ∞Ä)\u001b[39;00m\n\u001b[0;32m     14\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mm\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDesktop\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mÎ®∏Ïã†Îü¨Îãù ÏÇ¨Ïö© Îç∞Ïù¥ÌÑ∞\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mÌîºÏ≤òÏóîÏßÄÎãàÏñ¥ÎßÅÌïúÌÜµÌï©Îç∞Ïù¥ÌÑ∞\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mÌîºÏ≤òÏóîÏßÄÎãàÏñ¥ÎßÅÏùºÎã®Îã§ÌïúÌÜµÌï©Îç∞Ïù¥ÌÑ∞.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\m\\anaconda3\\Lib\\site-packages\\prophet\\forecaster.py:155\u001b[0m, in \u001b[0;36mProphet.__init__\u001b[1;34m(self, growth, changepoints, n_changepoints, changepoint_range, yearly_seasonality, weekly_seasonality, daily_seasonality, holidays, seasonality_mode, seasonality_prior_scale, holidays_prior_scale, changepoint_prior_scale, mcmc_samples, interval_width, uncertainty_samples, stan_backend, scaling, holidays_mode)\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidate_inputs()\n\u001b[1;32m--> 155\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_stan_backend(stan_backend)\n",
      "File \u001b[1;32mc:\\Users\\m\\anaconda3\\Lib\\site-packages\\prophet\\forecaster.py:166\u001b[0m, in \u001b[0;36mProphet._load_stan_backend\u001b[1;34m(self, stan_backend)\u001b[0m\n\u001b[0;32m    164\u001b[0m             logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to load backend \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m), trying the next one\u001b[39m\u001b[38;5;124m\"\u001b[39m, i\u001b[38;5;241m.\u001b[39mname, e)\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 166\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstan_backend \u001b[38;5;241m=\u001b[39m StanBackendEnum\u001b[38;5;241m.\u001b[39mget_backend_class(stan_backend)()\n\u001b[0;32m    168\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoaded stan backend: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstan_backend\u001b[38;5;241m.\u001b[39mget_type())\n",
      "File \u001b[1;32mc:\\Users\\m\\anaconda3\\Lib\\site-packages\\prophet\\models.py:95\u001b[0m, in \u001b[0;36mCmdStanPyBackend.__init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m local_cmdstan\u001b[38;5;241m.\u001b[39mexists():\n\u001b[0;32m     94\u001b[0m     cmdstanpy\u001b[38;5;241m.\u001b[39mset_cmdstan_path(\u001b[38;5;28mstr\u001b[39m(local_cmdstan))\n\u001b[1;32m---> 95\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\m\\anaconda3\\Lib\\site-packages\\prophet\\models.py:53\u001b[0m, in \u001b[0;36mIStanBackend.__init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m---> 53\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_model()\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstan_fit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnewton_fallback \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\m\\anaconda3\\Lib\\site-packages\\prophet\\models.py:104\u001b[0m, in \u001b[0;36mCmdStanPyBackend.load_model\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcmdstanpy\u001b[39;00m\n\u001b[0;32m    103\u001b[0m model_file \u001b[38;5;241m=\u001b[39m importlib_resources\u001b[38;5;241m.\u001b[39mfiles(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprophet\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstan_model\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprophet_model.bin\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 104\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cmdstanpy\u001b[38;5;241m.\u001b[39mCmdStanModel(exe_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(model_file))\n",
      "File \u001b[1;32mc:\\Users\\m\\anaconda3\\Lib\\site-packages\\cmdstanpy\\model.py:237\u001b[0m, in \u001b[0;36mCmdStanModel.__init__\u001b[1;34m(self, model_name, stan_file, exe_file, force_compile, stanc_options, cpp_options, user_header, compile)\u001b[0m\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m platform\u001b[38;5;241m.\u001b[39msystem() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWindows\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    236\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 237\u001b[0m         do_command([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwhere.exe\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtbb.dll\u001b[39m\u001b[38;5;124m'\u001b[39m], fd_out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    238\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m:\n\u001b[0;32m    239\u001b[0m         \u001b[38;5;66;03m# Add tbb to the $PATH on Windows\u001b[39;00m\n\u001b[0;32m    240\u001b[0m         libtbb \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSTAN_TBB\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\m\\anaconda3\\Lib\\site-packages\\cmdstanpy\\utils\\command.py:53\u001b[0m, in \u001b[0;36mdo_command\u001b[1;34m(cmd, cwd, fd_out, pbar)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m proc\u001b[38;5;241m.\u001b[39mpoll() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m proc\u001b[38;5;241m.\u001b[39mstdout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 53\u001b[0m         line \u001b[38;5;241m=\u001b[39m proc\u001b[38;5;241m.\u001b[39mstdout\u001b[38;5;241m.\u001b[39mreadline()\n\u001b[0;32m     54\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m fd_out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     55\u001b[0m             fd_out\u001b[38;5;241m.\u001b[39mwrite(line)\n",
      "File \u001b[1;32m<frozen codecs>:322\u001b[0m, in \u001b[0;36mdecode\u001b[1;34m(self, input, final)\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xc1 in position 0: invalid start byte"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from prophet import Prophet\n",
    "from datetime import datetime, timedelta\n",
    "import cmdstanpy\n",
    "\n",
    "# CmdStan ÏÑ§Ïπò\n",
    "cmdstanpy.install_cmdstan()\n",
    "\n",
    "# Prophet ÏÑ§Ï†ï\n",
    "model = Prophet(stan_backend='CMDSTANPY')\n",
    "\n",
    "# Îç∞Ïù¥ÌÑ∞ Î°úÎìú (Ïù∏ÏΩîÎî© ÏÑ§Ï†ï Ï∂îÍ∞Ä)\n",
    "file_path = r\"C:\\Users\\m\\Desktop\\Î®∏Ïã†Îü¨Îãù ÏÇ¨Ïö© Îç∞Ïù¥ÌÑ∞\\ÌîºÏ≤òÏóîÏßÄÎãàÏñ¥ÎßÅÌïúÌÜµÌï©Îç∞Ïù¥ÌÑ∞\\ÌîºÏ≤òÏóîÏßÄÎãàÏñ¥ÎßÅÏùºÎã®Îã§ÌïúÌÜµÌï©Îç∞Ïù¥ÌÑ∞.csv\"\n",
    "data = pd.read_csv(file_path, encoding=\"cp949\")  # ÎòêÎäî encoding=\"euc-kr\"\n",
    "\n",
    "# ÌïÑÏöîÌïú Ïª¨ÎüºÎßå ÏÑ†ÌÉù\n",
    "sales_columns = [\"ÏÉÅÍ∂å_ÏΩîÎìú_Î™Ö\", \"ÏÑúÎπÑÏä§_ÏóÖÏ¢Ö_ÏΩîÎìú_Î™Ö\", \"Í∏∞Ï§Ä_ÎÖÑÎ∂ÑÍ∏∞_ÏΩîÎìú\", \n",
    "                 \"ÏõîÏöîÏùº_Îß§Ï∂ú_Í∏àÏï°\", \"ÌôîÏöîÏùº_Îß§Ï∂ú_Í∏àÏï°\", \"ÏàòÏöîÏùº_Îß§Ï∂ú_Í∏àÏï°\", \n",
    "                 \"Î™©ÏöîÏùº_Îß§Ï∂ú_Í∏àÏï°\", \"Í∏àÏöîÏùº_Îß§Ï∂ú_Í∏àÏï°\", \"ÌÜ†ÏöîÏùº_Îß§Ï∂ú_Í∏àÏï°\", \"ÏùºÏöîÏùº_Îß§Ï∂ú_Í∏àÏï°\"]\n",
    "data = data[sales_columns]\n",
    "\n",
    "# Îß§Ï∂ú Îç∞Ïù¥ÌÑ∞Î•º float ÌòïÏãùÏúºÎ°ú Î≥ÄÌôò\n",
    "data.iloc[:, 3:] = data.iloc[:, 3:].astype(float)\n",
    "\n",
    "# Í≤∞Í≥º Ï†ÄÏû•ÏùÑ ÏúÑÌïú Î¶¨Ïä§Ìä∏\n",
    "daily_sales_results = []\n",
    "\n",
    "# ÏÉÅÍ∂å-ÏóÖÏ¢ÖÎ≥ÑÎ°ú ÏãúÍ≥ÑÏó¥ Î™®Îç∏ ÌïôÏäµ Î∞è Î≥ÄÌôò\n",
    "for (district, category), group in data.groupby([\"ÏÉÅÍ∂å_ÏΩîÎìú_Î™Ö\", \"ÏÑúÎπÑÏä§_ÏóÖÏ¢Ö_ÏΩîÎìú_Î™Ö\"]):\n",
    "    df_list = []\n",
    "    \n",
    "    # Î∂ÑÍ∏∞Î≥Ñ Îç∞Ïù¥ÌÑ∞ Ï†ïÎ¶¨\n",
    "    for _, row in group.iterrows():\n",
    "        year_quarter = str(int(row[\"Í∏∞Ï§Ä_ÎÖÑÎ∂ÑÍ∏∞_ÏΩîÎìú\"]))  # ÏÜåÏàòÏ†ê Î∞©ÏßÄ\n",
    "        year = int(year_quarter[:4])\n",
    "        quarter = int(year_quarter[4])\n",
    "        \n",
    "        # Î∂ÑÍ∏∞Î≥Ñ ÏãúÏûë ÎÇ†Ïßú ÏÑ§Ï†ï\n",
    "        quarter_start_month = {1: 1, 2: 4, 3: 7, 4: 10}[quarter]\n",
    "        start_date = datetime(year, quarter_start_month, 1)\n",
    "        end_date = start_date + pd.offsets.QuarterEnd()\n",
    "        \n",
    "        # ÏöîÏùºÎ≥Ñ Îß§Ï∂ú Îç∞Ïù¥ÌÑ∞ Î≥ÄÌôò\n",
    "        for i, day in enumerate([\"Ïõî\", \"Ìôî\", \"Ïàò\", \"Î™©\", \"Í∏à\", \"ÌÜ†\", \"Ïùº\"]):\n",
    "            sales_value = row[f\"{day}ÏöîÏùº_Îß§Ï∂ú_Í∏àÏï°\"]\n",
    "            date_range = pd.date_range(start=start_date, end=end_date, freq='W-MON') + timedelta(days=i)\n",
    "            \n",
    "            for date in date_range:\n",
    "                if date > end_date:\n",
    "                    break\n",
    "                df_list.append({\"ds\": date, \"y\": sales_value})\n",
    "    \n",
    "    # Prophet Î™®Îç∏ ÌïôÏäµ\n",
    "    df_prophet = pd.DataFrame(df_list)\n",
    "    model = Prophet()\n",
    "    model.fit(df_prophet)\n",
    "    \n",
    "    # Í∏∞Ï°¥ Îç∞Ïù¥ÌÑ∞Ïóê ÎåÄÌï¥ ÏùºÎ≥Ñ Îß§Ï∂úÏùÑ ÏòàÏ∏°\n",
    "    date_range = pd.date_range(start=df_prophet[\"ds\"].min(), end=df_prophet[\"ds\"].max(), freq='D')\n",
    "    future_df = pd.DataFrame({\"ds\": date_range})\n",
    "    forecast = model.predict(future_df)\n",
    "    \n",
    "    # ÏòàÏ∏° Í≤∞Í≥º Ï†ÄÏû•\n",
    "    for i, row in forecast.iterrows():\n",
    "        daily_sales_results.append({\n",
    "            \"ÎÇ†Ïßú\": row[\"ds\"].strftime(\"%Y-%m-%d\"),\n",
    "            \"ÏöîÏùº\": row[\"ds\"].strftime(\"%a\")[0],\n",
    "            \"ÏÉÅÍ∂å\": district,\n",
    "            \"ÏóÖÏ¢Ö\": category,\n",
    "            \"Îß§Ï∂ú_Í∏àÏï°\": row[\"yhat\"]\n",
    "        })\n",
    "\n",
    "# Î≥ÄÌôòÎêú Îç∞Ïù¥ÌÑ∞ÌîÑÎ†àÏûÑ ÏÉùÏÑ± Î∞è Ï†ÄÏû•\n",
    "daily_sales_df = pd.DataFrame(daily_sales_results)\n",
    "output_path = r\"C:\\Users\\m\\Desktop\\Î®∏Ïã†Îü¨Îãù ÏÇ¨Ïö© Îç∞Ïù¥ÌÑ∞\\ÏùºÎ≥Ñ_Îß§Ï∂ú_Îç∞Ïù¥ÌÑ∞.csv\"\n",
    "daily_sales_df.to_csv(output_path, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(f\"Í≥ºÍ±∞ ÏùºÎ≥Ñ Îß§Ï∂ú Îç∞Ïù¥ÌÑ∞Í∞Ä Ï†ÄÏû•ÎêòÏóàÏäµÎãàÎã§: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown stan backend: PYSTAN",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\m\\anaconda3\\Lib\\site-packages\\prophet\\models.py:261\u001b[0m, in \u001b[0;36mStanBackendEnum.get_backend_class\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m    260\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 261\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m StanBackendEnum[name]\u001b[38;5;241m.\u001b[39mvalue\n\u001b[0;32m    262\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\m\\anaconda3\\Lib\\enum.py:814\u001b[0m, in \u001b[0;36mEnumType.__getitem__\u001b[1;34m(cls, name)\u001b[0m\n\u001b[0;32m    811\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    812\u001b[0m \u001b[38;5;124;03mReturn the member matching `name`.\u001b[39;00m\n\u001b[0;32m    813\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 814\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_member_map_[name]\n",
      "\u001b[1;31mKeyError\u001b[0m: 'PYSTAN'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatetime\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m datetime, timedelta\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Prophet ÏÑ§Ï†ï (CMDSTANPY Ï†úÍ±∞)\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m model \u001b[38;5;241m=\u001b[39m Prophet(stan_backend\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPYSTAN\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Îç∞Ïù¥ÌÑ∞ Î°úÎìú (Ïù∏ÏΩîÎî© ÏÑ§Ï†ï Ï∂îÍ∞Ä)\u001b[39;00m\n\u001b[0;32m     10\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mm\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDesktop\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mÎ®∏Ïã†Îü¨Îãù ÏÇ¨Ïö© Îç∞Ïù¥ÌÑ∞\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mÌîºÏ≤òÏóîÏßÄÎãàÏñ¥ÎßÅÌïúÌÜµÌï©Îç∞Ïù¥ÌÑ∞\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mÌîºÏ≤òÏóîÏßÄÎãàÏñ¥ÎßÅÏùºÎã®Îã§ÌïúÌÜµÌï©Îç∞Ïù¥ÌÑ∞.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\m\\anaconda3\\Lib\\site-packages\\prophet\\forecaster.py:155\u001b[0m, in \u001b[0;36mProphet.__init__\u001b[1;34m(self, growth, changepoints, n_changepoints, changepoint_range, yearly_seasonality, weekly_seasonality, daily_seasonality, holidays, seasonality_mode, seasonality_prior_scale, holidays_prior_scale, changepoint_prior_scale, mcmc_samples, interval_width, uncertainty_samples, stan_backend, scaling, holidays_mode)\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidate_inputs()\n\u001b[1;32m--> 155\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_stan_backend(stan_backend)\n",
      "File \u001b[1;32mc:\\Users\\m\\anaconda3\\Lib\\site-packages\\prophet\\forecaster.py:166\u001b[0m, in \u001b[0;36mProphet._load_stan_backend\u001b[1;34m(self, stan_backend)\u001b[0m\n\u001b[0;32m    164\u001b[0m             logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to load backend \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m), trying the next one\u001b[39m\u001b[38;5;124m\"\u001b[39m, i\u001b[38;5;241m.\u001b[39mname, e)\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 166\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstan_backend \u001b[38;5;241m=\u001b[39m StanBackendEnum\u001b[38;5;241m.\u001b[39mget_backend_class(stan_backend)()\n\u001b[0;32m    168\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoaded stan backend: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstan_backend\u001b[38;5;241m.\u001b[39mget_type())\n",
      "File \u001b[1;32mc:\\Users\\m\\anaconda3\\Lib\\site-packages\\prophet\\models.py:263\u001b[0m, in \u001b[0;36mStanBackendEnum.get_backend_class\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m StanBackendEnum[name]\u001b[38;5;241m.\u001b[39mvalue\n\u001b[0;32m    262\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 263\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown stan backend: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: Unknown stan backend: PYSTAN"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from prophet import Prophet\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Prophet ÏÑ§Ï†ï (CMDSTANPY Ï†úÍ±∞)\n",
    "model = Prophet(stan_backend='PYSTAN')\n",
    "\n",
    "# Îç∞Ïù¥ÌÑ∞ Î°úÎìú (Ïù∏ÏΩîÎî© ÏÑ§Ï†ï Ï∂îÍ∞Ä)\n",
    "file_path = r\"C:\\Users\\m\\Desktop\\Î®∏Ïã†Îü¨Îãù ÏÇ¨Ïö© Îç∞Ïù¥ÌÑ∞\\ÌîºÏ≤òÏóîÏßÄÎãàÏñ¥ÎßÅÌïúÌÜµÌï©Îç∞Ïù¥ÌÑ∞\\ÌîºÏ≤òÏóîÏßÄÎãàÏñ¥ÎßÅÏùºÎã®Îã§ÌïúÌÜµÌï©Îç∞Ïù¥ÌÑ∞.csv\"\n",
    "data = pd.read_csv(file_path, encoding=\"cp949\")  # ÎòêÎäî encoding=\"euc-kr\"\n",
    "\n",
    "# ÌïÑÏöîÌïú Ïª¨ÎüºÎßå ÏÑ†ÌÉù\n",
    "sales_columns = [\"ÏÉÅÍ∂å_ÏΩîÎìú_Î™Ö\", \"ÏÑúÎπÑÏä§_ÏóÖÏ¢Ö_ÏΩîÎìú_Î™Ö\", \"Í∏∞Ï§Ä_ÎÖÑÎ∂ÑÍ∏∞_ÏΩîÎìú\", \n",
    "                 \"ÏõîÏöîÏùº_Îß§Ï∂ú_Í∏àÏï°\", \"ÌôîÏöîÏùº_Îß§Ï∂ú_Í∏àÏï°\", \"ÏàòÏöîÏùº_Îß§Ï∂ú_Í∏àÏï°\", \n",
    "                 \"Î™©ÏöîÏùº_Îß§Ï∂ú_Í∏àÏï°\", \"Í∏àÏöîÏùº_Îß§Ï∂ú_Í∏àÏï°\", \"ÌÜ†ÏöîÏùº_Îß§Ï∂ú_Í∏àÏï°\", \"ÏùºÏöîÏùº_Îß§Ï∂ú_Í∏àÏï°\"]\n",
    "data = data[sales_columns]\n",
    "\n",
    "# Îß§Ï∂ú Îç∞Ïù¥ÌÑ∞Î•º float ÌòïÏãùÏúºÎ°ú Î≥ÄÌôò\n",
    "data.iloc[:, 3:] = data.iloc[:, 3:].astype(float)\n",
    "\n",
    "# Í≤∞Í≥º Ï†ÄÏû•ÏùÑ ÏúÑÌïú Î¶¨Ïä§Ìä∏\n",
    "daily_sales_results = []\n",
    "\n",
    "# ÏÉÅÍ∂å-ÏóÖÏ¢ÖÎ≥ÑÎ°ú ÏãúÍ≥ÑÏó¥ Î™®Îç∏ ÌïôÏäµ Î∞è Î≥ÄÌôò\n",
    "for (district, category), group in data.groupby([\"ÏÉÅÍ∂å_ÏΩîÎìú_Î™Ö\", \"ÏÑúÎπÑÏä§_ÏóÖÏ¢Ö_ÏΩîÎìú_Î™Ö\"]):\n",
    "    df_list = []\n",
    "    \n",
    "    # Î∂ÑÍ∏∞Î≥Ñ Îç∞Ïù¥ÌÑ∞ Ï†ïÎ¶¨\n",
    "    for _, row in group.iterrows():\n",
    "        year_quarter = str(int(row[\"Í∏∞Ï§Ä_ÎÖÑÎ∂ÑÍ∏∞_ÏΩîÎìú\"]))  # ÏÜåÏàòÏ†ê Î∞©ÏßÄ\n",
    "        year = int(year_quarter[:4])\n",
    "        quarter = int(year_quarter[4])\n",
    "        \n",
    "        # Î∂ÑÍ∏∞Î≥Ñ ÏãúÏûë ÎÇ†Ïßú ÏÑ§Ï†ï\n",
    "        quarter_start_month = {1: 1, 2: 4, 3: 7, 4: 10}[quarter]\n",
    "        start_date = datetime(year, quarter_start_month, 1)\n",
    "        end_date = start_date + pd.offsets.QuarterEnd()\n",
    "        \n",
    "        # ÏöîÏùºÎ≥Ñ Îß§Ï∂ú Îç∞Ïù¥ÌÑ∞ Î≥ÄÌôò\n",
    "        for i, day in enumerate([\"Ïõî\", \"Ìôî\", \"Ïàò\", \"Î™©\", \"Í∏à\", \"ÌÜ†\", \"Ïùº\"]):\n",
    "            sales_value = row[f\"{day}ÏöîÏùº_Îß§Ï∂ú_Í∏àÏï°\"]\n",
    "            date_range = pd.date_range(start=start_date, end=end_date, freq='W-MON') + timedelta(days=i)\n",
    "            \n",
    "            for date in date_range:\n",
    "                if date > end_date:\n",
    "                    break\n",
    "                df_list.append({\"ds\": date, \"y\": sales_value})\n",
    "    \n",
    "    # Prophet Î™®Îç∏ ÌïôÏäµ\n",
    "    df_prophet = pd.DataFrame(df_list)\n",
    "    model = Prophet(stan_backend='PYSTAN')  # PYSTAN Î∞±ÏóîÎìú ÏÑ§Ï†ï\n",
    "    model.fit(df_prophet)\n",
    "    \n",
    "    # Í∏∞Ï°¥ Îç∞Ïù¥ÌÑ∞Ïóê ÎåÄÌï¥ ÏùºÎ≥Ñ Îß§Ï∂úÏùÑ ÏòàÏ∏°\n",
    "    date_range = pd.date_range(start=df_prophet[\"ds\"].min(), end=df_prophet[\"ds\"].max(), freq='D')\n",
    "    future_df = pd.DataFrame({\"ds\": date_range})\n",
    "    forecast = model.predict(future_df)\n",
    "    \n",
    "    # ÏòàÏ∏° Í≤∞Í≥º Ï†ÄÏû•\n",
    "    for i, row in forecast.iterrows():\n",
    "        daily_sales_results.append({\n",
    "            \"ÎÇ†Ïßú\": row[\"ds\"].strftime(\"%Y-%m-%d\"),\n",
    "            \"ÏöîÏùº\": row[\"ds\"].strftime(\"%a\")[0],\n",
    "            \"ÏÉÅÍ∂å\": district,\n",
    "            \"ÏóÖÏ¢Ö\": category,\n",
    "            \"Îß§Ï∂ú_Í∏àÏï°\": row[\"yhat\"]\n",
    "        })\n",
    "\n",
    "# Î≥ÄÌôòÎêú Îç∞Ïù¥ÌÑ∞ÌîÑÎ†àÏûÑ ÏÉùÏÑ± Î∞è Ï†ÄÏû•\n",
    "daily_sales_df = pd.DataFrame(daily_sales_results)\n",
    "output_path = r\"C:\\Users\\m\\Desktop\\Î®∏Ïã†Îü¨Îãù ÏÇ¨Ïö© Îç∞Ïù¥ÌÑ∞\\ÏùºÎ≥Ñ_Îß§Ï∂ú_Îç∞Ïù¥ÌÑ∞.csv\"\n",
    "daily_sales_df.to_csv(output_path, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(f\"Í≥ºÍ±∞ ÏùºÎ≥Ñ Îß§Ï∂ú Îç∞Ïù¥ÌÑ∞Í∞Ä Ï†ÄÏû•ÎêòÏóàÏäµÎãàÎã§: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\m\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\m\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it is not monotonic and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\m\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\m\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it is not monotonic and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\m\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\m\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it is not monotonic and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\m\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\m\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it is not monotonic and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\m\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\m\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it is not monotonic and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\m\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\m\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it is not monotonic and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\m\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\m\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it is not monotonic and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\m\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\m\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it is not monotonic and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\m\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\m\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it is not monotonic and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\m\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\m\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it is not monotonic and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\m\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\m\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it is not monotonic and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\m\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\m\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it is not monotonic and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\m\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\m\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it is not monotonic and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\m\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\m\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it is not monotonic and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\m\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\m\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it is not monotonic and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\m\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\m\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it is not monotonic and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Prediction must have `end` after `start`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 60\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;66;03m# Í∏∞Ï°¥ Îç∞Ïù¥ÌÑ∞Ïóê ÎåÄÌï¥ ÏùºÎ≥Ñ Îß§Ï∂ú ÏòàÏ∏°\u001b[39;00m\n\u001b[0;32m     59\u001b[0m date_range \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mdate_range(start\u001b[38;5;241m=\u001b[39mdf_sales\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mmin(), end\u001b[38;5;241m=\u001b[39mdf_sales\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mmax(), freq\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 60\u001b[0m forecast \u001b[38;5;241m=\u001b[39m results\u001b[38;5;241m.\u001b[39mget_prediction(start\u001b[38;5;241m=\u001b[39mdate_range\u001b[38;5;241m.\u001b[39mmin(), end\u001b[38;5;241m=\u001b[39mdate_range\u001b[38;5;241m.\u001b[39mmax())\u001b[38;5;241m.\u001b[39mpredicted_mean\n\u001b[0;32m     62\u001b[0m \u001b[38;5;66;03m# ÏòàÏ∏° Í≤∞Í≥º Ï†ÄÏû•\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m date, yhat \u001b[38;5;129;01min\u001b[39;00m forecast\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[1;32mc:\\Users\\m\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\mlemodel.py:3339\u001b[0m, in \u001b[0;36mMLEResults.get_prediction\u001b[1;34m(self, start, end, dynamic, information_set, signal_only, index, exog, extend_model, extend_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m   3335\u001b[0m     start \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m   3337\u001b[0m \u001b[38;5;66;03m# Handle start, end, dynamic\u001b[39;00m\n\u001b[0;32m   3338\u001b[0m start, end, out_of_sample, prediction_index \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m-> 3339\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39m_get_prediction_index(start, end, index))\n\u001b[0;32m   3341\u001b[0m \u001b[38;5;66;03m# Handle `dynamic`\u001b[39;00m\n\u001b[0;32m   3342\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dynamic, (\u001b[38;5;28mstr\u001b[39m, dt\u001b[38;5;241m.\u001b[39mdatetime, pd\u001b[38;5;241m.\u001b[39mTimestamp)):\n",
      "File \u001b[1;32mc:\\Users\\m\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:836\u001b[0m, in \u001b[0;36mTimeSeriesModel._get_prediction_index\u001b[1;34m(self, start, end, index, silent)\u001b[0m\n\u001b[0;32m    780\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    781\u001b[0m \u001b[38;5;124;03mGet the location of a specific key in an index or model row labels\u001b[39;00m\n\u001b[0;32m    782\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    833\u001b[0m \u001b[38;5;124;03msince we have required them to be full indexes, there is no ambiguity).\u001b[39;00m\n\u001b[0;32m    834\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    835\u001b[0m nobs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mendog)\n\u001b[1;32m--> 836\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m get_prediction_index(\n\u001b[0;32m    837\u001b[0m     start,\n\u001b[0;32m    838\u001b[0m     end,\n\u001b[0;32m    839\u001b[0m     nobs,\n\u001b[0;32m    840\u001b[0m     base_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index,\n\u001b[0;32m    841\u001b[0m     index\u001b[38;5;241m=\u001b[39mindex,\n\u001b[0;32m    842\u001b[0m     silent\u001b[38;5;241m=\u001b[39msilent,\n\u001b[0;32m    843\u001b[0m     index_none\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_none,\n\u001b[0;32m    844\u001b[0m     index_generated\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_generated,\n\u001b[0;32m    845\u001b[0m     data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata,\n\u001b[0;32m    846\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\m\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:389\u001b[0m, in \u001b[0;36mget_prediction_index\u001b[1;34m(start, end, nobs, base_index, index, silent, index_none, index_generated, data)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[38;5;66;03m# Validate prediction options\u001b[39;00m\n\u001b[0;32m    388\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m<\u001b[39m start:\n\u001b[1;32m--> 389\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrediction must have `end` after `start`.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    391\u001b[0m \u001b[38;5;66;03m# Handle custom prediction index\u001b[39;00m\n\u001b[0;32m    392\u001b[0m \u001b[38;5;66;03m# First, if we were given an index, check that it's the right size and\u001b[39;00m\n\u001b[0;32m    393\u001b[0m \u001b[38;5;66;03m# use it if so\u001b[39;00m\n\u001b[0;32m    394\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: Prediction must have `end` after `start`."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "# Îç∞Ïù¥ÌÑ∞ Î°úÎìú (Ïù∏ÏΩîÎî© ÏÑ§Ï†ï Ï∂îÍ∞Ä)\n",
    "file_path = r\"C:\\Users\\m\\Desktop\\Î®∏Ïã†Îü¨Îãù ÏÇ¨Ïö© Îç∞Ïù¥ÌÑ∞\\ÌîºÏ≤òÏóîÏßÄÎãàÏñ¥ÎßÅÌïúÌÜµÌï©Îç∞Ïù¥ÌÑ∞\\ÌîºÏ≤òÏóîÏßÄÎãàÏñ¥ÎßÅÏùºÎã®Îã§ÌïúÌÜµÌï©Îç∞Ïù¥ÌÑ∞.csv\"\n",
    "data = pd.read_csv(file_path, encoding=\"utf-8\")\n",
    "\n",
    "# ÌïÑÏöîÌïú Ïª¨ÎüºÎßå ÏÑ†ÌÉù\n",
    "sales_columns = [\"ÏÉÅÍ∂å_ÏΩîÎìú_Î™Ö\", \"ÏÑúÎπÑÏä§_ÏóÖÏ¢Ö_ÏΩîÎìú_Î™Ö\", \"Í∏∞Ï§Ä_ÎÖÑÎ∂ÑÍ∏∞_ÏΩîÎìú\", \n",
    "                 \"ÏõîÏöîÏùº_Îß§Ï∂ú_Í∏àÏï°\", \"ÌôîÏöîÏùº_Îß§Ï∂ú_Í∏àÏï°\", \"ÏàòÏöîÏùº_Îß§Ï∂ú_Í∏àÏï°\", \n",
    "                 \"Î™©ÏöîÏùº_Îß§Ï∂ú_Í∏àÏï°\", \"Í∏àÏöîÏùº_Îß§Ï∂ú_Í∏àÏï°\", \"ÌÜ†ÏöîÏùº_Îß§Ï∂ú_Í∏àÏï°\", \"ÏùºÏöîÏùº_Îß§Ï∂ú_Í∏àÏï°\"]\n",
    "data = data[sales_columns]\n",
    "\n",
    "# Îß§Ï∂ú Îç∞Ïù¥ÌÑ∞Î•º float ÌòïÏãùÏúºÎ°ú Î≥ÄÌôò\n",
    "data.iloc[:, 3:] = data.iloc[:, 3:].astype(float)\n",
    "\n",
    "# Í≤∞Í≥º Ï†ÄÏû•ÏùÑ ÏúÑÌïú Î¶¨Ïä§Ìä∏\n",
    "daily_sales_results = []\n",
    "\n",
    "# ÏÉÅÍ∂å-ÏóÖÏ¢ÖÎ≥ÑÎ°ú ÏãúÍ≥ÑÏó¥ Î™®Îç∏ ÌïôÏäµ Î∞è Î≥ÄÌôò\n",
    "for (district, category), group in data.groupby([\"ÏÉÅÍ∂å_ÏΩîÎìú_Î™Ö\", \"ÏÑúÎπÑÏä§_ÏóÖÏ¢Ö_ÏΩîÎìú_Î™Ö\"]):\n",
    "    df_list = []\n",
    "    \n",
    "    # Î∂ÑÍ∏∞Î≥Ñ Îç∞Ïù¥ÌÑ∞ Ï†ïÎ¶¨\n",
    "    for _, row in group.iterrows():\n",
    "        year_quarter = str(int(row[\"Í∏∞Ï§Ä_ÎÖÑÎ∂ÑÍ∏∞_ÏΩîÎìú\"]))  # ÏÜåÏàòÏ†ê Î∞©ÏßÄ\n",
    "        year = int(year_quarter[:4])\n",
    "        quarter = int(year_quarter[4])\n",
    "        \n",
    "        # Î∂ÑÍ∏∞Î≥Ñ ÏãúÏûë ÎÇ†Ïßú ÏÑ§Ï†ï\n",
    "        quarter_start_month = {1: 1, 2: 4, 3: 7, 4: 10}[quarter]\n",
    "        start_date = datetime(year, quarter_start_month, 1)\n",
    "        end_date = start_date + pd.offsets.QuarterEnd()\n",
    "        \n",
    "        # ÏöîÏùºÎ≥Ñ Îß§Ï∂ú Îç∞Ïù¥ÌÑ∞ Î≥ÄÌôò\n",
    "        for i, day in enumerate([\"Ïõî\", \"Ìôî\", \"Ïàò\", \"Î™©\", \"Í∏à\", \"ÌÜ†\", \"Ïùº\"]):\n",
    "            sales_value = row[f\"{day}ÏöîÏùº_Îß§Ï∂ú_Í∏àÏï°\"]\n",
    "            date_range = pd.date_range(start=start_date, end=end_date, freq='W-MON') + timedelta(days=i)\n",
    "            \n",
    "            for date in date_range:\n",
    "                if date > end_date:\n",
    "                    break\n",
    "                df_list.append({\"ds\": date, \"y\": sales_value})\n",
    "    \n",
    "    # SARIMAX Î™®Îç∏ ÌïôÏäµ\n",
    "    df_sales = pd.DataFrame(df_list)\n",
    "    df_sales.set_index(\"ds\", inplace=True)\n",
    "    \n",
    "    # SARIMAX Î™®Îç∏ ÏÑ§Ï†ï Î∞è ÌïôÏäµ\n",
    "    try:\n",
    "        model = SARIMAX(df_sales[\"y\"], order=(1, 1, 1), seasonal_order=(1, 1, 1, 7))\n",
    "        results = model.fit(disp=False)\n",
    "    except ValueError:\n",
    "        continue  # Îç∞Ïù¥ÌÑ∞ Î∂ÄÏ°± Ïãú Î™®Îç∏ ÏÉùÎûµ\n",
    "\n",
    "    # Í∏∞Ï°¥ Îç∞Ïù¥ÌÑ∞Ïóê ÎåÄÌï¥ ÏùºÎ≥Ñ Îß§Ï∂ú ÏòàÏ∏°\n",
    "    date_range = pd.date_range(start=df_sales.index.min(), end=df_sales.index.max(), freq='D')\n",
    "    forecast = results.get_prediction(start=date_range.min(), end=date_range.max()).predicted_mean\n",
    "\n",
    "    # ÏòàÏ∏° Í≤∞Í≥º Ï†ÄÏû•\n",
    "    for date, yhat in forecast.items():\n",
    "        daily_sales_results.append({\n",
    "            \"ÎÇ†Ïßú\": date.strftime(\"%Y-%m-%d\"),\n",
    "            \"ÏöîÏùº\": date.strftime(\"%a\")[0],\n",
    "            \"ÏÉÅÍ∂å\": district,\n",
    "            \"ÏóÖÏ¢Ö\": category,\n",
    "            \"Îß§Ï∂ú_Í∏àÏï°\": yhat\n",
    "        })\n",
    "\n",
    "# Î≥ÄÌôòÎêú Îç∞Ïù¥ÌÑ∞ÌîÑÎ†àÏûÑ ÏÉùÏÑ± Î∞è Ï†ÄÏû•\n",
    "daily_sales_df = pd.DataFrame(daily_sales_results)\n",
    "output_path = r\"C:\\Users\\m\\Desktop\\Î®∏Ïã†Îü¨Îãù ÏÇ¨Ïö© Îç∞Ïù¥ÌÑ∞\\ÏùºÎ≥Ñ_Îß§Ï∂ú_Îç∞Ïù¥ÌÑ∞.csv\"\n",
    "daily_sales_df.to_csv(output_path, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(f\"Í≥ºÍ±∞ ÏùºÎ≥Ñ Îß§Ï∂ú Îç∞Ïù¥ÌÑ∞Í∞Ä Ï†ÄÏû•ÎêòÏóàÏäµÎãàÎã§: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sktime\n",
      "  Downloading sktime-0.36.0-py3-none-any.whl.metadata (34 kB)\n",
      "Requirement already satisfied: joblib<1.5,>=1.2.0 in c:\\users\\m\\anaconda3\\lib\\site-packages (from sktime) (1.4.2)\n",
      "Requirement already satisfied: numpy<2.3,>=1.21 in c:\\users\\m\\anaconda3\\lib\\site-packages (from sktime) (1.26.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\m\\anaconda3\\lib\\site-packages (from sktime) (24.1)\n",
      "Requirement already satisfied: pandas<2.3.0,>=1.1 in c:\\users\\m\\anaconda3\\lib\\site-packages (from sktime) (2.2.2)\n",
      "Collecting scikit-base<0.13.0,>=0.6.1 (from sktime)\n",
      "  Downloading scikit_base-0.12.0-py3-none-any.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: scikit-learn<1.7.0,>=0.24 in c:\\users\\m\\anaconda3\\lib\\site-packages (from sktime) (1.5.1)\n",
      "Requirement already satisfied: scipy<2.0.0,>=1.2 in c:\\users\\m\\anaconda3\\lib\\site-packages (from sktime) (1.13.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\m\\anaconda3\\lib\\site-packages (from pandas<2.3.0,>=1.1->sktime) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\m\\anaconda3\\lib\\site-packages (from pandas<2.3.0,>=1.1->sktime) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\m\\anaconda3\\lib\\site-packages (from pandas<2.3.0,>=1.1->sktime) (2023.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\m\\anaconda3\\lib\\site-packages (from scikit-learn<1.7.0,>=0.24->sktime) (3.5.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\m\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas<2.3.0,>=1.1->sktime) (1.16.0)\n",
      "Downloading sktime-0.36.0-py3-none-any.whl (36.9 MB)\n",
      "   ---------------------------------------- 0.0/36.9 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 8.7/36.9 MB 48.8 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 17.3/36.9 MB 43.6 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 23.9/36.9 MB 40.8 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 30.4/36.9 MB 38.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  36.7/36.9 MB 36.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 36.9/36.9 MB 34.5 MB/s eta 0:00:00\n",
      "Downloading scikit_base-0.12.0-py3-none-any.whl (141 kB)\n",
      "Installing collected packages: scikit-base, sktime\n",
      "Successfully installed scikit-base-0.12.0 sktime-0.36.0\n"
     ]
    }
   ],
   "source": [
    "!pip install sktime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'ReducedRegressionForecaster' from 'sktime.forecasting.compose' (c:\\Users\\m\\anaconda3\\Lib\\site-packages\\sktime\\forecasting\\compose\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msktime\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mforecasting\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompose\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ReducedRegressionForecaster\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msktime\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mforecasting\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m temporal_train_test_split\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msktime\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mforecasting\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ForecastingHorizon\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'ReducedRegressionForecaster' from 'sktime.forecasting.compose' (c:\\Users\\m\\anaconda3\\Lib\\site-packages\\sktime\\forecasting\\compose\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sktime.forecasting.compose import ReducedRegressionForecaster\n",
    "from sktime.forecasting.model_selection import temporal_train_test_split\n",
    "from sktime.forecasting.base import ForecastingHorizon\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# Îç∞Ïù¥ÌÑ∞ Î°úÎìú\n",
    "file_path = r\"C:\\Users\\m\\Desktop\\Î®∏Ïã†Îü¨Îãù ÏÇ¨Ïö© Îç∞Ïù¥ÌÑ∞\\ÌîºÏ≤òÏóîÏßÄÎãàÏñ¥ÎßÅÌïúÌÜµÌï©Îç∞Ïù¥ÌÑ∞\\ÌîºÏ≤òÏóîÏßÄÎãàÏñ¥ÎßÅÏùºÎã®Îã§ÌïúÌÜµÌï©Îç∞Ïù¥ÌÑ∞.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# ÏöîÏùº Îß§Ï∂ú Ïª¨Îüº Î™©Î°ù\n",
    "day_columns = [\"ÏõîÏöîÏùº_Îß§Ï∂ú_Í∏àÏï°\", \"ÌôîÏöîÏùº_Îß§Ï∂ú_Í∏àÏï°\", \"ÏàòÏöîÏùº_Îß§Ï∂ú_Í∏àÏï°\", \"Î™©ÏöîÏùº_Îß§Ï∂ú_Í∏àÏï°\", \"Í∏àÏöîÏùº_Îß§Ï∂ú_Í∏àÏï°\", \"ÌÜ†ÏöîÏùº_Îß§Ï∂ú_Í∏àÏï°\", \"ÏùºÏöîÏùº_Îß§Ï∂ú_Í∏àÏï°\"]\n",
    "\n",
    "# Îç∞Ïù¥ÌÑ∞ ÌïÑÌÑ∞ÎßÅ Î∞è Ï†ïÎ†¨\n",
    "data = data[[\"Í∏∞Ï§Ä_ÎÖÑÎ∂ÑÍ∏∞_ÏΩîÎìú\", \"ÏÉÅÍ∂å_ÏΩîÎìú_Î™Ö\", \"ÏÑúÎπÑÏä§_ÏóÖÏ¢Ö_ÏΩîÎìú_Î™Ö\"] + day_columns]\n",
    "data = data.sort_values(by=[\"ÏÉÅÍ∂å_ÏΩîÎìú_Î™Ö\", \"ÏÑúÎπÑÏä§_ÏóÖÏ¢Ö_ÏΩîÎìú_Î™Ö\", \"Í∏∞Ï§Ä_ÎÖÑÎ∂ÑÍ∏∞_ÏΩîÎìú\"])\n",
    "\n",
    "# Í≤∞Í≥º Ï†ÄÏû•Ìï† DataFrame ÏÉùÏÑ±\n",
    "results = []\n",
    "\n",
    "# ÏÉÅÍ∂å Î∞è ÏóÖÏ¢Ö Í∑∏Î£πÎ≥Ñ ÏãúÍ≥ÑÏó¥ Ìå®ÌÑ¥ ÌïôÏäµ ÌõÑ Ïùº Îã®ÏúÑ Îß§Ï∂ú Ï∂îÏ†ï\n",
    "for (region_code, service_code), group_data in data.groupby([\"ÏÉÅÍ∂å_ÏΩîÎìú_Î™Ö\", \"ÏÑúÎπÑÏä§_ÏóÖÏ¢Ö_ÏΩîÎìú_Î™Ö\"]):\n",
    "    # Î∂ÑÍ∏∞ Í∞íÏù¥ ÎÇ†ÏßúÎ°ú Ìï¥ÏÑù Í∞ÄÎä•ÌïòÎèÑÎ°ù Î≥ÄÌôò\n",
    "    group_data[\"Í∏∞Ï§Ä_ÎÖÑÎ∂ÑÍ∏∞_ÏΩîÎìú\"] = pd.to_datetime((group_data[\"Í∏∞Ï§Ä_ÎÖÑÎ∂ÑÍ∏∞_ÏΩîÎìú\"] // 100) * 100 + 1, format=\"%Y%m%d\")\n",
    "\n",
    "    # ÏöîÏùºÎ≥Ñ Îç∞Ïù¥ÌÑ∞ Ïû¨Íµ¨ÏÑ±\n",
    "    group_data[\"Î∂ÑÍ∏∞_ÌèâÍ∑†_Îß§Ï∂ú\"] = group_data[day_columns].mean(axis=1)\n",
    "\n",
    "    # ÏãúÍ≥ÑÏó¥ Î™®Îç∏ ÌïôÏäµ Îç∞Ïù¥ÌÑ∞ Íµ¨ÏÑ±\n",
    "    y = group_data.set_index(\"Í∏∞Ï§Ä_ÎÖÑÎ∂ÑÍ∏∞_ÏΩîÎìú\")[\"Î∂ÑÍ∏∞_ÌèâÍ∑†_Îß§Ï∂ú\"]\n",
    "\n",
    "    if len(y) < 4:  # ÏµúÏÜå Îç∞Ïù¥ÌÑ∞ Í∞úÏàò ÌôïÏù∏\n",
    "        continue\n",
    "\n",
    "    # Îç∞Ïù¥ÌÑ∞ Î∂ÑÌï†\n",
    "    y_train, y_test = temporal_train_test_split(y, test_size=1)\n",
    "    fh = ForecastingHorizon(pd.date_range(y_test.index[0], periods=91, freq='D'), is_relative=False)\n",
    "\n",
    "    # Î™®Îç∏ Ï¥àÍ∏∞Ìôî Î∞è ÌïôÏäµ\n",
    "    forecaster = ReducedRegressionForecaster(regressor=GradientBoostingRegressor(), window_length=3)\n",
    "    forecaster.fit(y_train)\n",
    "\n",
    "    # Ïùº Îã®ÏúÑ Îß§Ï∂ú Ï∂îÏ†ï\n",
    "    y_pred = forecaster.predict(fh)\n",
    "\n",
    "    # Í≤∞Í≥º Ï†ÄÏû•\n",
    "    for date, value in y_pred.items():\n",
    "        results.append({\n",
    "            \"ÏÉÅÍ∂å_ÏΩîÎìú_Î™Ö\": region_code,\n",
    "            \"ÏÑúÎπÑÏä§_ÏóÖÏ¢Ö_ÏΩîÎìú_Î™Ö\": service_code,\n",
    "            \"ÎÇ†Ïßú\": date,\n",
    "            \"Ï∂îÏ†ï_Îß§Ï∂ú_Í∏àÏï°\": value\n",
    "        })\n",
    "\n",
    "# Í≤∞Í≥º DataFrameÏúºÎ°ú Î≥ÄÌôò\n",
    "result_df = pd.DataFrame(results)\n",
    "\n",
    "# Í≤∞Í≥º Ï†ÄÏû•\n",
    "output_file = r\"C:\\Users\\m\\Desktop\\Î®∏Ïã†Îü¨Îãù ÏÇ¨Ïö© Îç∞Ïù¥ÌÑ∞\\ÌîºÏ≤òÏóîÏßÄÎãàÏñ¥ÎßÅÌïúÌÜµÌï©Îç∞Ïù¥ÌÑ∞\\Ï∂îÏ†ï_ÏùºÎ≥Ñ_Îß§Ï∂ú_Îç∞Ïù¥ÌÑ∞.csv\"\n",
    "result_df.to_csv(output_file, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(f\"Ï∂îÏ†ï Í≤∞Í≥ºÍ∞Ä '{output_file}'Ïóê Ï†ÄÏû•ÎêòÏóàÏäµÎãàÎã§.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The `window_length` and `fh` are incompatible with the length of `y`",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 38\u001b[0m\n\u001b[0;32m     35\u001b[0m forecaster \u001b[38;5;241m=\u001b[39m make_reduction(RandomForestRegressor(), window_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecursive\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# Î™®Îç∏ ÌïôÏäµ\u001b[39;00m\n\u001b[1;32m---> 38\u001b[0m forecaster\u001b[38;5;241m.\u001b[39mfit(y_train)\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# ÏòàÏ∏° ÏàòÌñâ\u001b[39;00m\n\u001b[0;32m     41\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m forecaster\u001b[38;5;241m.\u001b[39mpredict(fh)\n",
      "File \u001b[1;32mc:\\Users\\m\\anaconda3\\Lib\\site-packages\\sktime\\forecasting\\base\\_base.py:395\u001b[0m, in \u001b[0;36mBaseForecaster.fit\u001b[1;34m(self, y, X, fh)\u001b[0m\n\u001b[0;32m    393\u001b[0m \u001b[38;5;66;03m# we call the ordinary _fit if no looping/vectorization needed\u001b[39;00m\n\u001b[0;32m    394\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m vectorization_needed:\n\u001b[1;32m--> 395\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit(y\u001b[38;5;241m=\u001b[39my_inner, X\u001b[38;5;241m=\u001b[39mX_inner, fh\u001b[38;5;241m=\u001b[39mfh)\n\u001b[0;32m    396\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    397\u001b[0m     \u001b[38;5;66;03m# otherwise we call the vectorized version of fit\u001b[39;00m\n\u001b[0;32m    398\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_vectorize(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m, y\u001b[38;5;241m=\u001b[39my_inner, X\u001b[38;5;241m=\u001b[39mX_inner, fh\u001b[38;5;241m=\u001b[39mfh)\n",
      "File \u001b[1;32mc:\\Users\\m\\anaconda3\\Lib\\site-packages\\sktime\\forecasting\\compose\\_reduce.py:940\u001b[0m, in \u001b[0;36m_RecursiveReducer._fit\u001b[1;34m(self, y, X, fh)\u001b[0m\n\u001b[0;32m    933\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformers_ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m n_timepoints \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mmax\u001b[39m(ts):\n\u001b[0;32m    934\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    935\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNot sufficient observations to calculate transformations\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    936\u001b[0m             \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease reduce window length / window lagging to match\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    937\u001b[0m             \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobservation size\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    938\u001b[0m         )\n\u001b[1;32m--> 940\u001b[0m yt, Xt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform(y, X)\n\u001b[0;32m    942\u001b[0m \u001b[38;5;66;03m# Make sure yt is 1d array to avoid DataConversion warning from scikit-learn.\u001b[39;00m\n\u001b[0;32m    943\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformers_ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\m\\anaconda3\\Lib\\site-packages\\sktime\\forecasting\\compose\\_reduce.py:847\u001b[0m, in \u001b[0;36m_RecursiveReducer._transform\u001b[1;34m(self, y, X)\u001b[0m\n\u001b[0;32m    842\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_transform\u001b[39m(\u001b[38;5;28mself\u001b[39m, y, X\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    843\u001b[0m     \u001b[38;5;66;03m# For the recursive strategy, the forecasting horizon for the sliding-window\u001b[39;00m\n\u001b[0;32m    844\u001b[0m     \u001b[38;5;66;03m# transform is simply a one-step ahead horizon, regardless of the horizon\u001b[39;00m\n\u001b[0;32m    845\u001b[0m     \u001b[38;5;66;03m# used during prediction.\u001b[39;00m\n\u001b[0;32m    846\u001b[0m     fh \u001b[38;5;241m=\u001b[39m ForecastingHorizon([\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m--> 847\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _sliding_window_transform(\n\u001b[0;32m    848\u001b[0m         y,\n\u001b[0;32m    849\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwindow_length_,\n\u001b[0;32m    850\u001b[0m         fh,\n\u001b[0;32m    851\u001b[0m         X\u001b[38;5;241m=\u001b[39mX,\n\u001b[0;32m    852\u001b[0m         transformers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformers_,\n\u001b[0;32m    853\u001b[0m         scitype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_estimator_scitype,\n\u001b[0;32m    854\u001b[0m         pooling\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooling,\n\u001b[0;32m    855\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\m\\anaconda3\\Lib\\site-packages\\sktime\\forecasting\\compose\\_reduce.py:156\u001b[0m, in \u001b[0;36m_sliding_window_transform\u001b[1;34m(y, window_length, fh, X, transformers, scitype, pooling, windows_identical)\u001b[0m\n\u001b[0;32m    153\u001b[0m fh_max \u001b[38;5;241m=\u001b[39m fh[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m window_length \u001b[38;5;241m+\u001b[39m fh_max \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m n_timepoints:\n\u001b[1;32m--> 156\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    157\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe `window_length` and `fh` are incompatible with the length of `y`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    158\u001b[0m     )\n\u001b[0;32m    160\u001b[0m \u001b[38;5;66;03m# Get the effective window length accounting for the forecasting horizon.\u001b[39;00m\n\u001b[0;32m    161\u001b[0m effective_window_length \u001b[38;5;241m=\u001b[39m window_length \u001b[38;5;241m+\u001b[39m fh_max\n",
      "\u001b[1;31mValueError\u001b[0m: The `window_length` and `fh` are incompatible with the length of `y`"
     ]
    }
   ],
   "source": [
    "from sktime.forecasting.compose import make_reduction\n",
    "from sktime.forecasting.base import ForecastingHorizon\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Îç∞Ïù¥ÌÑ∞ Î°úÎìú\n",
    "df = pd.read_csv(r\"C:\\Users\\m\\Desktop\\Î®∏Ïã†Îü¨Îãù ÏÇ¨Ïö© Îç∞Ïù¥ÌÑ∞\\ÌîºÏ≤òÏóîÏßÄÎãàÏñ¥ÎßÅÌïúÌÜµÌï©Îç∞Ïù¥ÌÑ∞\\ÌîºÏ≤òÏóîÏßÄÎãàÏñ¥ÎßÅÏùºÎã®Îã§ÌïúÌÜµÌï©Îç∞Ïù¥ÌÑ∞.csv\")\n",
    "\n",
    "# Îç∞Ïù¥ÌÑ∞ Ï†ïÎ†¨\n",
    "df = df.sort_values('Í∏∞Ï§Ä_ÎÖÑÎ∂ÑÍ∏∞_ÏΩîÎìú')\n",
    "\n",
    "# ÌäπÏ†ï ÏÉÅÍ∂åÍ≥º ÏóÖÏ¢Ö ÏÑ†ÌÉù (ÏÇ¨Ïö©Ïûê Îç∞Ïù¥ÌÑ∞Ïóê ÎßûÍ≤å ÏàòÏ†ï)\n",
    "target_data = df[(df[\"ÏÉÅÍ∂å_ÏΩîÎìú_Î™Ö\"] == \"ÏÉÅÍ∂åA\") & (df[\"ÏÑúÎπÑÏä§_ÏóÖÏ¢Ö_ÏΩîÎìú_Î™Ö\"] == \"ÏóÖÏ¢ÖA\")]\n",
    "\n",
    "# ÌïÑÏöîÌïú Ïª¨ÎüºÎßå ÏÑ†ÌÉù\n",
    "target_data = target_data[['Í∏∞Ï§Ä_ÎÖÑÎ∂ÑÍ∏∞_ÏΩîÎìú', 'ÏõîÏöîÏùº_Îß§Ï∂ú_Í∏àÏï°', 'ÌôîÏöîÏùº_Îß§Ï∂ú_Í∏àÏï°',\n",
    "                           'ÏàòÏöîÏùº_Îß§Ï∂ú_Í∏àÏï°', 'Î™©ÏöîÏùº_Îß§Ï∂ú_Í∏àÏï°',\n",
    "                           'Í∏àÏöîÏùº_Îß§Ï∂ú_Í∏àÏï°', 'ÌÜ†ÏöîÏùº_Îß§Ï∂ú_Í∏àÏï°', 'ÏùºÏöîÏùº_Îß§Ï∂ú_Í∏àÏï°']]\n",
    "\n",
    "# Í∏∞Ï§Ä Ïó∞Î∂ÑÍ∏∞Î•º Ïù∏Îç±Ïä§Î°ú ÏÑ§Ï†ï\n",
    "target_data.set_index('Í∏∞Ï§Ä_ÎÖÑÎ∂ÑÍ∏∞_ÏΩîÎìú', inplace=True)\n",
    "\n",
    "# ÏãúÍ≥ÑÏó¥ Îç∞Ïù¥ÌÑ∞ Î≥ÄÌôò (ÏöîÏùºÎ≥Ñ Îß§Ï∂úÏùò Ìï©)\n",
    "y = target_data.sum(axis=1)\n",
    "\n",
    "# ÌïôÏäµ/ÌÖåÏä§Ìä∏ Îç∞Ïù¥ÌÑ∞ Î∂ÑÎ¶¨\n",
    "y_train, y_test = temporal_train_test_split(y, test_size=4)\n",
    "\n",
    "# ÏòàÏ∏°Ìï† ÏãúÏ†ê ÏÑ§Ï†ï\n",
    "fh = ForecastingHorizon(np.arange(1, len(y_test) + 1))\n",
    "\n",
    "# Î™®Îç∏ Íµ¨ÏÑ±\n",
    "forecaster = make_reduction(RandomForestRegressor(), window_length=4, strategy=\"recursive\")\n",
    "\n",
    "# Î™®Îç∏ ÌïôÏäµ\n",
    "forecaster.fit(y_train)\n",
    "\n",
    "# ÏòàÏ∏° ÏàòÌñâ\n",
    "y_pred = forecaster.predict(fh)\n",
    "\n",
    "# Í≤∞Í≥º Ï†ÄÏû•Ïö© DataFrame ÏÉùÏÑ±\n",
    "prediction_dates = pd.date_range(start='2024-04-01', periods=len(y_pred), freq='D')  # ÏãúÏûë ÎÇ†ÏßúÎäî ÏòàÏ†ú\n",
    "weekday_names = [\"Ïõî\", \"Ìôî\", \"Ïàò\", \"Î™©\", \"Í∏à\", \"ÌÜ†\", \"Ïùº\"]\n",
    "\n",
    "results = pd.DataFrame({\n",
    "    \"ÎÇ†Ïßú\": prediction_dates,\n",
    "    \"ÏöîÏùº\": [weekday_names[date.weekday()] for date in prediction_dates],\n",
    "    \"ÏÉÅÍ∂å\": \"ÏÉÅÍ∂åA\",\n",
    "    \"ÏóÖÏ¢Ö\": \"ÏóÖÏ¢ÖA\",\n",
    "    \"Îß§Ï∂ú_Í∏àÏï°\": y_pred.values\n",
    "})\n",
    "\n",
    "# ÌååÏùº Ï†ÄÏû•\n",
    "results.to_csv(\"Îß§Ï∂ú_Ï∂îÏ†ï_Í≤∞Í≥º.csv\", index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(\"ÏòàÏ∏° Í≤∞Í≥ºÍ∞Ä 'Îß§Ï∂ú_Ï∂îÏ†ï_Í≤∞Í≥º.csv' ÌååÏùºÎ°ú Ï†ÄÏû•ÎêòÏóàÏäµÎãàÎã§.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r\"C:\\Users\\dlwlg\\Desktop\\ÌîºÏ≤òÏóîÏßÄÎãàÏñ¥ÎßÅÌïúÌÜµÌï©Îç∞Ïù¥ÌÑ∞\\ÌîºÏ≤òÏóîÏßÄÎãàÏñ¥ÎßÅÏùºÎã®Îã§ÌïúÌÜµÌï©Îç∞Ïù¥ÌÑ∞.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Îç∞Ïù¥ÌÑ∞ Ï†ÄÏû• ÏôÑÎ£å: Í≥ºÍ±∞_Ï∂îÏ†ï_Îç∞Ïù¥ÌÑ∞.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sktime.forecasting.compose import make_reduction\n",
    "from sktime.forecasting.base import ForecastingHorizon\n",
    "\n",
    "# 1. Îç∞Ïù¥ÌÑ∞ Î°úÎìú Î∞è Ï†ïÎ†¨\n",
    "df = pd.read_csv(r\"C:\\Users\\dlwlg\\Desktop\\ÌîºÏ≤òÏóîÏßÄÎãàÏñ¥ÎßÅÌïúÌÜµÌï©Îç∞Ïù¥ÌÑ∞\\ÌîºÏ≤òÏóîÏßÄÎãàÏñ¥ÎßÅÏùºÎã®Îã§ÌïúÌÜµÌï©Îç∞Ïù¥ÌÑ∞.csv\")\n",
    "df = df.sort_values(\"Í∏∞Ï§Ä_ÎÖÑÎ∂ÑÍ∏∞_ÏΩîÎìú\")\n",
    "\n",
    "# 2. Îß§Ï∂ú_Í∏àÏï° Ïª¨Îüº ÏÉùÏÑ±: ÎãπÏõî, Ï£ºÏ§ë, Ï£ºÎßê Îß§Ï∂ú Í∏àÏï°Ïùò ÌèâÍ∑† ÏÇ¨Ïö©\n",
    "df[\"Îß§Ï∂ú_Í∏àÏï°\"] = df[[\"ÎãπÏõî_Îß§Ï∂ú_Í∏àÏï°\", \"Ï£ºÏ§ë_Îß§Ï∂ú_Í∏àÏï°\", \"Ï£ºÎßê_Îß§Ï∂ú_Í∏àÏï°\"]].mean(axis=1)\n",
    "\n",
    "# 3. Î∂ÑÍ∏∞ ÏãúÏûëÏùº Í≥ÑÏÇ∞ Ìï®Ïàò (Ïòà: \"20191\" ‚Üí 2019ÎÖÑ 1Î∂ÑÍ∏∞ ‚Üí 2019-01-01)\n",
    "def get_quarter_start(qcode):\n",
    "    year = int(str(qcode)[:4])\n",
    "    quarter = int(str(qcode)[-1])\n",
    "    month = (quarter - 1) * 3 + 1\n",
    "    return pd.Timestamp(year, month, 1)\n",
    "\n",
    "df[\"ÎÇ†Ïßú\"] = df[\"Í∏∞Ï§Ä_ÎÖÑÎ∂ÑÍ∏∞_ÏΩîÎìú\"].apply(get_quarter_start)\n",
    "\n",
    "results = []\n",
    "\n",
    "# 4. Î∂ÑÍ∏∞Î≥Ñ Îç∞Ïù¥ÌÑ∞ Ï≤òÎ¶¨ Î∞è ÏòàÏ∏°\n",
    "for quarter_code, group in df.groupby(\"Í∏∞Ï§Ä_ÎÖÑÎ∂ÑÍ∏∞_ÏΩîÎìú\"):\n",
    "    # Í∑∏Î£πÏùò Ï≤´ Î≤àÏß∏ 'ÎÇ†Ïßú' Í∞í ÏÑ†ÌÉù\n",
    "    start_date = group[\"ÎÇ†Ïßú\"].iloc[0]\n",
    "    end_date = start_date + pd.DateOffset(months=3) - pd.DateOffset(days=1)\n",
    "    dates_range = pd.date_range(start=start_date, end=end_date)\n",
    "    \n",
    "    forecast_dates = pd.DataFrame({\"ÎÇ†Ïßú\": dates_range})\n",
    "    forecast_dates[\"ÏöîÏùº\"] = forecast_dates[\"ÎÇ†Ïßú\"].dt.day_name().map({\n",
    "        \"Monday\": \"Ïõî\", \"Tuesday\": \"Ìôî\", \"Wednesday\": \"Ïàò\",\n",
    "        \"Thursday\": \"Î™©\", \"Friday\": \"Í∏à\", \"Saturday\": \"ÌÜ†\", \"Sunday\": \"Ïùº\"\n",
    "    })\n",
    "    # ÏÉÅÍ∂å/ÏóÖÏ¢Ö Ï†ïÎ≥¥Îäî Í∑∏Î£πÏùò Ï≤´ Î≤àÏß∏ Í∞íÏùÑ ÏÇ¨Ïö©\n",
    "    forecast_dates[\"ÏÉÅÍ∂å\"] = group[\"ÏÉÅÍ∂å_ÏΩîÎìú_Î™Ö\"].iloc[0]\n",
    "    forecast_dates[\"ÏóÖÏ¢Ö\"] = group[\"ÏÑúÎπÑÏä§_ÏóÖÏ¢Ö_ÏΩîÎìú_Î™Ö\"].iloc[0]\n",
    "    \n",
    "    # 5. y_train Íµ¨ÏÑ± (Îß§Ï∂ú_Í∏àÏï°) Î∞è Ïù∏Îç±Ïä§Î•º DatetimeIndexÎ°ú Ïû¨ÏÑ§Ï†ï\n",
    "    y_train = group[\"Îß§Ï∂ú_Í∏àÏï°\"]\n",
    "    y_train.index = pd.date_range(start=start_date, periods=len(y_train), freq=\"D\")\n",
    "    \n",
    "    if y_train.isnull().any() or len(y_train) < 5:\n",
    "        print(f\"Insufficient data for quarter {quarter_code}\")\n",
    "        continue\n",
    "\n",
    "    forecaster = make_reduction(RandomForestRegressor(), window_length=4, strategy=\"recursive\")\n",
    "    fh = ForecastingHorizon(np.arange(1, len(forecast_dates) + 1))\n",
    "    \n",
    "    try:\n",
    "        forecaster.fit(y_train)\n",
    "        y_pred = forecaster.predict(fh)\n",
    "        forecast_dates[\"Îß§Ï∂ú_Í∏àÏï°\"] = y_pred\n",
    "        results.append(forecast_dates)\n",
    "    except Exception as e:\n",
    "        print(f\"Error for {quarter_code}: {e}\")\n",
    "        continue\n",
    "\n",
    "# 6. Í≤∞Í≥º Î≥ëÌï© Î∞è Ï†ÄÏû•\n",
    "if results:\n",
    "    final_df = pd.concat(results, ignore_index=True)\n",
    "    final_df.to_csv(r\"C:\\Users\\dlwlg\\Desktop\\ÌîºÏ≤òÏóîÏßÄÎãàÏñ¥ÎßÅÌïúÌÜµÌï©Îç∞Ïù¥ÌÑ∞\\Í≥ºÍ±∞_Ï∂îÏ†ï_Îç∞Ïù¥ÌÑ∞.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "    print(\"Îç∞Ïù¥ÌÑ∞ Ï†ÄÏû• ÏôÑÎ£å: Í≥ºÍ±∞_Ï∂îÏ†ï_Îç∞Ïù¥ÌÑ∞.csv\")\n",
    "else:\n",
    "    print(\"No data to save.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mport pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Îç∞Ïù¥ÌÑ∞ Î∂àÎü¨Ïò§Í∏∞\n",
    "data_path = \"C:\\\\Users\\\\m\\\\Desktop\\\\Î®∏Ïã†Îü¨Îãù ÏÇ¨Ïö© Îç∞Ïù¥ÌÑ∞\\\\ÌîºÏ≤òÏóîÏßÄÎãàÏñ¥ÎßÅÌïúÌÜµÌï©Îç∞Ïù¥ÌÑ∞\\\\ÌîºÏ≤òÏóîÏßÄÎãàÏñ¥ÎßÅÏùºÎã®Îã§ÌïúÌÜµÌï©Îç∞Ïù¥ÌÑ∞.csv\"\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "# ÌïÑÏöîÌïú Ïª¨Îüº ÏÑ†ÌÉù\n",
    "df = df[[\"Í∏∞Ï§Ä_ÎÖÑÎ∂ÑÍ∏∞_ÏΩîÎìú\", \"ÏÉÅÍ∂å_ÏΩîÎìú_Î™Ö\", \"ÏÑúÎπÑÏä§_ÏóÖÏ¢Ö_ÏΩîÎìú_Î™Ö\", \n",
    "          \"ÏõîÏöîÏùº_Îß§Ï∂ú_Í∏àÏï°\", \"ÌôîÏöîÏùº_Îß§Ï∂ú_Í∏àÏï°\", \"ÏàòÏöîÏùº_Îß§Ï∂ú_Í∏àÏï°\", \n",
    "          \"Î™©ÏöîÏùº_Îß§Ï∂ú_Í∏àÏï°\", \"Í∏àÏöîÏùº_Îß§Ï∂ú_Í∏àÏï°\", \"ÌÜ†ÏöîÏùº_Îß§Ï∂ú_Í∏àÏï°\", \"ÏùºÏöîÏùº_Îß§Ï∂ú_Í∏àÏï°\"]]\n",
    "\n",
    "# Îß§Ï∂ú Îç∞Ïù¥ÌÑ∞Î•º ÏùºÎã®ÏúÑÎ°ú ÌéºÏπòÍ∏∞ ÏúÑÌï¥ ÏöîÏùº Ï†ïÎ≥¥Î•º Ï†ïÎ¶¨\n",
    "days = [\"ÏõîÏöîÏùº_Îß§Ï∂ú_Í∏àÏï°\", \"ÌôîÏöîÏùº_Îß§Ï∂ú_Í∏àÏï°\", \"ÏàòÏöîÏùº_Îß§Ï∂ú_Í∏àÏï°\",\n",
    "        \"Î™©ÏöîÏùº_Îß§Ï∂ú_Í∏àÏï°\", \"Í∏àÏöîÏùº_Îß§Ï∂ú_Í∏àÏï°\", \"ÌÜ†ÏöîÏùº_Îß§Ï∂ú_Í∏àÏï°\", \"ÏùºÏöîÏùº_Îß§Ï∂ú_Í∏àÏï°\"]\n",
    "\n",
    "# ÏãúÍ≥ÑÏó¥ Ìå®ÌÑ¥ Îç∞Ïù¥ÌÑ∞ Ï§ÄÎπÑ\n",
    "sequences = []\n",
    "group_keys = []\n",
    "\n",
    "for key, group in df.groupby([\"ÏÉÅÍ∂å_ÏΩîÎìú_Î™Ö\", \"ÏÑúÎπÑÏä§_ÏóÖÏ¢Ö_ÏΩîÎìú_Î™Ö\"]):\n",
    "    sales_data = group[days].values.flatten()\n",
    "    if len(sales_data) >= 7:\n",
    "        sequences.append(sales_data)\n",
    "        group_keys.append(key)\n",
    "\n",
    "# Ïú†Ìö® Îç∞Ïù¥ÌÑ∞ ÌôïÏù∏\n",
    "if not sequences:\n",
    "    raise ValueError(\"Ïú†Ìö®Ìïú ÏãúÍ≥ÑÏó¥ Îç∞Ïù¥ÌÑ∞Í∞Ä ÏóÜÏäµÎãàÎã§.\")\n",
    "\n",
    "# Î¶¨Ïä§Ìä∏Î•º Î∞∞Ïó¥Î°ú Î≥ÄÌôò\n",
    "sequences = np.array([seq[:7] for seq in sequences if len(seq) >= 7])\n",
    "\n",
    "# Îç∞Ïù¥ÌÑ∞ Ï∞®Ïõê ÌôïÏû• (LSTM ÏûÖÎ†• ÏöîÍµ¨ Ï°∞Í±¥)\n",
    "X = sequences[:, :-1].reshape((-1, 6, 1))\n",
    "y = sequences[:, -1].reshape((-1, 1))\n",
    "\n",
    "# Î™®Îç∏ Íµ¨ÏÑ±\n",
    "input_layer = Input(shape=(6, 1))\n",
    "lstm_layer = LSTM(50)(input_layer)\n",
    "output_layer = Dense(1)(lstm_layer)\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# Î™®Îç∏ Ïª¥ÌååÏùº Î∞è ÌïôÏäµ\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
    "model.fit(X, y, epochs=10, batch_size=32)\n",
    "\n",
    "# Îç∞Ïù¥ÌÑ∞ Ï∂îÏ†ï Î∞è Ï†ÄÏû•\n",
    "results = []\n",
    "\n",
    "for key, sales_data in zip(group_keys, sequences):\n",
    "    # ÏûÖÎ†• Îç∞Ïù¥ÌÑ∞ Íµ¨ÏÑ±\n",
    "    input_data = sales_data[:-1].reshape(1, 6, 1)\n",
    "    predicted_value = model.predict(input_data)[0][0]\n",
    "\n",
    "    # Í∏∞Ï°¥ Îç∞Ïù¥ÌÑ∞Ïóê Ï∂îÏ†ïÎêú Í∞í Ï∂îÍ∞Ä\n",
    "    for i, day in enumerate(days):\n",
    "        results.append({\n",
    "            \"ÎÇ†Ïßú\": f\"{key[0]}_{day}\",\n",
    "            \"ÏöîÏùº\": day.split('_')[0],\n",
    "            \"ÏÉÅÍ∂å\": key[0],\n",
    "            \"ÏóÖÏ¢Ö\": key[1],\n",
    "            \"Îß§Ï∂ú_Í∏àÏï°\": sales_data[i] if i < 6 else predicted_value\n",
    "        })\n",
    "\n",
    "# Í≤∞Í≥ºÎ•º DataFrameÏúºÎ°ú Î≥ÄÌôò\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Îç∞Ïù¥ÌÑ∞ Ï†ÄÏû•\n",
    "output_path = \"C:\\\\Users\\\\m\\\\Desktop\\\\Î®∏Ïã†Îü¨Îãù ÏÇ¨Ïö© Îç∞Ïù¥ÌÑ∞\\\\ÌîºÏ≤òÏóîÏßÄÎãàÏñ¥ÎßÅÌïúÌÜµÌï©Îç∞Ïù¥ÌÑ∞\\\\Ï∂îÏ†ïÍ≤∞Í≥º_Îç∞Ïù¥ÌÑ∞.csv\"\n",
    "results_df.to_csv(output_path, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(\"Îç∞Ïù¥ÌÑ∞ Ï∂îÏ†ï Î∞è Ï†ÄÏû• ÏôÑÎ£å!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import datetime\n",
    "\n",
    "# Îç∞Ïù¥ÌÑ∞ Î°úÎìú\n",
    "df = pd.read_csv(r\"C:\\Users\\dlwlg\\Desktop\\ÌîºÏ≤òÏóîÏßÄÎãàÏñ¥ÎßÅÌïúÌÜµÌï©Îç∞Ïù¥ÌÑ∞\\ÌîºÏ≤òÏóîÏßÄÎãàÏñ¥ÎßÅÏùºÎã®Îã§ÌïúÌÜµÌï©Îç∞Ïù¥ÌÑ∞.csv\")\n",
    "\n",
    "# ÏöîÏùº Ïª¨Îüº Î¶¨Ïä§Ìä∏\n",
    "days = [\"ÏõîÏöîÏùº_Îß§Ï∂ú_Í∏àÏï°\", \"ÌôîÏöîÏùº_Îß§Ï∂ú_Í∏àÏï°\", \"ÏàòÏöîÏùº_Îß§Ï∂ú_Í∏àÏï°\", \"Î™©ÏöîÏùº_Îß§Ï∂ú_Í∏àÏï°\", \"Í∏àÏöîÏùº_Îß§Ï∂ú_Í∏àÏï°\", \"ÌÜ†ÏöîÏùº_Îß§Ï∂ú_Í∏àÏï°\", \"ÏùºÏöîÏùº_Îß§Ï∂ú_Í∏àÏï°\"]\n",
    "\n",
    "# NaN Í∞í Ï≤òÎ¶¨\n",
    "df = df.dropna()\n",
    "\n",
    "# Îç∞Ïù¥ÌÑ∞ Ïä§ÏºÄÏùºÎßÅ\n",
    "scaler = MinMaxScaler()\n",
    "scaled_values = scaler.fit_transform(df[days])\n",
    "df[days] = scaled_values\n",
    "\n",
    "# ÏãúÍ≥ÑÏó¥ Îç∞Ïù¥ÌÑ∞Î•º ÏúÑÌïú Í∑∏Î£πÌôî Î∞è ÏãúÌÄÄÏä§ ÏÉùÏÑ±\n",
    "group_keys = []\n",
    "sequences = []\n",
    "\n",
    "for key, group in df.groupby([\"Í∏∞Ï§Ä_ÎÖÑÎ∂ÑÍ∏∞_ÏΩîÎìú\", \"ÏÉÅÍ∂å_ÏΩîÎìú_Î™Ö\", \"ÏÑúÎπÑÏä§_ÏóÖÏ¢Ö_ÏΩîÎìú_Î™Ö\"]):\n",
    "    sales_data = group[days].values.flatten()\n",
    "    if len(sales_data) >= len(days):  # ÌïÑÏöîÌïú Í∏∏Ïù¥Îßå Ìè¨Ìï®\n",
    "        sequences.append(sales_data)\n",
    "        group_keys.append(key)\n",
    "\n",
    "# LSTM Î™®Îç∏ Íµ¨ÏÑ±\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, activation='relu', input_shape=(6, 1)))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer=Adam(learning_rate=0.01), loss='mse')\n",
    "\n",
    "# Îç∞Ïù¥ÌÑ∞ Ï§ÄÎπÑ\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for sequence in sequences:\n",
    "    X.append(sequence[:-1])  # ÏûÖÎ†• Í∞í (6ÏùºÏπò)\n",
    "    y.append(sequence[-1])   # ÌÉÄÍπÉ Í∞í (7Î≤àÏß∏ Í∞í)\n",
    "\n",
    "X = np.array(X).reshape(-1, 6, 1)\n",
    "y = np.array(y)\n",
    "\n",
    "# Î™®Îç∏ ÌïôÏäµ\n",
    "model.fit(X, y, epochs=10, batch_size=32)\n",
    "\n",
    "# Î∂ÑÍ∏∞ ÏΩîÎìúÎ°ú ÎÇ†Ïßú Î™©Î°ù ÏÉùÏÑ± Ìï®Ïàò\n",
    "def generate_dates_for_quarter(quarter_code):\n",
    "    try:\n",
    "        year = int(str(quarter_code)[:4])\n",
    "        quarter = int(str(quarter_code)[-1])\n",
    "\n",
    "        # Î∂ÑÍ∏∞ ÏãúÏûë ÎÇ†Ïßú Î∞è Ï¢ÖÎ£å ÎÇ†Ïßú ÏÑ§Ï†ï\n",
    "        if quarter == 1:\n",
    "            start_date = datetime.date(year, 1, 1)\n",
    "            end_date = datetime.date(year, 3, 31)\n",
    "        elif quarter == 2:\n",
    "            start_date = datetime.date(year, 4, 1)\n",
    "            end_date = datetime.date(year, 6, 30)\n",
    "        elif quarter == 3:\n",
    "            start_date = datetime.date(year, 7, 1)\n",
    "            end_date = datetime.date(year, 9, 30)\n",
    "        elif quarter == 4:\n",
    "            start_date = datetime.date(year, 10, 1)\n",
    "            end_date = datetime.date(year, 12, 31)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid quarter code\")\n",
    "        \n",
    "        delta = end_date - start_date\n",
    "        dates = [start_date + datetime.timedelta(days=i) for i in range(delta.days + 1)]\n",
    "        return dates\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating dates for quarter code {quarter_code}: {e}\")\n",
    "        return []\n",
    "\n",
    "# Í≤∞Í≥º Ï†ÄÏû• Î¶¨Ïä§Ìä∏\n",
    "results = []\n",
    "\n",
    "for key, sales_data in zip(group_keys, sequences):\n",
    "    quarter_code = key[0]  # Í∏∞Ï§Ä_ÎÖÑÎ∂ÑÍ∏∞_ÏΩîÎìú ÏÇ¨Ïö©\n",
    "    input_data = sales_data[:-1].reshape(1, 6, 1)\n",
    "    \n",
    "    # ÏòàÏ∏°Í∞í Ïó≠Î≥ÄÌôò Ïãú Ïä§ÏºÄÏùºÎü¨ ÌòïÏÉÅÏóê ÎßûÍ≤å Ï°∞Ï†ï\n",
    "    predicted_value_raw = model.predict(input_data)\n",
    "    predicted_value_padded = np.pad(predicted_value_raw, ((0, 0), (0, len(days) - predicted_value_raw.shape[1])), mode='constant')\n",
    "    predicted_value = scaler.inverse_transform(predicted_value_padded)[0][0]\n",
    "\n",
    "    # Î∂ÑÍ∏∞Ïóê Ìï¥ÎãπÌïòÎäî ÎÇ†Ïßú Î™©Î°ù ÏÉùÏÑ±\n",
    "    dates = generate_dates_for_quarter(quarter_code)\n",
    "\n",
    "    for i, day in enumerate(days):\n",
    "        if i < len(dates):  # ÎÇ†ÏßúÍ∞Ä ÏûàÎäî Î≤îÏúÑÍπåÏßÄÎßå Ï≤òÎ¶¨\n",
    "            results.append({\n",
    "                \"ÎÇ†Ïßú\": dates[i].strftime('%Y-%m-%d'),\n",
    "                \"ÏöîÏùº\": day.split('_')[0],\n",
    "                \"ÏÉÅÍ∂å\": key[1],\n",
    "                \"ÏóÖÏ¢Ö\": key[2],\n",
    "                \"Îß§Ï∂ú_Í∏àÏï°\": sales_data[i] if i < len(sales_data) else predicted_value\n",
    "            })\n",
    "\n",
    "# Í≤∞Í≥º DataFrame ÏÉùÏÑ± Î∞è Ï†ÄÏû•\n",
    "result_df = pd.DataFrame(results)\n",
    "result_df.to_csv(r\"C:\\Users\\dlwlg\\Desktop\\ÌîºÏ≤òÏóîÏßÄÎãàÏñ¥ÎßÅÌïúÌÜµÌï©Îç∞Ïù¥ÌÑ∞\\test.csv\", index=False, encoding='utf-8-sig')\n",
    "print(\"Results saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
