{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 모델 검증 결과\n",
      "MAPE (평균 절대 퍼센트 오차): 0.0000\n",
      "RMSE (평균 제곱근 오차): 0.0000\n",
      "\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 104\u001b[0m\n\u001b[0;32m    101\u001b[0m predicted_ratio \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(future_X)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    103\u001b[0m \u001b[38;5;66;03m# 16. 2024년 3분기 자치구 매출 예측 후 상권별 적용\u001b[39;00m\n\u001b[1;32m--> 104\u001b[0m district_total_future_sales \u001b[38;5;241m=\u001b[39m district_sales_grouped[district_sales_grouped[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m기준_년분기\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m future_quarter][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m자치구_총매출\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    105\u001b[0m predicted_sales \u001b[38;5;241m=\u001b[39m district_total_future_sales \u001b[38;5;241m*\u001b[39m predicted_ratio\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m📌 선택한 상권: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mselected_district\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_percentage_error, mean_squared_error\n",
    "\n",
    "# 데이터 경로 설정\n",
    "base_path = \"C:/Users/m/Desktop/머신러닝 사용 데이터\"\n",
    "sales_data_path = f\"{base_path}/구 데이터/피처엔지니어링한통합데이터/피처엔지니어링일단다한통합데이터.csv\"\n",
    "pop_data_path = f\"{base_path}/서울 일별 유동인구.csv\"\n",
    "econ_index_path = f\"{base_path}/전처리 데이터/경제심리지수.csv\"\n",
    "cpi_data_path = f\"{base_path}/전처리 데이터/소비자물가지수.csv\"\n",
    "\n",
    "# 1. 데이터 로드\n",
    "sales_df = pd.read_csv(sales_data_path)\n",
    "pop_df = pd.read_csv(pop_data_path)\n",
    "econ_df = pd.read_csv(econ_index_path)\n",
    "cpi_df = pd.read_csv(cpi_data_path)\n",
    "\n",
    "# 2. 데이터 전처리\n",
    "# 기준_년분기_코드 변환 (20191 → 2019Q1)\n",
    "sales_df[\"기준_년분기\"] = sales_df[\"기준_년분기_코드\"].astype(str).apply(lambda x: f\"{x[:4]}Q{int(x[4])}\")\n",
    "\n",
    "# 사용자 입력값 받기 (올바른 값이 입력될 때까지 반복)\n",
    "while True:\n",
    "    selected_district = input(\"예측할 상권명을 입력하세요: \").strip()\n",
    "    selected_industry = input(\"예측할 업종명을 입력하세요: \").strip()\n",
    "\n",
    "    # 3. 선택한 상권-업종 데이터 필터링\n",
    "    filtered_sales = sales_df[(sales_df[\"상권_코드_명\"] == selected_district) &\n",
    "                              (sales_df[\"서비스_업종_코드_명\"] == selected_industry)]\n",
    "\n",
    "    if not filtered_sales.empty:\n",
    "        break  # 유효한 데이터가 있으면 반복 종료\n",
    "    else:\n",
    "        print(\"⚠️ 입력한 상권명 또는 업종명이 데이터에 없습니다. 다시 입력하세요.\\n\")\n",
    "\n",
    "# 4. 해당 상권이 속한 자치구 찾기\n",
    "selected_district_code = filtered_sales[\"자치구_코드_명\"].iloc[0]\n",
    "\n",
    "# 5. 해당 자치구 전체 매출 데이터 가져오기\n",
    "district_sales = sales_df[sales_df[\"자치구_코드_명\"] == selected_district_code]\n",
    "\n",
    "# 6. 분기별 자치구 전체 매출 합산\n",
    "district_sales_grouped = district_sales.groupby(\"기준_년분기\")[\"당월_매출_금액\"].sum().reset_index()\n",
    "district_sales_grouped.rename(columns={\"당월_매출_금액\": \"자치구_총매출\"}, inplace=True)\n",
    "\n",
    "# 7. 해당 상권이 차지하는 비율 계산\n",
    "sales_with_ratio = filtered_sales.merge(district_sales_grouped, on=\"기준_년분기\")\n",
    "sales_with_ratio[\"매출_비율\"] = sales_with_ratio[\"당월_매출_금액\"] / sales_with_ratio[\"자치구_총매출\"]\n",
    "\n",
    "# 8. 유동인구 데이터 연결 (자치구 기준)\n",
    "pop_df.rename(columns={\"시군구명\": \"자치구_코드_명\", \"총생활인구수\": \"유동인구\"}, inplace=True)\n",
    "sales_with_ratio = sales_with_ratio.merge(pop_df[[\"자치구_코드_명\", \"유동인구\"]], on=\"자치구_코드_명\", how=\"left\")\n",
    "\n",
    "# 9. 경제심리지수 및 소비자물가지수 연결\n",
    "econ_df[\"날짜\"] = pd.to_datetime(econ_df[\"날짜\"])\n",
    "cpi_df[\"날짜\"] = pd.to_datetime(cpi_df[\"날짜\"])\n",
    "\n",
    "econ_df[\"기준_년분기\"] = econ_df[\"날짜\"].dt.to_period(\"Q\").astype(str)\n",
    "cpi_df[\"기준_년분기\"] = cpi_df[\"날짜\"].dt.to_period(\"Q\").astype(str)\n",
    "\n",
    "sales_with_ratio = sales_with_ratio.merge(econ_df[[\"기준_년분기\", \"경제심리지수\"]], on=\"기준_년분기\", how=\"left\")\n",
    "sales_with_ratio = sales_with_ratio.merge(cpi_df[[\"기준_년분기\", \"소비자물가지수\"]], on=\"기준_년분기\", how=\"left\")\n",
    "\n",
    "# 10. 학습용 데이터 준비\n",
    "features = [\"유동인구\", \"경제심리지수\", \"소비자물가지수\"]\n",
    "target = \"매출_비율\"\n",
    "\n",
    "sales_with_ratio.dropna(inplace=True)  # 결측치 제거\n",
    "X = sales_with_ratio[features]\n",
    "y = sales_with_ratio[target]\n",
    "\n",
    "# 11. 학습/검증 데이터 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 12. 모델 학습\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 13. 검증 데이터 평가\n",
    "y_pred = model.predict(X_test)\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "print(f\"\\n📊 모델 검증 결과\")\n",
    "print(f\"MAPE (평균 절대 퍼센트 오차): {mape:.4f}\")\n",
    "print(f\"RMSE (평균 제곱근 오차): {rmse:.4f}\\n\")\n",
    "\n",
    "# 14. 전체 데이터로 다시 학습 후 2024년 3분기 예측\n",
    "model.fit(X, y)\n",
    "\n",
    "# 15. 2024년 3분기 예측을 위한 데이터 생성\n",
    "future_quarter = \"2024Q3\"\n",
    "latest_cpi = cpi_df[cpi_df[\"기준_년분기\"] == future_quarter][\"소비자물가지수\"].values[0]\n",
    "latest_econ = econ_df[econ_df[\"기준_년분기\"] == future_quarter][\"경제심리지수\"].values[0]\n",
    "latest_pop = pop_df[pop_df[\"자치구_코드_명\"] == selected_district_code][\"유동인구\"].mean()\n",
    "\n",
    "future_X = pd.DataFrame([[latest_pop, latest_econ, latest_cpi]], columns=features)\n",
    "predicted_ratio = model.predict(future_X)[0]\n",
    "\n",
    "# 16. 2024년 3분기 자치구 매출 예측 후 상권별 적용\n",
    "district_total_future_sales = district_sales_grouped[district_sales_grouped[\"기준_년분기\"] == future_quarter][\"자치구_총매출\"].values[0]\n",
    "predicted_sales = district_total_future_sales * predicted_ratio\n",
    "\n",
    "print(f\"📌 선택한 상권: {selected_district}\")\n",
    "print(f\"📌 선택한 업종: {selected_industry}\")\n",
    "print(f\"📈 예측된 2024년 3분기 매출: {predicted_sales:,.0f} 원\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1169470658.py, line 39)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[3], line 39\u001b[1;36m\u001b[0m\n\u001b[1;33m    sales_ratio = filtered_sales.groupby(\"기준_년분기\")[\"당월_매출_금액\"].sum() /\u001b[0m\n\u001b[1;37m                                                                       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# 파일 경로 설정\n",
    "sales_data_path = \"C:\\\\Users\\\\m\\\\Desktop\\\\머신러닝 사용 데이터\\\\구 데이터\\\\피처엔지니어링한통합데이터\\\\피처엔지니어링일단다한통합데이터.csv\"\n",
    "pop_data_path = \"C:\\\\Users\\\\m\\\\Desktop\\\\머신러닝 사용 데이터\\\\서울 일별 유동인구.csv\"\n",
    "econ_index_path = \"C:\\\\Users\\\\m\\\\Desktop\\\\머신러닝 사용 데이터\\\\전처리 데이터\\\\경제심리지수.csv\"\n",
    "cpi_data_path = \"C:\\\\Users\\\\m\\\\Desktop\\\\머신러닝 사용 데이터\\\\전처리 데이터\\\\소비자물가지수.csv\"\n",
    "\n",
    "# 데이터 로드\n",
    "sales_df = pd.read_csv(sales_data_path)\n",
    "pop_df = pd.read_csv(pop_data_path)\n",
    "econ_df = pd.read_csv(econ_index_path)\n",
    "cpi_df = pd.read_csv(cpi_data_path)\n",
    "\n",
    "# 사용자 입력\n",
    "selected_district = input(\"자치구를 입력하세요: \")\n",
    "selected_business = input(\"업종명을 입력하세요: \")\n",
    "\n",
    "# 2019~2024년 2분기까지의 데이터 필터링\n",
    "sales_df = sales_df[sales_df['기준_년분기_코드'] <= 20242]\n",
    "filtered_sales = sales_df[(sales_df['상권_코드_명'] == selected_district) & \n",
    "                           (sales_df['서비스_업종_코드_명'] == selected_business)]\n",
    "\n",
    "if filtered_sales.empty:\n",
    "    raise ValueError(\"선택한 상권-업종 데이터가 없습니다.\")\n",
    "\n",
    "# 자치구 매출 총합 계산\n",
    "sales_df['기준_년분기'] = sales_df['기준_년분기_코드']\n",
    "district_sales_grouped = sales_df.groupby(['기준_년분기', '자치구_코드_명'])['당월_매출_금액'].sum().reset_index()\n",
    "district_sales_grouped.rename(columns={'당월_매출_금액': '자치구_총매출'}, inplace=True)\n",
    "\n",
    "# 선택한 상권의 자치구 찾기\n",
    "selected_district_code = filtered_sales[\"자치구_코드_명\"].iloc[0]\n",
    "district_sales_filtered = district_sales_grouped[district_sales_grouped['자치구_코드_명'] == selected_district_code]\n",
    "\n",
    "# 매출 비율 계산\n",
    "sales_ratio = filtered_sales.groupby(\"기준_년분기\")[\"당월_매출_금액\"].sum() / \n",
    "district_sales_filtered.groupby(\"기준_년분기\")[\"자치구_총매출\"].sum()\n",
    "sales_ratio = sales_ratio.fillna(0).reset_index()\n",
    "sales_ratio.rename(columns={\"당월_매출_금액\": \"매출_비율\"}, inplace=True)\n",
    "\n",
    "# 유동인구, 경제심리지수, 소비자물가지수 결합\n",
    "econ_df['년월'] = econ_df['날짜'].str[:7]\n",
    "cpi_df['년월'] = cpi_df['날짜'].str[:7]\n",
    "pop_df['년월'] = pop_df['시군구명'].map(lambda x: str(x)[:7])\n",
    "merged_data = sales_ratio.merge(pop_df, left_on='기준_년분기', right_on='년월', how='left')\n",
    "merged_data = merged_data.merge(econ_df, on='년월', how='left')\n",
    "merged_data = merged_data.merge(cpi_df, on='년월', how='left')\n",
    "\n",
    "# 학습 데이터 준비\n",
    "X = merged_data[['총생활인구수', '경제심리지수', '소비자물가지수']]\n",
    "y = merged_data['매출_비율']\n",
    "\n",
    "# 모델 학습\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "# 미래 데이터 예측\n",
    "future_data = merged_data.iloc[-1].copy()\n",
    "future_data['기준_년분기'] = 20243\n",
    "future_X = future_data[['총생활인구수', '경제심리지수', '소비자물가지수']].values.reshape(1, -1)\n",
    "predicted_ratio = model.predict(future_X)[0]\n",
    "\n",
    "# 2024년 3분기 자치구 매출 예측 후 상권별 적용\n",
    "future_quarter = 20243\n",
    "future_district_sales = district_sales_filtered.iloc[-1]['자치구_총매출'] * 1.02  # 성장률 적용 (가정치)\n",
    "predicted_sales = future_district_sales * predicted_ratio\n",
    "\n",
    "print(f\"📌 선택한 상권: {selected_district}\")\n",
    "print(f\"📌 선택한 업종: {selected_business}\")\n",
    "print(f\"📊 예측된 2024년 3분기 매출: {predicted_sales:,.0f} 원\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "선택한 자치구와 업종 데이터가 없습니다.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 25\u001b[0m\n\u001b[0;32m     23\u001b[0m filtered_sales \u001b[38;5;241m=\u001b[39m df[(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m자치구_코드_명\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m selected_district) \u001b[38;5;241m&\u001b[39m (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m서비스_업종_코드_명\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m selected_sector)]\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filtered_sales\u001b[38;5;241m.\u001b[39mempty:\n\u001b[1;32m---> 25\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m선택한 자치구와 업종 데이터가 없습니다.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# 4. 자치구 전체 매출 데이터 계산\u001b[39;00m\n\u001b[0;32m     28\u001b[0m district_sales_grouped \u001b[38;5;241m=\u001b[39m df[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m자치구_코드_명\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m selected_district]\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m기준_년분기_코드\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m당월_매출_금액\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mreset_index()\n",
      "\u001b[1;31mValueError\u001b[0m: 선택한 자치구와 업종 데이터가 없습니다."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "\n",
    "# 1. 데이터 로드\n",
    "data_path = \"C:\\\\Users\\\\m\\\\Desktop\\\\머신러닝 사용 데이터\\\\구 데이터\\\\피처엔지니어링한통합데이터\\\\피처엔지니어링일단다한통합데이터.csv\"\n",
    "pop_data_path = \"C:\\\\Users\\\\m\\\\Desktop\\\\머신러닝 사용 데이터\\\\서울 일별 유동인구.csv\"\n",
    "econ_index_path = \"C:\\\\Users\\\\m\\\\Desktop\\\\머신러닝 사용 데이터\\\\전처리 데이터\\\\경제심리지수.csv\"\n",
    "cpi_data_path = \"C:\\\\Users\\\\m\\\\Desktop\\\\머신러닝 사용 데이터\\\\전처리 데이터\\\\소비자물가지수.csv\"\n",
    "\n",
    "df = pd.read_csv(data_path)\n",
    "pop_df = pd.read_csv(pop_data_path)\n",
    "econ_df = pd.read_csv(econ_index_path)\n",
    "cpi_df = pd.read_csv(cpi_data_path)\n",
    "\n",
    "# 2. 사용자 입력 받기\n",
    "selected_district = input(\"자치구명을 입력하세요: \")\n",
    "selected_sector = input(\"업종명을 입력하세요: \")\n",
    "\n",
    "# 3. 선택한 상권과 업종 데이터 필터링\n",
    "filtered_sales = df[(df['자치구_코드_명'] == selected_district) & (df['서비스_업종_코드_명'] == selected_sector)]\n",
    "if filtered_sales.empty:\n",
    "    raise ValueError(\"선택한 자치구와 업종 데이터가 없습니다.\")\n",
    "\n",
    "# 4. 자치구 전체 매출 데이터 계산\n",
    "district_sales_grouped = df[df['자치구_코드_명'] == selected_district].groupby('기준_년분기_코드')['당월_매출_금액'].sum().reset_index()\n",
    "sector_sales_grouped = filtered_sales.groupby('기준_년분기_코드')['당월_매출_금액'].sum().reset_index()\n",
    "\n",
    "# 5. 매출 비율 계산 및 학습 데이터 준비\n",
    "merged_sales = pd.merge(sector_sales_grouped, district_sales_grouped, on='기준_년분기_코드', suffixes=('_업종', '_자치구'))\n",
    "merged_sales['매출비율'] = merged_sales['당월_매출_금액_업종'] / merged_sales['당월_매출_금액_자치구']\n",
    "\n",
    "# 6. 외부 데이터 결합 (경제심리지수, 소비자물가지수)\n",
    "econ_df['날짜'] = econ_df['날짜'].astype(str).str[:6].astype(int)\n",
    "cpi_df['날짜'] = cpi_df['날짜'].astype(str).str[:6].astype(int)\n",
    "\n",
    "merged_sales = merged_sales.merge(econ_df, left_on='기준_년분기_코드', right_on='날짜', how='left')\n",
    "merged_sales = merged_sales.merge(cpi_df, left_on='기준_년분기_코드', right_on='날짜', how='left')\n",
    "merged_sales.drop(columns=['날짜_x', '날짜_y'], inplace=True)\n",
    "\n",
    "# 7. 학습 데이터 및 검증 데이터 분할\n",
    "X = merged_sales[['경제심리지수', '소비자물가지수']]\n",
    "y = merged_sales['매출비율']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 8. 모델 학습\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 9. 모델 검증\n",
    "y_pred = model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"검증 결과: MAE={mae:.4f}, R²={r2:.4f}\")\n",
    "\n",
    "# 10. 2024년 3분기 예측 데이터 준비\n",
    "future_quarter = 20243\n",
    "future_X = X.iloc[[-1]]  # 가장 최근 데이터를 기반으로 예측\n",
    "predicted_ratio = model.predict(future_X)[0]\n",
    "\n",
    "# 11. 2024년 3분기 자치구 예상 매출 계산\n",
    "latest_district_sales = district_sales_grouped[district_sales_grouped['기준_년분기_코드'] == 20242]['당월_매출_금액'].values[0]\n",
    "predicted_district_sales = latest_district_sales * 1.02  # 자치구 매출이 2% 성장한다고 가정\n",
    "predicted_sales = predicted_district_sales * predicted_ratio\n",
    "\n",
    "print(f\"📌 선택한 자치구: {selected_district}, 선택한 업종: {selected_sector}\")\n",
    "print(f\"✅ 2024년 3분기 예측 매출: {predicted_sales:,.0f}원\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'시군구명'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15336\\570041857.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[0mpopulation_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpopulation_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'시군구명'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'자치구_코드_명'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[0mpopulation_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpopulation_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'자치구_코드_명'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'총생활인구수'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;31m# 🔥 수정된 병합 코드: 컬럼명이 다름을 고려하여 `left_on`, `right_on` 사용\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m district_sales_grouped = district_sales_grouped.merge(\n\u001b[0m\u001b[0;32m     39\u001b[0m     \u001b[0mpopulation_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mleft_on\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'자치구_코드_명'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mright_on\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'시군구명'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'left'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\m\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m  10828\u001b[0m         \u001b[0mvalidate\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mMergeValidate\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10829\u001b[0m     \u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10830\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmerge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10831\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m> 10832\u001b[1;33m         return merge(\n\u001b[0m\u001b[0;32m  10833\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10834\u001b[0m             \u001b[0mright\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10835\u001b[0m             \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhow\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\m\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m    166\u001b[0m             \u001b[0mvalidate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m             \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m         \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 170\u001b[1;33m         op = _MergeOperation(\n\u001b[0m\u001b[0;32m    171\u001b[0m             \u001b[0mleft_df\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m             \u001b[0mright_df\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m             \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhow\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\m\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, indicator, validate)\u001b[0m\n\u001b[0;32m    790\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mright_join_keys\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    792\u001b[0m             \u001b[0mleft_drop\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    793\u001b[0m             \u001b[0mright_drop\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 794\u001b[1;33m         \u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_merge_keys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    795\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    796\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mleft_drop\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    797\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleft\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleft\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_drop_labels_or_levels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleft_drop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\m\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1293\u001b[0m                         \u001b[1;31m# Then we're either Hashable or a wrong-length arraylike,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1294\u001b[0m                         \u001b[1;31m#  the latter of which will raise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1295\u001b[0m                         \u001b[0mrk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mHashable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1296\u001b[0m                         \u001b[1;32mif\u001b[0m \u001b[0mrk\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1297\u001b[1;33m                             \u001b[0mright_keys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mright\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1298\u001b[0m                         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1299\u001b[0m                             \u001b[1;31m# work-around for merge_asof(right_index=True)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1300\u001b[0m                             \u001b[0mright_keys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mright\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\m\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1907\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mother_axes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1908\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_level_reference\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1909\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1910\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1911\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1912\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1913\u001b[0m         \u001b[1;31m# Check for duplicates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1914\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: '시군구명'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 데이터 파일 로드\n",
    "sales_df = pd.read_csv(r\"C:\\Users\\m\\Desktop\\머신러닝 사용 데이터\\구 데이터\\피처엔지니어링한통합데이터\\피처엔지니어링일단다한통합데이터.csv\")\n",
    "population_df = pd.read_csv(r\"C:\\Users\\m\\Desktop\\머신러닝 사용 데이터\\서울 일별 유동인구.csv\")\n",
    "economic_index_df = pd.read_csv(r\"C:\\Users\\m\\Desktop\\머신러닝 사용 데이터\\전처리 데이터\\경제심리지수.csv\")\n",
    "cpi_df = pd.read_csv(r\"C:\\Users\\m\\Desktop\\머신러닝 사용 데이터\\전처리 데이터\\소비자물가지수.csv\")\n",
    "\n",
    "# 사용자 입력값 받기\n",
    "selected_district = input(\"상권명을 입력하세요: \")\n",
    "selected_industry = input(\"업종명을 입력하세요: \")\n",
    "\n",
    "# 1. 선택된 상권-업종의 매출 데이터 필터링\n",
    "filtered_sales = sales_df[\n",
    "    (sales_df['상권_코드_명'] == selected_district) & \n",
    "    (sales_df['서비스_업종_코드_명'] == selected_industry)\n",
    "]\n",
    "\n",
    "# 2. 선택된 상권이 포함된 자치구 구하기\n",
    "selected_districts = filtered_sales['자치구_코드_명'].unique()\n",
    "\n",
    "# 3. 해당 자치구와 업종의 매출 총합 구하기\n",
    "district_sales_grouped = sales_df[\n",
    "    (sales_df['자치구_코드_명'].isin(selected_districts)) & \n",
    "    (sales_df['서비스_업종_코드_명'] == selected_industry)\n",
    "].groupby('기준_년분기_코드')['당월_매출_금액'].sum().reset_index()\n",
    "\n",
    "# 4. 선택된 상권-업종의 매출 비율 계산\n",
    "selected_total_sales = filtered_sales.groupby('기준_년분기_코드')['당월_매출_금액'].sum().reset_index()\n",
    "merged_sales = selected_total_sales.merge(district_sales_grouped, on='기준_년분기_코드', suffixes=('_상권', '_자치구'))\n",
    "merged_sales['매출_비율'] = merged_sales['당월_매출_금액_상권'] / merged_sales['당월_매출_금액_자치구']\n",
    "\n",
    "# 5. 유동인구 데이터 전처리 및 병합\n",
    "population_df = population_df.rename(columns={'시군구명': '자치구_코드_명'})\n",
    "population_df = population_df.groupby('자치구_코드_명')['총생활인구수'].mean().reset_index()\n",
    "\n",
    "# 🔥 수정된 병합 코드: 컬럼명이 다름을 고려하여 `left_on`, `right_on` 사용\n",
    "district_sales_grouped = district_sales_grouped.merge(\n",
    "    population_df, left_on='자치구_코드_명', right_on='시군구명', how='left'\n",
    ")\n",
    "\n",
    "# 6. 경제심리지수 및 소비자물가지수 병합\n",
    "economic_index_df['날짜'] = pd.to_datetime(economic_index_df['날짜'])\n",
    "cpi_df['날짜'] = pd.to_datetime(cpi_df['날짜'])\n",
    "\n",
    "# 7. 2019~2024년 2분기까지의 데이터 필터링\n",
    "district_sales_grouped['기준_년분기_코드'] = district_sales_grouped['기준_년분기_코드'].astype(str)\n",
    "filtered_data = district_sales_grouped[district_sales_grouped['기준_년분기_코드'].str[:4].astype(int) < 20243]\n",
    "\n",
    "# 8. 머신러닝 모델 학습 준비\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "features = filtered_data[['기준_년분기_코드', '총생활인구수']]\n",
    "target = filtered_data['당월_매출_금액']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# 9. 모델 학습 및 예측\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# 10. 모델 평가 및 미래 매출 예측\n",
    "mae = mean_absolute_error(y_test, predictions)\n",
    "print(f\"모델 MAE(평균 절대 오차): {mae}\")\n",
    "\n",
    "# 11. 2024년 3분기 매출 예측\n",
    "future_quarter = pd.DataFrame({'기준_년분기_코드': [20243], '총생활인구수': [population_df['총생활인구수'].mean()]})\n",
    "predicted_sales = model.predict(future_quarter)\n",
    "\n",
    "# 12. 최종 예측 결과 출력\n",
    "predicted_sales_value = predicted_sales[0] * merged_sales['매출_비율'].mean()\n",
    "print(f\"예측된 2024년 3분기 {selected_district} {selected_industry} 매출: {predicted_sales_value:.2f} 원\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "신규 데이터 생성(매출 데이터 추출, 유동인구 데이터와 병합합)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 병합 완료! 저장된 파일: C:\\Users\\m\\Desktop\\머신러닝 사용 데이터\\병합된_매출_유동인구.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 📌 1. 매출 데이터 불러오기\n",
    "sales_file = r\"C:\\Users\\m\\Desktop\\머신러닝 사용 데이터\\구 데이터\\피처엔지니어링한통합데이터\\피처엔지니어링일단다한통합데이터.csv\"\n",
    "sales_df = pd.read_csv(sales_file, encoding=\"utf-8-sig\")\n",
    "\n",
    "# 필요한 컬럼만 선택\n",
    "sales_df = sales_df[['기준_년분기_코드', '상권_코드_명', '서비스_업종_코드_명', '당월_매출_금액', '당월_매출_건수', '총_유동인구_수', '자치구_코드_명']]\n",
    "\n",
    "# 📌 2. 유동인구 데이터 불러오기\n",
    "pop_file = r\"C:\\Users\\m\\Desktop\\머신러닝 사용 데이터\\서울 일별 유동인구.csv\"\n",
    "pop_df = pd.read_csv(pop_file, encoding=\"utf-8-sig\")\n",
    "\n",
    "# 기준일ID를 연분기 형식으로 변환 (예: 20180416 -> 20181)\n",
    "pop_df['기준_년분기_코드'] = (pop_df['기준일ID'] // 10000) * 10 + ((pop_df['기준일ID'] % 10000) // 3000 + 1)\n",
    "\n",
    "# 일별 데이터를 분기별로 집계\n",
    "pop_quarterly_df = pop_df.groupby(['기준_년분기_코드', '시군구명'], as_index=False)[\n",
    "    ['총생활인구수', '일최대인구수', '일최소인구수', '일최대이동인구수', '서울외유입인구수']\n",
    "].sum()\n",
    "\n",
    "# 컬럼명 변경 (매출 데이터와 일관성 유지)\n",
    "pop_quarterly_df = pop_quarterly_df.rename(columns={'시군구명': '자치구_코드_명'})\n",
    "\n",
    "# 📌 3. 데이터 병합\n",
    "merged_df = sales_df.merge(pop_quarterly_df, on=['기준_년분기_코드', '자치구_코드_명'], how='left')\n",
    "\n",
    "# 📌 4. CSV 파일로 저장\n",
    "output_file = r\"C:\\Users\\m\\Desktop\\머신러닝 사용 데이터\\병합된_매출_유동인구.csv\"\n",
    "merged_df.to_csv(output_file, encoding=\"utf-8-sig\", index=False)\n",
    "\n",
    "print(f\"데이터 병합 완료! 저장된 파일: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검증 결과 - MAE: 9829827.11, RMSE: 14001143.83\n",
      "2024년 3분기의 예상 매출: 101649046.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\m\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# 데이터 로드\n",
    "sales_data = pd.read_csv(r\"C:\\Users\\m\\Desktop\\머신러닝 사용 데이터\\병합된_매출_유동인구.csv\")\n",
    "cpi_data = pd.read_csv(r\"C:\\Users\\m\\Desktop\\머신러닝 사용 데이터\\전처리 데이터\\소비자물가지수.csv\")\n",
    "esi_data = pd.read_csv(r\"C:\\Users\\m\\Desktop\\머신러닝 사용 데이터\\전처리 데이터\\경제심리지수.csv\")\n",
    "\n",
    "# 날짜 형식 변환\n",
    "cpi_data['날짜'] = pd.to_datetime(cpi_data['날짜'])\n",
    "esi_data['날짜'] = pd.to_datetime(esi_data['날짜'])\n",
    "\n",
    "# 분기 코드로 변환\n",
    "def get_quarter_code(date):\n",
    "    return date.year * 10 + (date.month - 1) // 3 + 1\n",
    "\n",
    "cpi_data['기준_년분기_코드'] = cpi_data['날짜'].apply(get_quarter_code)\n",
    "esi_data['기준_년분기_코드'] = esi_data['날짜'].apply(get_quarter_code)\n",
    "\n",
    "# 분기별 평균 계산\n",
    "cpi_quarterly = cpi_data.groupby('기준_년분기_코드')['소비자물가지수'].mean().reset_index()\n",
    "esi_quarterly = esi_data.groupby('기준_년분기_코드')['경제심리지수'].mean().reset_index()\n",
    "\n",
    "# 경제심리지수는 직전 분기의 평균값 사용\n",
    "esi_quarterly['경제심리지수'] = esi_quarterly['경제심리지수'].shift(1)\n",
    "\n",
    "# 사용자 입력값 받기\n",
    "region_name = input(\"상권명을 입력하세요: \")\n",
    "industry_name = input(\"업종명을 입력하세요: \")\n",
    "\n",
    "# 상권 및 업종에 해당하는 데이터 필터링\n",
    "filtered_sales = sales_data[(sales_data['상권_코드_명'] == region_name) & \n",
    "                            (sales_data['서비스_업종_코드_명'] == industry_name)]\n",
    "\n",
    "# 자치구별 매출 총합 계산\n",
    "region_sales = sales_data.groupby(['기준_년분기_코드', '자치구_코드_명'])['당월_매출_금액'].sum().reset_index()\n",
    "filtered_sales = filtered_sales.merge(region_sales, on=['기준_년분기_코드', '자치구_코드_명'], suffixes=('', '_자치구총합'))\n",
    "\n",
    "# 매출 비율 계산\n",
    "filtered_sales['매출비율'] = filtered_sales['당월_매출_금액'] / filtered_sales['당월_매출_금액_자치구총합']\n",
    "\n",
    "# 소비자물가지수와 경제심리지수를 병합\n",
    "filtered_sales = filtered_sales.merge(cpi_quarterly, on='기준_년분기_코드', how='left')\n",
    "filtered_sales = filtered_sales.merge(esi_quarterly, on='기준_년분기_코드', how='left')\n",
    "\n",
    "# 학습 및 타겟 변수 설정\n",
    "X = filtered_sales[['소비자물가지수', '경제심리지수', '총생활인구수', '일최대인구수', '일최소인구수', '일최대이동인구수', '서울외유입인구수']]\n",
    "y = filtered_sales['당월_매출_금액']\n",
    "\n",
    "# 학습-검증 데이터 분리 (8:2 비율)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 모델 학습\n",
    "model = RandomForestRegressor(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 검증 결과 출력\n",
    "y_pred = model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "print(f\"검증 결과 - MAE: {mae:.2f}, RMSE: {rmse:.2f}\")\n",
    "\n",
    "# 2024년 3분기의 소비자물가지수와 경제심리지수를 가져옴\n",
    "q3_cpi = cpi_quarterly[cpi_quarterly['기준_년분기_코드'] == 20243]['소비자물가지수'].values[0]\n",
    "q3_previous_qtr_code = 20242  # 직전 분기 코드\n",
    "q3_previous_qtr_avg_esi = esi_quarterly[esi_quarterly['기준_년분기_코드'] == q3_previous_qtr_code]['경제심리지수'].values[0]\n",
    "\n",
    "# 예측을 위한 입력값 생성 (임의로 인구 데이터를 평균값으로 설정)\n",
    "input_features = [[q3_cpi, q3_previous_qtr_avg_esi, \n",
    "                   filtered_sales['총생활인구수'].mean(), \n",
    "                   filtered_sales['일최대인구수'].mean(), \n",
    "                   filtered_sales['일최소인구수'].mean(), \n",
    "                   filtered_sales['일최대이동인구수'].mean(), \n",
    "                   filtered_sales['서울외유입인구수'].mean()]]\n",
    "\n",
    "predicted_sales_q3 = model.predict(input_features)[0]\n",
    "print(f\"2024년 3분기의 예상 매출: {predicted_sales_q3:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검증 결과 - MAE: 9829827.11, RMSE: 14001143.83\n",
      "2024년 3분기의 예상 매출: 101649046.18\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# 데이터 로드\n",
    "sales_data = pd.read_csv(r\"C:\\Users\\m\\Desktop\\머신러닝 사용 데이터\\병합된_매출_유동인구.csv\")\n",
    "cpi_data = pd.read_csv(r\"C:\\Users\\m\\Desktop\\머신러닝 사용 데이터\\전처리 데이터\\소비자물가지수.csv\")\n",
    "esi_data = pd.read_csv(r\"C:\\Users\\m\\Desktop\\머신러닝 사용 데이터\\전처리 데이터\\경제심리지수.csv\")\n",
    "\n",
    "# 날짜 형식 변환\n",
    "cpi_data['날짜'] = pd.to_datetime(cpi_data['날짜'])\n",
    "esi_data['날짜'] = pd.to_datetime(esi_data['날짜'])\n",
    "\n",
    "# 분기 코드로 변환\n",
    "def get_quarter_code(date):\n",
    "    return date.year * 10 + ((date.month - 1) // 3) + 1\n",
    "\n",
    "cpi_data['기준_년분기_코드'] = cpi_data['날짜'].apply(get_quarter_code)\n",
    "esi_data['기준_년분기_코드'] = esi_data['날짜'].apply(get_quarter_code)\n",
    "\n",
    "# 분기별 평균 계산\n",
    "cpi_quarterly = cpi_data.groupby('기준_년분기_코드')['소비자물가지수'].mean().reset_index()\n",
    "esi_quarterly = esi_data.groupby('기준_년분기_코드')['경제심리지수'].mean().reset_index()\n",
    "\n",
    "# 경제심리지수는 직전 분기의 평균값 사용\n",
    "esi_quarterly['경제심리지수'] = esi_quarterly['경제심리지수'].shift(1)\n",
    "\n",
    "# 사용자 입력값 받기\n",
    "region_name = input(\"상권명을 입력하세요: \")\n",
    "industry_name = input(\"업종명을 입력하세요: \")\n",
    "\n",
    "# 상권 및 업종에 해당하는 데이터 필터링\n",
    "filtered_sales = sales_data[(sales_data['상권_코드_명'] == region_name) & \n",
    "                            (sales_data['서비스_업종_코드_명'] == industry_name)]\n",
    "\n",
    "# 자치구별 매출 총합 계산\n",
    "region_sales = sales_data.groupby(['기준_년분기_코드', '자치구_코드_명'])['당월_매출_금액'].sum().reset_index()\n",
    "filtered_sales = filtered_sales.merge(region_sales, on=['기준_년분기_코드', '자치구_코드_명'], \n",
    "                                      suffixes=('', '_자치구총합'))\n",
    "\n",
    "# 매출 비율 계산\n",
    "filtered_sales['매출비율'] = filtered_sales['당월_매출_금액'] / filtered_sales['당월_매출_금액_자치구총합']\n",
    "\n",
    "# 소비자물가지수와 경제심리지수를 병합\n",
    "filtered_sales = filtered_sales.merge(cpi_quarterly, on='기준_년분기_코드', how='left')\n",
    "filtered_sales = filtered_sales.merge(esi_quarterly, on='기준_년분기_코드', how='left')\n",
    "\n",
    "# 학습 및 타겟 변수 설정\n",
    "feature_columns = ['소비자물가지수', '경제심리지수', '총생활인구수', '일최대인구수', \n",
    "                   '일최소인구수', '일최대이동인구수', '서울외유입인구수']\n",
    "X = filtered_sales[feature_columns]\n",
    "y = filtered_sales['당월_매출_금액']\n",
    "\n",
    "# 학습-검증 데이터 분리 (8:2 비율)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 모델 학습\n",
    "model = RandomForestRegressor(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 검증 결과 출력\n",
    "y_pred = model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(f\"검증 결과 - MAE: {mae:.2f}, RMSE: {rmse:.2f}\")\n",
    "\n",
    "# 2024년 3분기의 소비자물가지수와 경제심리지수를 가져옴\n",
    "q3_cpi = cpi_quarterly[cpi_quarterly['기준_년분기_코드'] == 20243]['소비자물가지수'].values[0]\n",
    "q3_previous_qtr_code = 20242  # 직전 분기 코드\n",
    "q3_previous_qtr_avg_esi = esi_quarterly[esi_quarterly['기준_년분기_코드'] == q3_previous_qtr_code]['경제심리지수'].values[0]\n",
    "\n",
    "# 예측을 위한 입력값 생성 (임의로 인구 데이터를 평균값으로 설정)\n",
    "input_data = {\n",
    "    '소비자물가지수': [q3_cpi],\n",
    "    '경제심리지수': [q3_previous_qtr_avg_esi],\n",
    "    '총생활인구수': [filtered_sales['총생활인구수'].mean()],\n",
    "    '일최대인구수': [filtered_sales['일최대인구수'].mean()],\n",
    "    '일최소인구수': [filtered_sales['일최소인구수'].mean()],\n",
    "    '일최대이동인구수': [filtered_sales['일최대이동인구수'].mean()],\n",
    "    '서울외유입인구수': [filtered_sales['서울외유입인구수'].mean()]\n",
    "}\n",
    "\n",
    "# DataFrame으로 생성하여 학습 시 사용한 feature 이름을 동일하게 지정\n",
    "input_features = pd.DataFrame(input_data, columns=feature_columns)\n",
    "\n",
    "predicted_sales_q3 = model.predict(input_features)[0]\n",
    "print(f\"2024년 3분기의 예상 매출: {predicted_sales_q3:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다른 모델(XGboost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-2.1.4-py3-none-win_amd64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\m\\anaconda3\\lib\\site-packages (from xgboost) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\m\\anaconda3\\lib\\site-packages (from xgboost) (1.13.1)\n",
      "Downloading xgboost-2.1.4-py3-none-win_amd64.whl (124.9 MB)\n",
      "   ---------------------------------------- 0.0/124.9 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 7.6/124.9 MB 39.0 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 13.1/124.9 MB 32.9 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 19.7/124.9 MB 33.6 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 24.9/124.9 MB 30.9 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 30.4/124.9 MB 30.1 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 35.4/124.9 MB 29.2 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 39.3/124.9 MB 27.8 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 44.8/124.9 MB 27.7 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 49.8/124.9 MB 27.3 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 55.3/124.9 MB 27.3 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 59.8/124.9 MB 26.6 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 64.0/124.9 MB 26.1 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 68.7/124.9 MB 25.9 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 71.8/124.9 MB 25.3 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 76.5/124.9 MB 25.2 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 79.4/124.9 MB 24.5 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 82.1/124.9 MB 23.7 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 84.9/124.9 MB 23.3 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 87.8/124.9 MB 22.7 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 92.3/124.9 MB 22.6 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 97.0/124.9 MB 22.8 MB/s eta 0:00:02\n",
      "   ------------------------------- ------- 102.0/124.9 MB 22.8 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 107.5/124.9 MB 23.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 112.7/124.9 MB 23.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 119.0/124.9 MB 23.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  124.8/124.9 MB 23.6 MB/s eta 0:00:01\n",
      "   --------------------------------------- 124.9/124.9 MB 22.9 MB/s eta 0:00:00\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-2.1.4\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검증 결과 - MAE: 12164253.54, RMSE: 14829197.65\n",
      "2024년 3분기의 예상 매출: 105060776.00\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# 데이터 로드\n",
    "sales_data = pd.read_csv(r\"C:\\Users\\m\\Desktop\\머신러닝 사용 데이터\\병합된_매출_유동인구.csv\")\n",
    "cpi_data = pd.read_csv(r\"C:\\Users\\m\\Desktop\\머신러닝 사용 데이터\\전처리 데이터\\소비자물가지수.csv\")\n",
    "esi_data = pd.read_csv(r\"C:\\Users\\m\\Desktop\\머신러닝 사용 데이터\\전처리 데이터\\경제심리지수.csv\")\n",
    "\n",
    "# 날짜 형식 변환\n",
    "cpi_data['날짜'] = pd.to_datetime(cpi_data['날짜'])\n",
    "esi_data['날짜'] = pd.to_datetime(esi_data['날짜'])\n",
    "\n",
    "# 분기 코드로 변환\n",
    "def get_quarter_code(date):\n",
    "    return date.year * 10 + ((date.month - 1) // 3) + 1\n",
    "\n",
    "cpi_data['기준_년분기_코드'] = cpi_data['날짜'].apply(get_quarter_code)\n",
    "esi_data['기준_년분기_코드'] = esi_data['날짜'].apply(get_quarter_code)\n",
    "\n",
    "# 분기별 평균 계산\n",
    "cpi_quarterly = cpi_data.groupby('기준_년분기_코드')['소비자물가지수'].mean().reset_index()\n",
    "esi_quarterly = esi_data.groupby('기준_년분기_코드')['경제심리지수'].mean().reset_index()\n",
    "\n",
    "# 경제심리지수는 직전 분기의 평균값 사용\n",
    "esi_quarterly['경제심리지수'] = esi_quarterly['경제심리지수'].shift(1)\n",
    "\n",
    "# 사용자 입력값 받기\n",
    "region_name = input(\"상권명을 입력하세요: \")\n",
    "industry_name = input(\"업종명을 입력하세요: \")\n",
    "\n",
    "# 상권 및 업종에 해당하는 데이터 필터링\n",
    "filtered_sales = sales_data[\n",
    "    (sales_data['상권_코드_명'] == region_name) & \n",
    "    (sales_data['서비스_업종_코드_명'] == industry_name)\n",
    "]\n",
    "\n",
    "# 자치구별 매출 총합 계산\n",
    "region_sales = sales_data.groupby(['기준_년분기_코드', '자치구_코드_명'])['당월_매출_금액'].sum().reset_index()\n",
    "filtered_sales = filtered_sales.merge(\n",
    "    region_sales, \n",
    "    on=['기준_년분기_코드', '자치구_코드_명'], \n",
    "    suffixes=('', '_자치구총합')\n",
    ")\n",
    "\n",
    "# 매출 비율 계산\n",
    "filtered_sales['매출비율'] = filtered_sales['당월_매출_금액'] / filtered_sales['당월_매출_금액_자치구총합']\n",
    "\n",
    "# 소비자물가지수와 경제심리지수를 병합\n",
    "filtered_sales = filtered_sales.merge(cpi_quarterly, on='기준_년분기_코드', how='left')\n",
    "filtered_sales = filtered_sales.merge(esi_quarterly, on='기준_년분기_코드', how='left')\n",
    "\n",
    "# 학습 및 타겟 변수 설정\n",
    "feature_columns = [\n",
    "    '소비자물가지수', '경제심리지수', '총생활인구수', \n",
    "    '일최대인구수', '일최소인구수', '일최대이동인구수', '서울외유입인구수'\n",
    "]\n",
    "X = filtered_sales[feature_columns]\n",
    "y = filtered_sales['당월_매출_금액']\n",
    "\n",
    "# 학습-검증 데이터 분리 (8:2 비율)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# XGBoost 모델 적용 (랜덤포레스트보다 일반적으로 좋은 성능을 기대할 수 있음)\n",
    "model = XGBRegressor(\n",
    "    random_state=42,\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=3\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 검증 결과 출력\n",
    "y_pred = model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(f\"검증 결과 - MAE: {mae:.2f}, RMSE: {rmse:.2f}\")\n",
    "\n",
    "# 2024년 3분기의 소비자물가지수와 경제심리지수를 가져옴\n",
    "q3_cpi = cpi_quarterly[cpi_quarterly['기준_년분기_코드'] == 20243]['소비자물가지수'].values[0]\n",
    "q3_previous_qtr_code = 20242  # 직전 분기 코드\n",
    "q3_previous_qtr_avg_esi = esi_quarterly[\n",
    "    esi_quarterly['기준_년분기_코드'] == q3_previous_qtr_code\n",
    "]['경제심리지수'].values[0]\n",
    "\n",
    "# 예측을 위한 입력값 생성 (임의로 인구 데이터를 평균값으로 설정)\n",
    "input_data = {\n",
    "    '소비자물가지수': [q3_cpi],\n",
    "    '경제심리지수': [q3_previous_qtr_avg_esi],\n",
    "    '총생활인구수': [filtered_sales['총생활인구수'].mean()],\n",
    "    '일최대인구수': [filtered_sales['일최대인구수'].mean()],\n",
    "    '일최소인구수': [filtered_sales['일최소인구수'].mean()],\n",
    "    '일최대이동인구수': [filtered_sales['일최대이동인구수'].mean()],\n",
    "    '서울외유입인구수': [filtered_sales['서울외유입인구수'].mean()]\n",
    "}\n",
    "\n",
    "# DataFrame으로 생성하여 학습 시 사용한 feature 이름을 동일하게 지정\n",
    "input_features = pd.DataFrame(input_data, columns=feature_columns)\n",
    "\n",
    "predicted_sales_q3 = model.predict(input_features)[0]\n",
    "print(f\"2024년 3분기의 예상 매출: {predicted_sales_q3:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다른 데이터 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting neural\n",
      "  Downloading neural-0.1.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: prophet in c:\\users\\m\\anaconda3\\lib\\site-packages (1.1.6)\n",
      "Requirement already satisfied: cmdstanpy>=1.0.4 in c:\\users\\m\\anaconda3\\lib\\site-packages (from prophet) (1.2.5)\n",
      "Requirement already satisfied: numpy>=1.15.4 in c:\\users\\m\\anaconda3\\lib\\site-packages (from prophet) (1.26.4)\n",
      "Requirement already satisfied: matplotlib>=2.0.0 in c:\\users\\m\\anaconda3\\lib\\site-packages (from prophet) (3.9.2)\n",
      "Requirement already satisfied: pandas>=1.0.4 in c:\\users\\m\\anaconda3\\lib\\site-packages (from prophet) (2.2.2)\n",
      "Requirement already satisfied: holidays<1,>=0.25 in c:\\users\\m\\anaconda3\\lib\\site-packages (from prophet) (0.66)\n",
      "Requirement already satisfied: tqdm>=4.36.1 in c:\\users\\m\\anaconda3\\lib\\site-packages (from prophet) (4.66.5)\n",
      "Requirement already satisfied: importlib-resources in c:\\users\\m\\anaconda3\\lib\\site-packages (from prophet) (6.5.2)\n",
      "Requirement already satisfied: stanio<2.0.0,>=0.4.0 in c:\\users\\m\\anaconda3\\lib\\site-packages (from cmdstanpy>=1.0.4->prophet) (0.5.1)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\m\\anaconda3\\lib\\site-packages (from holidays<1,>=0.25->prophet) (2.9.0.post0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\m\\anaconda3\\lib\\site-packages (from matplotlib>=2.0.0->prophet) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\m\\anaconda3\\lib\\site-packages (from matplotlib>=2.0.0->prophet) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\m\\anaconda3\\lib\\site-packages (from matplotlib>=2.0.0->prophet) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\m\\anaconda3\\lib\\site-packages (from matplotlib>=2.0.0->prophet) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\m\\anaconda3\\lib\\site-packages (from matplotlib>=2.0.0->prophet) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\m\\anaconda3\\lib\\site-packages (from matplotlib>=2.0.0->prophet) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\m\\anaconda3\\lib\\site-packages (from matplotlib>=2.0.0->prophet) (3.1.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\m\\anaconda3\\lib\\site-packages (from pandas>=1.0.4->prophet) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\m\\anaconda3\\lib\\site-packages (from pandas>=1.0.4->prophet) (2023.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\m\\anaconda3\\lib\\site-packages (from tqdm>=4.36.1->prophet) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\m\\anaconda3\\lib\\site-packages (from python-dateutil->holidays<1,>=0.25->prophet) (1.16.0)\n",
      "Downloading neural-0.1.0-py2.py3-none-any.whl (5.2 kB)\n",
      "Installing collected packages: neural\n",
      "Successfully installed neural-0.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install neural prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'neuralprophet'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mneuralprophet\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NeuralProphet\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# 데이터 불러오기\u001b[39;00m\n\u001b[0;32m      6\u001b[0m data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mm\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDesktop\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m머신러닝 사용 데이터\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m머신러닝용_시계열데이터_null 제거.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'neuralprophet'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from neuralprophet import NeuralProphet\n",
    "\n",
    "# 데이터 불러오기\n",
    "data = pd.read_csv(r\"C:\\Users\\m\\Desktop\\머신러닝 사용 데이터\\머신러닝용_시계열데이터_null 제거.csv\")\n",
    "\n",
    "data['날짜'] = pd.to_datetime(data['날짜'])  # 날짜 변환\n",
    "\n",
    "# 0인 값을 NaN으로 변경\n",
    "data.loc[data['총_결제금액'] == 0, '총_결제금액'] = np.nan\n",
    "data.loc[data['총_결제건수'] == 0, '총_결제건수'] = np.nan\n",
    "\n",
    "# 자치구별로 처리\n",
    "def fill_missing_values(group, target):\n",
    "    df = group[['날짜', target]].copy()\n",
    "    df = df.rename(columns={'날짜': 'ds', target: 'y'})\n",
    "    \n",
    "    # 학습 데이터와 예측할 데이터 분리\n",
    "    train_df = df.dropna()\n",
    "    predict_df = df[df['y'].isna()]\n",
    "    \n",
    "    if train_df.empty or predict_df.empty:\n",
    "        return group  # 학습할 데이터가 없으면 원본 반환\n",
    "    \n",
    "    # 모델 학습\n",
    "    model = NeuralProphet()\n",
    "    model.fit(train_df, freq='D', progress_bar=False)\n",
    "    \n",
    "    # 결측치 예측\n",
    "    future = predict_df[['ds']]\n",
    "    forecast = model.predict(future)\n",
    "    \n",
    "    # 예측값 채우기\n",
    "    group.loc[group[target].isna(), target] = forecast['yhat1'].values\n",
    "    return group\n",
    "\n",
    "# 모든 자치구에 적용\n",
    "data = data.groupby('자치구', group_keys=False).apply(lambda g: fill_missing_values(g, '총_결제금액'))\n",
    "data = data.groupby('자치구', group_keys=False).apply(lambda g: fill_missing_values(g, '총_결제건수'))\n",
    "\n",
    "# 결과 저장\n",
    "data.to_csv(\"filled_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
